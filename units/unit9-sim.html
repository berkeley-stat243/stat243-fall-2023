<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris Paciorek">
<meta name="dcterms.date" content="2023-10-17">

<title>Statistics 243 Fall 2023 - Simulation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../units/unit10-linalg.html" rel="next">
<link href="../units/unit8-numbers.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Statistics 243 Fall 2023</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../office_hours.html" rel="" target="">
 <span class="menu-text">Office hours</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../schedule.html" rel="" target="">
 <span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-units" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Units</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-units">    
        <li>
    <a class="dropdown-item" href="../units/unit1-intro.html" rel="" target="">
 <span class="dropdown-text">Unit 1 (UNIX intro)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit2-dataTech.html" rel="" target="">
 <span class="dropdown-text">Unit 2 (Data technologies)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit3-bash.html" rel="" target="">
 <span class="dropdown-text">Unit 3 (Bash shell)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit4-goodPractices.html" rel="" target="">
 <span class="dropdown-text">Unit 4 (Good practices)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit5-programming.html" rel="" target="">
 <span class="dropdown-text">Unit 5 (Programming)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit6-parallel.html" rel="" target="">
 <span class="dropdown-text">Unit 6 (Parallelization)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit7-bigData.html" rel="" target="">
 <span class="dropdown-text">Unit 7 (Databases)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit8-numbers.html" rel="" target="">
 <span class="dropdown-text">Unit 8 (Precision)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit9-sim.html" rel="" target="">
 <span class="dropdown-text">Unit 9 (Simulation)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit10-linalg.html" rel="" target="">
 <span class="dropdown-text">Unit 10 (Linear Algebra)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-labs" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Labs</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-labs">    
        <li>
    <a class="dropdown-item" href="../labs/lab0-setup.html" rel="" target="">
 <span class="dropdown-text">Lab 0: Setup</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab1-submission.html" rel="" target="">
 <span class="dropdown-text">Lab 1: Problem set submission</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab2-testing.html" rel="" target="">
 <span class="dropdown-text">Lab 2: Assertions, Exceptions, and Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab3-debugging.html" rel="" target="">
 <span class="dropdown-text">Lab 3: Debugging</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab5-codereview.html" rel="" target="">
 <span class="dropdown-text">Lab 5: Code Reviews</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/06/scf.html" rel="" target="">
 <span class="dropdown-text">Lab 6: SCF and Parallel Computing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/py_vs_R.html" rel="" target="">
 <span class="dropdown-text">Lab 7: R vs.&nbsp;Python</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-how-tos" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">How tos</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-how-tos">    
        <li>
    <a class="dropdown-item" href="../howtos/accessingPython.html" rel="" target="">
 <span class="dropdown-text">Accessing Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/accessingUnixCommandLine.html" rel="" target="">
 <span class="dropdown-text">Accessing the Unix Command Line</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/gitInstall.html" rel="" target="">
 <span class="dropdown-text">Installing Git</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/quartoInstall.html" rel="" target="">
 <span class="dropdown-text">Installing Quarto</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/ps-submission.html" rel="" target="">
 <span class="dropdown-text">Problem Set Submissions</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Windows</li>
        <li>
    <a class="dropdown-item" href="../howtos/windowsAndLinux.html" rel="" target="">
 <span class="dropdown-text">Installing the Linux Subsystem on Windows</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://edstem.org/us/courses/42474/discussion/" rel="" target="">
 <span class="menu-text">Discussion</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://statistics.berkeley.edu/computing/training/tutorials" rel="" target="">
 <span class="menu-text">Tutorials</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/berkeley-stat243/stat243-fall-2023" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../units/unit9-sim.html">Unit 9 (Simulation)</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit1-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 1 (UNIX intro)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit2-dataTech.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 2 (Data technologies)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit3-bash.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 3 (Bash shell)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit4-goodPractices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 4 (Good practices)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit5-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 5 (Programming)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit6-parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 6 (Parallelization)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit7-bigData.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 7 (Databases)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit8-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 8 (Precision)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit9-sim.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Unit 9 (Simulation)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit10-linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 10 (Linear Algebra)</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#monte-carlo-considerations" id="toc-monte-carlo-considerations" class="nav-link active" data-scroll-target="#monte-carlo-considerations">1. Monte Carlo considerations</a>
  <ul class="collapse">
  <li><a href="#motivating-example" id="toc-motivating-example" class="nav-link" data-scroll-target="#motivating-example">Motivating example</a></li>
  <li><a href="#monte-carlo-mc-basics" id="toc-monte-carlo-mc-basics" class="nav-link" data-scroll-target="#monte-carlo-mc-basics">Monte Carlo (MC) basics</a>
  <ul class="collapse">
  <li><a href="#monte-carlo-overview" id="toc-monte-carlo-overview" class="nav-link" data-scroll-target="#monte-carlo-overview">Monte Carlo overview</a></li>
  <li><a href="#simulation-uncertainty-i.e.-monte-carlo-uncertainty" id="toc-simulation-uncertainty-i.e.-monte-carlo-uncertainty" class="nav-link" data-scroll-target="#simulation-uncertainty-i.e.-monte-carlo-uncertainty">Simulation uncertainty (i.e., Monte Carlo uncertainty)</a></li>
  <li><a href="#final-notes" id="toc-final-notes" class="nav-link" data-scroll-target="#final-notes">Final notes</a></li>
  </ul></li>
  <li><a href="#variance-reduction-optional" id="toc-variance-reduction-optional" class="nav-link" data-scroll-target="#variance-reduction-optional">Variance reduction (optional)</a></li>
  </ul></li>
  <li><a href="#design-of-simulation-studies" id="toc-design-of-simulation-studies" class="nav-link" data-scroll-target="#design-of-simulation-studies">2. Design of simulation studies</a>
  <ul class="collapse">
  <li><a href="#basic-steps-of-a-simulation-study" id="toc-basic-steps-of-a-simulation-study" class="nav-link" data-scroll-target="#basic-steps-of-a-simulation-study">Basic steps of a simulation study</a></li>
  <li><a href="#various-considerations" id="toc-various-considerations" class="nav-link" data-scroll-target="#various-considerations">Various considerations</a></li>
  <li><a href="#experimental-design-optional" id="toc-experimental-design-optional" class="nav-link" data-scroll-target="#experimental-design-optional">Experimental Design (optional)</a></li>
  </ul></li>
  <li><a href="#implementation-of-simulation-studies" id="toc-implementation-of-simulation-studies" class="nav-link" data-scroll-target="#implementation-of-simulation-studies">3. Implementation of simulation studies</a>
  <ul class="collapse">
  <li><a href="#computational-efficiency" id="toc-computational-efficiency" class="nav-link" data-scroll-target="#computational-efficiency">Computational efficiency</a></li>
  <li><a href="#analysis-and-reporting" id="toc-analysis-and-reporting" class="nav-link" data-scroll-target="#analysis-and-reporting">Analysis and reporting</a></li>
  </ul></li>
  <li><a href="#random-number-generation-rng" id="toc-random-number-generation-rng" class="nav-link" data-scroll-target="#random-number-generation-rng">4. Random number generation (RNG)</a>
  <ul class="collapse">
  <li><a href="#generating-random-uniforms-on-a-computer" id="toc-generating-random-uniforms-on-a-computer" class="nav-link" data-scroll-target="#generating-random-uniforms-on-a-computer">Generating random uniforms on a computer</a>
  <ul class="collapse">
  <li><a href="#sequential-congruential-generators" id="toc-sequential-congruential-generators" class="nav-link" data-scroll-target="#sequential-congruential-generators">Sequential congruential generators</a></li>
  <li><a href="#modern-generators-pcg-and-mersenne-twister" id="toc-modern-generators-pcg-and-mersenne-twister" class="nav-link" data-scroll-target="#modern-generators-pcg-and-mersenne-twister">Modern generators (PCG and Mersenne Twister)</a></li>
  </ul></li>
  <li><a href="#rng-in-python" id="toc-rng-in-python" class="nav-link" data-scroll-target="#rng-in-python">RNG in Python</a></li>
  <li><a href="#rng-in-parallel" id="toc-rng-in-parallel" class="nav-link" data-scroll-target="#rng-in-parallel">RNG in parallel</a></li>
  </ul></li>
  <li><a href="#generating-random-variables" id="toc-generating-random-variables" class="nav-link" data-scroll-target="#generating-random-variables">5. Generating random variables</a>
  <ul class="collapse">
  <li><a href="#multivariate-distributions" id="toc-multivariate-distributions" class="nav-link" data-scroll-target="#multivariate-distributions">Multivariate distributions</a></li>
  <li><a href="#inverse-cdf" id="toc-inverse-cdf" class="nav-link" data-scroll-target="#inverse-cdf">Inverse CDF</a></li>
  <li><a href="#rejection-sampling" id="toc-rejection-sampling" class="nav-link" data-scroll-target="#rejection-sampling">Rejection sampling</a></li>
  <li><a href="#adaptive-rejection-sampling-optional" id="toc-adaptive-rejection-sampling-optional" class="nav-link" data-scroll-target="#adaptive-rejection-sampling-optional">Adaptive rejection sampling (optional)</a></li>
  <li><a href="#importance-sampling" id="toc-importance-sampling" class="nav-link" data-scroll-target="#importance-sampling">Importance sampling</a></li>
  <li><a href="#ratio-of-uniforms-optional" id="toc-ratio-of-uniforms-optional" class="nav-link" data-scroll-target="#ratio-of-uniforms-optional">Ratio of uniforms (optional)</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="unit9-sim.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Simulation</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chris Paciorek </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 17, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><a href="./unit9-sim.pdf" class="btn btn-primary">PDF</a></p>
<p>References:</p>
<ul>
<li>Gentle: Computational Statistics</li>
<li>Monahan: Numerical Methods of Statistics</li>
</ul>
<p>Many (most?) statistical papers include a simulation (i.e., Monte Carlo) study. Many papers on machine learning methods also include a simulation study. The basic idea is that closed-form mathematical analysis of the properties of a statistical or machine learning method/model is often hard to do. Even if possible, it usually involves approximations or simplifications. A canonical situation in statistics is that we have an asymptotic result and we want to know what happens in finite samples, but often we do not even have the asymptotic result. Instead, we can estimate mathematical expressions using random numbers. So we design a simulation study to evaluate the method/model or compare multiple methods. The result is that the researcher carries out an experiment (on the computer, sometimes called <em>in silico</em>), generally varying different factors to see what has an effect on the outcome of interest.</p>
<p>The basic strategy generally involves simulating data and then using the method(s) on the simulated data, summarizing the results to assess/compare the method(s).</p>
<p>Most simulation studies aim to approximate an integral, generally an expected value (mean, bias, variance, MSE, probability, etc.). In low dimensions, methods such as Gaussian quadrature are best for estimating an integral but these methods don’t scale well, so in higher dimensions (e.g., the usual situation with <span class="math inline">\(n\)</span> observations) we often use Monte Carlo techniques.</p>
<p>To be more concrete:</p>
<ul>
<li><p>If we have a <em>method for estimating a model parameter</em> (including estimating uncertainty), such as a regression coefficient, what properties do we want the method to have and what criteria could we use?</p></li>
<li><p>If we have a <em>prediction method</em> (including prediction uncertainty), what properties do we want the method to have and what criteria could we use?</p></li>
<li><p>If we have a <em>method for doing a hypothesis test</em>, what criteria would we use to assess the hypothesis test? What properties do we want the test to have?</p></li>
<li><p>If we have a <em>method for finding a confidence interval or a prediction interval</em>, what criteria would we use to assess the interval?</p></li>
</ul>
<section id="monte-carlo-considerations" class="level1">
<h1>1. Monte Carlo considerations</h1>
<section id="motivating-example" class="level2">
<h2 class="anchored" data-anchor-id="motivating-example">Motivating example</h2>
<p>Let’s consider linear regression, with observations <span class="math inline">\(Y=(y_{1},y_{2},\ldots,y_{n})\)</span> and an <span class="math inline">\(n\times p\)</span> matrix of predictors/covariates/features/variables <span class="math inline">\(X\)</span>, where <span class="math inline">\(\hat{\beta}=(X^{\top}X)^{-1}X^{\top}Y\)</span>. If we assume that we have <span class="math inline">\(EY=X\beta\)</span> and <span class="math inline">\(\mbox{Var}(Y)=\sigma^{2}I\)</span>, then we can determine analytically that we have <span class="math display">\[\begin{aligned}
E\hat{\beta} &amp; = &amp; \beta\\
\mbox{Var}(\hat{\beta})=E((\hat{\beta}-E\hat{\beta})^{2}) &amp; = &amp; \sigma^{2}(X^{\top}X)^{-1}\\
\mbox{MSPE}(Y^{*})=E(Y^{*}-\hat{Y})^{2}) &amp; = &amp; \sigma^{2}(1+X^{*\top}(X^{\top}X)^{-1}X^{*}).\end{aligned}\]</span> where <span class="math inline">\(Y^{*}\)</span>is some new observation we’d like to predict given <span class="math inline">\(X^{*}\)</span>.</p>
<p>But suppose that we’re interested in the properties of standard regression estimation when in reality the mean is not linear in <span class="math inline">\(X\)</span> or the properties of the errors are more complicated than having independent homoscedastic errors. (This is always the case, but the issue is how far from the truth the standard assumptions are.) Or suppose we have a modified procedure to produce <span class="math inline">\(\hat{\beta}\)</span>, such as a procedure that is robust to outliers. In those cases, we cannot compute the expectations above analytically.</p>
<p>Instead we decide to use a Monte Carlo estimate. To keep the notation more simple, let’s just consider one element of the vector <span class="math inline">\(\beta\)</span> (i.e., one of the regression coefficients) and continue to call that <span class="math inline">\(\beta\)</span>. If we randomly generate <span class="math inline">\(m\)</span> different datasets from some distribution <span class="math inline">\(f\)</span>, and <span class="math inline">\(\hat{\beta}_{i}\)</span> is the estimated coefficient based on the <span class="math inline">\(i\)</span>th dataset: <span class="math inline">\(Y_{i}=(y_{i1},y_{i2},\ldots,y_{in})\)</span>, then we can estimate <span class="math inline">\(E\hat{\beta}\)</span> under that distribution <span class="math inline">\(f\)</span> as <span class="math display">\[\widehat{E(\hat{\beta})}=\bar{\hat{\beta}}=\frac{1}{m}\sum_{i=1}^{m}\hat{\beta}_{i}\]</span> Or to estimate the variance, we have <span class="math display">\[\widehat{\mbox{Var}(\hat{\beta})}=\frac{1}{m}\sum_{i=1}^{m}(\hat{\beta}_{i}-\bar{\hat{\beta}})^{2}.\]</span> In evaluating the performance of regression under non-standard conditions or the performance of our robust regression procedure, what decisions do we have to make to be able to carry out our Monte Carlo procedure?</p>
<p>Next let’s think about Monte Carlo methods in general.</p>
</section>
<section id="monte-carlo-mc-basics" class="level2">
<h2 class="anchored" data-anchor-id="monte-carlo-mc-basics">Monte Carlo (MC) basics</h2>
<section id="monte-carlo-overview" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-overview">Monte Carlo overview</h3>
<p>The basic idea is that we often want to estimate <span class="math inline">\(\phi\equiv E_{f}(h(Y))\)</span> for <span class="math inline">\(Y\sim f\)</span>. Note that if <span class="math inline">\(h\)</span> is an indicator function, this includes estimation of probabilities, e.g., for a scalar <span class="math inline">\(Y\)</span>, we have <span class="math inline">\(p=P(Y\leq y)=F(y)=\int_{-\infty}^{y}f(t)dt=\int I(t\leq y)f(t)dt=E_{f}(I(Y\leq y))\)</span>. We would estimate variances or MSEs by having <span class="math inline">\(h\)</span> involve squared terms.</p>
<p>We get an MC estimate of <span class="math inline">\(\phi\)</span> based on an iid sample of a large number of values of <span class="math inline">\(Y\)</span> from <span class="math inline">\(f\)</span>: <span class="math display">\[\hat{\phi}=\frac{1}{m}\sum_{i=1}^{m}h(Y_{i}),\]</span> which is justified by the Law of Large Numbers: <span class="math display">\[\lim_{m\to\infty}\frac{1}{m}\sum_{i=1}^{m}h(Y_{i})=E_{f}h(Y).\]</span></p>
<p>Note that in most simulation studies, <span class="math inline">\(Y\)</span> is an entire dataset (predictors/covariates), and the “iid sample” means generating <span class="math inline">\(m\)</span> different datasets from <span class="math inline">\(f\)</span>, i.e., <span class="math inline">\(Y_{i}\in\{Y_{1},\ldots,Y_{m}\}\)</span> not <span class="math inline">\(m\)</span> different scalar values. If the dataset has <span class="math inline">\(n\)</span> observations, then <span class="math inline">\(Y_{i}=(Y_{i1},\ldots,Y_{in})\)</span>.</p>
<section id="back-to-the-regression-example" class="level4">
<h4 class="anchored" data-anchor-id="back-to-the-regression-example">Back to the regression example</h4>
<p>Let’s relate that back to our regression example. In that particular case, if we’re interested in whether the regression estimator is biased, we want to know: <span class="math display">\[\phi=E\hat{\beta},\]</span> where <span class="math inline">\(h(Y) = \hat{\beta}(Y)\)</span>. We can use the Monte Carlo estimate of <span class="math inline">\(\phi\)</span>: <span class="math display">\[\hat{\phi}=\frac{1}{m}\sum_{i=1}^{m}h(Y_{i})=\frac{1}{m}\sum_{i=1}^{m}\hat{\beta}_{i}=\widehat{E(\hat{\beta})}.\]</span></p>
<p>If we are interested in the variance of the regression estimator, we have</p>
<p><span class="math display">\[\phi=\mbox{Var}(\hat{\beta})=E_{f}((\hat{\beta}-E\hat{\beta})^{2})\]</span> and we can use the Monte Carlo estimate of <span class="math inline">\(\phi\)</span>: <span class="math display">\[\hat{\phi}=\frac{1}{m}\sum_{i=1}^{m}h(Y_{i})=\frac{1}{m}\sum_{i=1}^{m}(\hat{\beta}_{i}-E\hat{\beta})^{2}=\widehat{\mbox{Var}(\hat{\beta)}}\]</span> where <span class="math display">\[h(Y)=(\hat{\beta}-E\hat{\beta})^{2}.\]</span></p>
<p>Finally note that we also need to use the Monte Carlo estimate of <span class="math inline">\(E\hat{\beta}\)</span> in the Monte Carlo estimation of the variance.</p>
<p>We might also be interested in the coverage of a confidence interval. In that case we have <span class="math display">\[h(Y)=1_{\beta\in CI(Y)}\]</span> and we can estimate the coverage as <span class="math display">\[\hat{\phi}=\frac{1}{m}\sum_{i=1}^{m}1_{\beta\in CI(y_{i})}.\]</span> Of course we want that <span class="math inline">\(\hat{\phi}\approx1-\alpha\)</span> for a <span class="math inline">\(100(1-\alpha)\)</span> confidence interval. In the standard case of a 95% interval we want <span class="math inline">\(\hat{\phi}\approx0.95\)</span>.</p>
</section>
</section>
<section id="simulation-uncertainty-i.e.-monte-carlo-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="simulation-uncertainty-i.e.-monte-carlo-uncertainty">Simulation uncertainty (i.e., Monte Carlo uncertainty)</h3>
<p>Since <span class="math inline">\(\hat{\phi}\)</span> is simply an average of <span class="math inline">\(m\)</span> identically-distributed values, <span class="math inline">\(h(Y_{1}),\ldots,h(Y_{m})\)</span>, the simulation variance of <span class="math inline">\(\hat{\phi}\)</span> is <span class="math inline">\(\mbox{Var}(\hat{\phi})=\sigma^{2}/m\)</span>, with <span class="math inline">\(\sigma^{2}=\mbox{Var}(h(Y))\)</span>. An estimator of <span class="math inline">\(\sigma^{2}=E_{f}((h(Y)-\phi)^{2})\)</span> is <span class="math display">\[\begin{aligned}
\hat{\sigma}^{2} &amp; = &amp; \frac{1}{m-1}\sum_{i=1}^{m}(h(Y_{i})-\hat{\phi})^{2}\end{aligned}\]</span> So our MC simulation error is based on <span class="math display">\[\widehat{\mbox{Var}}(\hat{\phi})=\frac{\hat{\sigma}^{2}}{m}=\frac{1}{m(m-1)}\sum_{i=1}^{m}(h(Y_{i})-\hat{\phi})^{2}.\]</span> Note that this is particularly confusing if we have <span class="math inline">\(\hat{\phi}=\widehat{\mbox{Var}(\hat{\beta})}\)</span> because then we have <span class="math inline">\(\widehat{\mbox{Var}}(\hat{\phi})=\widehat{\mbox{Var}}(\widehat{\mbox{Var}(\hat{\beta})})\)</span>!</p>
<p>The simulation variance is <span class="math inline">\(O(\frac{1}{m})\)</span> because we have <span class="math inline">\(m^{2}\)</span> in the denominator and a sum over <span class="math inline">\(m\)</span> terms in the numerator.</p>
<p>Note that in the simulation setting, the randomness in the system is very well-defined (as it is in survey sampling, but unlike in most other applications of statistics), because it comes from the RNG that we perform as part of our attempt to estimate <span class="math inline">\(\phi\)</span>. Happily, we are in control of <span class="math inline">\(m\)</span>, so in principle we can reduce the simulation error to as little as we desire. Unhappily, as usual, the simulation standard error goes down with the square root of <span class="math inline">\(m\)</span>.</p>
<blockquote class="blockquote">
<p><strong>Important</strong>: This is the uncertainty in our simulation-based estimate of some quantity (expectation) of interest. It is NOT the statistical uncertainty in a problem.</p>
</blockquote>
<section id="back-to-the-regression-example-1" class="level4">
<h4 class="anchored" data-anchor-id="back-to-the-regression-example-1">Back to the regression example</h4>
<p>Some examples of simulation variances we might be interested in in the regression example include:</p>
<ul>
<li><p>Uncertainty in our estimate of bias: <span class="math inline">\(\widehat{\mbox{Var}}(\widehat{E(\hat{\beta})}-\beta)\)</span>.</p></li>
<li><p>Uncertainty in the estimated variance of the estimated coefficient: <span class="math inline">\(\widehat{\mbox{Var}}(\widehat{\mbox{Var}(\hat{\beta})})\)</span>.</p></li>
<li><p>Uncertainty in the estimated mean square prediction error: <span class="math inline">\(\widehat{\mbox{Var}}(\widehat{\mbox{MSPE}(Y^{*})})\)</span>.</p></li>
</ul>
<p>In all cases we have to estimate the simulation variance, hence the <span class="math inline">\(\widehat{\mbox{Var}}()\)</span> notation.</p>
</section>
</section>
<section id="final-notes" class="level3">
<h3 class="anchored" data-anchor-id="final-notes">Final notes</h3>
<p>Sometimes the <span class="math inline">\(Y_{i}\)</span> are generated in a dependent fashion (e.g., sequential MC or MCMC), in which case this variance estimator, <span class="math inline">\(\widehat{\mbox{Var}}(\hat{\phi})\)</span> does not hold because the samples are not IID, but the estimator <span class="math inline">\(\hat{\phi}\)</span> is still a valid, unbiased estimator of <span class="math inline">\(\phi\)</span>.</p>
</section>
</section>
<section id="variance-reduction-optional" class="level2">
<h2 class="anchored" data-anchor-id="variance-reduction-optional">Variance reduction (optional)</h2>
<p>There are some tools for variance reduction in MC settings. One is importance sampling (see Section 3). Others are the use of control variates and antithetic sampling. I haven’t personally run across these latter in practice, so I’m not sure how widely used they are and won’t go into them here.</p>
<p>In some cases we can set up natural strata, for which we know the probability of being in each stratum. Then we would estimate <span class="math inline">\(\mu\)</span> for each stratum and combine the estimates based on the probabilities. The intuition is that we remove the variability in sampling amongst the strata from our simulation.</p>
<p>Another strategy that comes up in MCMC contexts is <em>Rao-Blackwellization</em>. Suppose we want to know <span class="math inline">\(E(h(X))\)</span> where <span class="math inline">\(X=\{X_{1},X_{2}\}\)</span>. Iterated expectation tells us that <span class="math inline">\(E(h(X))=E(E(h(X)|X_{2})\)</span>. If we can compute <span class="math inline">\(E(h(X)|X_{2})=\int h(x_{1},x_{2})f(x_{1}|x_{2})dx_{1}\)</span> then we should avoid introducing stochasticity related to the <span class="math inline">\(X_{1}\)</span> draw (since we can analytically integrate over that) and only average over stochasticity from the <span class="math inline">\(X_{2}\)</span> draw by estimating <span class="math inline">\(E_{X_{2}}(E(h(X)|X_{2})\)</span>. The estimator is <span class="math display">\[\hat{\mu}_{RB}=\frac{1}{m}\sum_{i=1}^{m}E(h(X)|X_{2,i})\]</span> where we either draw from the marginal distribution of <span class="math inline">\(X_{2}\)</span>, or equivalently, draw <span class="math inline">\(X\)</span>, but only use <span class="math inline">\(X_{2}\)</span>. Our MC estimator averages over the simulated values of <span class="math inline">\(X_{2}\)</span>. This is called Rao-Blackwellization because it relates to the idea of conditioning on a sufficient statistic. It has lower variance because the variance of each term in the sum of the Rao-Blackwellized estimator is <span class="math inline">\(\mbox{Var}(E(h(X)|X_{2})\)</span>, which is less than the variance in the usual MC estimator, <span class="math inline">\(\mbox{Var}(h(X))\)</span>, based on the usual iterated variance formula: <span class="math inline">\(V(X)=E(V(X|Y))+V(E(X|Y))\Rightarrow V(E(X|Y))&lt;V(X)\)</span>.</p>
</section>
</section>
<section id="design-of-simulation-studies" class="level1">
<h1>2. Design of simulation studies</h1>
<p>Consider the paper that is part of PS5. We can think about designing a simulation study in that context.</p>
<p>First, what are the key issues that need to be assessed to evaluate their methodology?</p>
<p>Second, what do we need to consider in carrying out a simulation study to address those issues? I.e., what are the key decisions to be made in setting up the simulations?</p>
<section id="basic-steps-of-a-simulation-study" class="level2">
<h2 class="anchored" data-anchor-id="basic-steps-of-a-simulation-study">Basic steps of a simulation study</h2>
<ol type="1">
<li><p>Specify what makes up an individual experiment (i.e., the individual simulated dataset) given a specific set of inputs: sample size, distribution(s) to use, parameter values, statistic of interest, etc. In other words, exactly how would you generate one simulated dataset?</p></li>
<li><p>Often you’ll want to see how your results will vary if you change some of the inputs; e.g., sample sizes, parameter values, data generating mechanisms. So determine what factors you’ll want to vary. Each unique combination of input values will be a scenario.</p></li>
<li><p>Write code to carry out the individual experiment and return the quantity of interest, with arguments to your code being the inputs that you want to vary.</p></li>
<li><p>For each combination of inputs you want to explore (each scenario), repeat the experiment <span class="math inline">\(m\)</span> times. Note this is an easily parallel calculation (in both the data generating dimension and the inputs dimension(s)).</p></li>
<li><p>Summarize the results for each scenario, quantifying simulation uncertainty.</p></li>
<li><p>Report the results in graphical or tabular form.</p></li>
</ol>
<p>Often a simulation study will compare multiple methods, so you’ll need to do steps 3-6 for each method.</p>
</section>
<section id="various-considerations" class="level2">
<h2 class="anchored" data-anchor-id="various-considerations">Various considerations</h2>
<p>Since a simulation study is an experiment, we should use the same principles of design and analysis we would recommend when advising a practicioner on setting up a scientific experiment.</p>
<p>These include efficiency, reporting of uncertainty, reproducibility and documentation.</p>
<p>In generating the data for a simulation study, we want to think about what structure real data would have that we want to mimic in the simulation study: distributional assumptions, parameter values, dependence structure, outliers, random effects, sample size (<span class="math inline">\(n\)</span>), etc.</p>
<p>All of these may become input variables in a simulation study. Often we compare two or more statistical methods conditioning on the data context and then assess whether the differences between methods vary with the data context choices. E.g., if we compare an MLE to a robust estimator, which is better under a given set of choices about the data generating mechanism and how sensitive is the comparison to changing the features of the data generating mechanism? So the “treatment variable” is the choice of statistical method. We’re then interested in sensitivity to the conditions (different input values).</p>
<p>Often we can have a large number of replicates (<span class="math inline">\(m\)</span>) because the simulation is fast on a computer, so we can sometimes reduce the simulation error to essentially zero and thereby avoid reporting uncertainty. To do this, we need to calculate the simulation standard error, generally, <span class="math inline">\(s/\sqrt{m}\)</span> and see how it compares to the effect sizes. This is particularly important when reporting on the bias of a statistical method.</p>
<p>We might denote the data, which could be the statistical estimator under each of two methods as <span class="math inline">\(Y_{ijklq}\)</span>, where <span class="math inline">\(q\)</span> indexes treatment, <span class="math inline">\(j,k,l\)</span> index different additional input variables, and <span class="math inline">\(i\in\{1,\ldots,m\}\)</span> indexes the replicate. E.g., <span class="math inline">\(j\)</span> might index whether the data are from a t or normal, <span class="math inline">\(k\)</span> the value of a parameter, and <span class="math inline">\(l\)</span> the dataset sample size (i.e., different levels of <span class="math inline">\(n\)</span>).</p>
<p>One can think about choosing <span class="math inline">\(m\)</span> based on a basic power calculation, though since we can always generate more replicates, one might just proceed sequentially and stop when the precision of the results is sufficient.</p>
<p>When comparing methods, it’s best to use the same simulated datasets for each level of the treatment variable and to do an analysis that controls for the dataset (i.e., for the random numbers used), thereby removing some variability from the error term. A simple example is to do a paired analysis, where we look at differences between the outcome for two statistical methods, pairing based on the simulated dataset.</p>
<p>One can even use the “same” random number generation for the replicates under different conditions. E.g., in assessing sensitivity to a <span class="math inline">\(t\)</span> vs. normal data generating mechanism, we might generate the normal RVs and then for the <span class="math inline">\(t\)</span> use the same random numbers, in the sense of using the same quantiles of the <span class="math inline">\(t\)</span> as were generated for the normal - this is pretty easy, as seen below. This helps to control for random differences between the datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t, norm</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>devs <span class="op">=</span> np.random.normal(size<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>tdevs <span class="op">=</span> t.ppf(norm.cdf(devs), df<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(devs, tdevs)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'devs'</span>)<span class="op">;</span> plt.ylabel(<span class="st">'tdevs'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(devs), <span class="bu">max</span>(devs)], [<span class="bu">min</span>(devs), <span class="bu">max</span>(devs)], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="unit9-sim_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="experimental-design-optional" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design-optional">Experimental Design (optional)</h2>
<p>A typical context is that one wants to know the effect of multiple input variables on some outcome. Often, scientists, and even statisticians doing simulation studies will vary one input variable at a time. As we know from standard experimental design, this is inefficient.</p>
<p>The standard strategy is to discretize the inputs, each into a small number of levels. If we have a small enough number of inputs and of levels, we can do a full factorial design (potentially with replication). For example if we have three inputs and three levels each, we have <span class="math inline">\(3^{3}\)</span> different treatment combinations. Choosing the levels in a reasonable way is obviously important.</p>
<p>As the number of inputs and/or levels increases to the point that we can’t carry out the full factorial, a fractional factorial is an option. This carefully chooses which treatment combinations to omit. The goal is to achieve balance across the levels in a way that allows us to estimate lower level effects (in particular main effects) but not all high-order interactions. What happens is that high-order interactions are aliased to (confounded with) lower-order effects. For example you might choose a fractional factorial design so that you can estimate main effects and two-way interactions but not higher-order interactions.</p>
<p>In interpreting the results, I suggest focusing on the decomposition of sums of squares and not on statistical significance. In most cases, we expect the inputs to have at least some effect on the outcome, so the null hypothesis is a straw man. Better to assess the magnitude of the impacts of the different inputs.</p>
<p>When one has a very large number of inputs, one can use the Latin hypercube approach to sample in the input space in a uniform way, spreading the points out so that each input is sampled uniformly. Assume that each input is <span class="math inline">\(\mathcal{U}(0,1)\)</span> (one can easily transform to whatever marginal distributions you want). Suppose that you can run <span class="math inline">\(m\)</span> samples. Then for each input variable, we divide the unit interval into <span class="math inline">\(m\)</span> bins and randomly choose the order of bins and the position within each bin. This is done independently for each variable and then combined to give <span class="math inline">\(m\)</span> samples from the input space. We would then analyze main effects and perhaps two-way interactions to assess which inputs seem to be most important.</p>
<p>Even amongst statisticians, taking an experimental design approach to a simulation study is not particularly common, but it’s worth considering.</p>
</section>
</section>
<section id="implementation-of-simulation-studies" class="level1">
<h1>3. Implementation of simulation studies</h1>
<p>Luke Miratrix (a UCB Stats PhD alum) has prepared a nice tutorial on carrying out a simulation study, including helpful R code. So if the discussion here is not concrete enough or you want to see how to effectively implement such a study, see <em>simulation_tutorial_miratrix.pdf</em> and the similarly named R code file.</p>
<section id="computational-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="computational-efficiency">Computational efficiency</h2>
<p>Parallel processing is often helpful for simulation studies. The reason is that simulation studies are embarrassingly parallel - we can send each replicate to a different computer processor and then collect the results back, and the speedup should scale directly with the number of processors we used. Since we often need to some sort of looping, writing code in C/C++ and compiling and linking to the code from Python may also be a good strategy, albeit one not covered in this course.</p>
<p>A handy function in Python is <code>itertools.product</code> to get all combinations of a set of vectors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>thetaLevels <span class="op">=</span> [<span class="st">"low"</span>, <span class="st">"med"</span>, <span class="st">"hi"</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>tVsNorm <span class="op">=</span> [<span class="st">"t"</span>, <span class="st">"norm"</span>]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>levels <span class="op">=</span> <span class="bu">list</span>(itertools.product(thetaLevels, tVsNorm, n))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="analysis-and-reporting" class="level2">
<h2 class="anchored" data-anchor-id="analysis-and-reporting">Analysis and reporting</h2>
<p>Often results are reported simply in tables, but it can be helpful to think through whether a graphical representation is more informative (sometimes it’s not or it’s worse, but in some cases it may be much better). Since you’ll often have a variety of scenarios to display, using trellis plots in ggplot2 via the <code>facet_wrap</code> function will often be a good approach to display how results vary as a function of multiple inputs in R. In Python, it looks like there are various ways (<code>RPlot</code> in pandas, seaborn, plotly), but I don’t know what the most standard way is.</p>
<p>You should set the seed when you start the experiment, so that it’s possible to replicate it. It’s also a good idea to save the current value of the seed whenever you save interim results, so that you can restart simulations (this is particularly helpful for MCMC) at the exact point you left off, including the random number sequence.</p>
<p>To enhance reproducibility, it’s good practice to post your simulation code (and potentially simulated data) on GitHub, on your website, or as supplementary material with the journal. Another person should be able to fully reproduce your results, including the exact random number generation that you did (e.g., you should provide code for how you set the random seed for your randon number generator).</p>
<p>Many journals are requiring increasingly detailed documentation of the code and data used in your work, including code and data for simulations. Here are the American Statistical Association’s requirements on documenting computations in its journals:</p>
<p>“The ASA strongly encourages authors to submit datasets, code, other programs, and/or extended appendices that are directly relevant to their submitted articles. These materials are valuable to users of the ASA’s journals and further the profession’s commitment to reproducible research. Whenever a dataset is used, its source should be fully documented and the data should be made available as on online supplement. Exceptions for reasons of security or confidentiality may be granted by the Editor. Whenever specific code has been used to implement or illustrate the results of a paper, that code should be made available if possible. [.…snip.…] Articles reporting results based on computation should provide enough information so that readers can evaluate the quality of the results. Such information includes estimated accuracy of results, as well as descriptions of pseudorandom-number generators, numerical algorithms, programming languages, and major software components used.”</p>
</section>
</section>
<section id="random-number-generation-rng" class="level1">
<h1>4. Random number generation (RNG)</h1>
<p>At the core of simulations is the ability to generate random numbers, and based on that, random variables. On a computer, our goal is to generate sequences of pseudo-random numbers that behave like random numbers but are replicable. The reason that replicability is important is so that we can reproduce the simulation.</p>
<section id="generating-random-uniforms-on-a-computer" class="level2">
<h2 class="anchored" data-anchor-id="generating-random-uniforms-on-a-computer">Generating random uniforms on a computer</h2>
<p>Generating a sequence of random standard uniforms is the basis for all generation of random variables, since random uniforms (either a single one or more than one) can be used to generate values from other distributions. Most random numbers on a computer are <em>pseudo-random</em>. The numbers are chosen from a deterministic stream of numbers that behave like random numbers but are actually a finite sequence (recall that both integers and real numbers on a computer are actually discrete and there are finitely many distinct values), so it’s actually possible to get repeats. The seed of a RNG is the place within that sequence where you start to use the pseudo-random numbers.</p>
<section id="sequential-congruential-generators" class="level3">
<h3 class="anchored" data-anchor-id="sequential-congruential-generators">Sequential congruential generators</h3>
<p>Many RNG methods are sequential congruential methods. The basic idea is that the next value is <span class="math display">\[u_{k}=f(u_{k-1},\ldots,u_{k-j})\mbox{mod}\,m\]</span> for some function, <span class="math inline">\(f\)</span>, and some positive integer <span class="math inline">\(m\)</span> . Often <span class="math inline">\(j=1\)</span>. <em>mod</em> just means to take the remainder after dividing by <span class="math inline">\(m\)</span>. One then generates the random standard uniform value as <span class="math inline">\(u_{k}/m\)</span>, which by construction is in <span class="math inline">\([0,1]\)</span>. For our discussion below, it is important to distinguish the <em>state</em> (<span class="math inline">\(u\)</span>) from the output of the RNG.</p>
<p>Given the construction, such sequences are periodic if the subsequence ever reappears, which is of course guaranteed because there is a finite number of possible subsequence values given that all the <span class="math inline">\(u_{k}\)</span> values are remainders of divisions by a fixed number . One key to a good random number generator (RNG) is to have a very long period.</p>
<p>An example of a sequential congruential method is a basic linear congruential generator: <span class="math display">\[u_{k}=(au_{k-1}+c)\mbox{mod}\,m\]</span> with integer <span class="math inline">\(a\)</span>, <span class="math inline">\(m\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(u_{k}\)</span> values. Here the periodicity can’t exceed <span class="math inline">\(m-1\)</span> (the method is set up so that we never get <span class="math inline">\(u_{k}=0\)</span> as this causes the algorithm to break), so we only have <span class="math inline">\(m-1\)</span> possible values. The seed is the initial state, <span class="math inline">\(u_{0}\)</span> - i.e., the point in the sequence at which we start. By setting the seed you guarantee reproducibility since given a starting value, the sequence is deterministic. In general <span class="math inline">\(a\)</span>, <span class="math inline">\(c\)</span> and <span class="math inline">\(m\)</span> are chosen to be ‘large’. The standard values of <span class="math inline">\(m\)</span> are Mersenne primes, which have the form <span class="math inline">\(2^{p}-1\)</span> (but these are not prime for all <span class="math inline">\(p\)</span>). Here’s an example of a linear congruential sampler (with <span class="math inline">\(c=0\)</span>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="dv">171</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">30269</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.empty(n)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>u[<span class="dv">0</span>] <span class="op">=</span> <span class="dv">7306</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    u[i] <span class="op">=</span> (a <span class="op">*</span> u[i<span class="op">-</span><span class="dv">1</span>]) <span class="op">%</span> m</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> u <span class="op">/</span> m</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>uFromNP <span class="op">=</span> np.random.uniform(size <span class="op">=</span> n)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>), u)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"manual"</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Index"</span>)<span class="op">;</span> plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>), uFromNP)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"numpy"</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Index"</span>)<span class="op">;</span> plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>plt.hist(u, bins<span class="op">=</span><span class="dv">25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(array([6., 3., 6., 4., 1., 4., 6., 3., 4., 9., 4., 5., 1., 1., 2., 7., 1.,
       2., 5., 2., 6., 5., 4., 4., 5.]), array([0.01833559, 0.05743434, 0.09653309, 0.13563183, 0.17473058,
       0.21382933, 0.25292808, 0.29202683, 0.33112557, 0.37022432,
       0.40932307, 0.44842182, 0.48752057, 0.52661931, 0.56571806,
       0.60481681, 0.64391556, 0.68301431, 0.72211305, 0.7612118 ,
       0.80031055, 0.8394093 , 0.87850804, 0.91760679, 0.95670554,
       0.99580429]), &lt;BarContainer object of 25 artists&gt;)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Value"</span>)<span class="op">;</span> plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.hist(uFromNP, bins<span class="op">=</span><span class="dv">25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(array([6., 4., 1., 7., 3., 6., 3., 2., 3., 4., 4., 5., 2., 3., 2., 6., 4.,
       5., 3., 6., 5., 6., 2., 4., 4.]), array([3.68753857e-04, 3.98033276e-02, 7.92379014e-02, 1.18672475e-01,
       1.58107049e-01, 1.97541623e-01, 2.36976197e-01, 2.76410770e-01,
       3.15845344e-01, 3.55279918e-01, 3.94714492e-01, 4.34149065e-01,
       4.73583639e-01, 5.13018213e-01, 5.52452787e-01, 5.91887361e-01,
       6.31321934e-01, 6.70756508e-01, 7.10191082e-01, 7.49625656e-01,
       7.89060230e-01, 8.28494803e-01, 8.67929377e-01, 9.07363951e-01,
       9.46798525e-01, 9.86233098e-01]), &lt;BarContainer object of 25 artists&gt;)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Value"</span>)<span class="op">;</span> plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="unit9-sim_files/figure-html/unnamed-chunk-4-3.png" class="img-fluid" width="960"></p>
</div>
</div>
<p>A wide variety of different RNG have been proposed. Many have turned out to have substantial defects based on tests designed to assess if the behavior of the RNG mimics true randomness. Some of the behavior we want to ensure is uniformity of each individual random deviate, independence of sequences of deviates, and multivariate uniformity of subsequences. One test of a RNG that many RNGs don’t perform well on is to assess the properties of <span class="math inline">\(k\)</span>-tuples - subsequences of length <span class="math inline">\(k\)</span>, which should be independently distributed in the <span class="math inline">\(k\)</span>-dimensional unit hypercube. Unfortunately, linear congruential methods produce values that lie on a simple lattice in <span class="math inline">\(k\)</span>-space, i.e., the points are not selected from <span class="math inline">\(q^{k}\)</span> uniformly spaced points, where <span class="math inline">\(q\)</span> is the the number of unique values. Instead, points often lie on parallel lines in the hypercube.</p>
<p>Combining generators can yield better generators. The Wichmann-Hill is an option in R and is a combination of three linear congruential generators with <span class="math inline">\(a=\{171,172,170\}\)</span>, <span class="math inline">\(m=\{30269,30307,30323\}\)</span>, and <span class="math inline">\(u_{i}=(x_{i}/30269+y_{i}/30307+z_{i}/30323)\mbox{mod}\,1\)</span> where <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>, and <span class="math inline">\(z\)</span> are generated from the three individual generators. Let’s mimic the Wichmann-Hill manually:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">RNGkind</span>(<span class="st">"Wichmann-Hill"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>saveSeed <span class="ot">&lt;-</span> .Random.seed</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>uFromR <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">10</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">171</span>, <span class="dv">172</span>, <span class="dv">170</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">30269</span>, <span class="dv">30307</span>, <span class="dv">30323</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>xyz <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nr =</span> <span class="dv">10</span>, <span class="at">nc =</span> <span class="dv">3</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>xyz[<span class="dv">1</span>, ] <span class="ot">&lt;-</span> (a <span class="sc">*</span> saveSeed[<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>]) <span class="sc">%%</span> m</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    xyz[i, ] <span class="ot">&lt;-</span> (a <span class="sc">*</span> xyz[i<span class="dv">-1</span>, ]) <span class="sc">%%</span> m</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">c</span>(uFromR[i],<span class="fu">sum</span>(xyz[i, ]<span class="sc">/</span>m)<span class="sc">%%</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1297134 0.1297134
[1] 0.9822407 0.9822407
[1] 0.8267184 0.8267184
[1] 0.242355 0.242355
[1] 0.8568853 0.8568853
[1] 0.8408788 0.8408788
[1] 0.3421633 0.3421633
[1] 0.7062672 0.7062672
[1] 0.6212432 0.6212432
[1] 0.6537663 0.6537663</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="do">## we should be able to recover the current value of the seed</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>xyz[<span class="dv">10</span>, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 24279 14851 10966</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>.Random.seed[<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 24279 14851 10966</code></pre>
</div>
</div>
</section>
<section id="modern-generators-pcg-and-mersenne-twister" class="level3">
<h3 class="anchored" data-anchor-id="modern-generators-pcg-and-mersenne-twister">Modern generators (PCG and Mersenne Twister)</h3>
<p>Recently <a href="https://www.pcg-random.org/pdf/hmc-cs-2014-0905.pdf">O’Neal proposed a new approach</a> to using the linear congruential generator in a way that gives much better performance than the basic versions of such generators described above. This approach is now the default random number generator in numpy (see <code>numpy.random.default_rng()</code>), called the <a href="https://numpy.org/doc/stable/reference/random/bit_generators/pcg64.html#numpy.random.PCG64">PCG-64 generator</a>. ‘PCG’ stands for permutation congruential generator and encompasses a family of such generators.</p>
<p>The idea of the PCG approach goes like this:</p>
<ul>
<li>Linear congruential generators (LCG) are simple and fast, but for small values of <span class="math inline">\(m\)</span> don’t perform all that well statistically, in particular having values on a lattice as discussed above.</li>
<li>Using a large value of <span class="math inline">\(m\)</span> can actually give good statistical performance.</li>
<li>Applying a technique called <em>permutation functions</em> to the state of the LCG in order to produce the output at each step (the random value returned to the user) can improve the statistical performance even further.</li>
</ul>
<p>Instead of using relatively small values of <span class="math inline">\(m\)</span> seen above, in the PCG approach one uses <span class="math inline">\(m=2^k\)</span>, for ‘large enough’ <span class="math inline">\(k\)</span>, usually 64 or 128. It turns out that if <span class="math inline">\(m=2^k\)</span> then the period of the <span class="math inline">\(b\)</span>th bit of the state is <span class="math inline">\(2^b\)</span> where <span class="math inline">\(b=1\)</span> is the right-most bit. Small periods are of course bad for RNG, so the bits with small period cause the LCG to not perform well. Thankfully, one simple fix is simply to discard some number of the right-most bits (this is one form of <em>bit shift</em>). Note that if one does this, the output of the RNG is based on a subset of the bits, which means that the number of unique values that can be generated is smaller than the period. This is not a problem given we start with a state with a large number of bits (64 or 128 as mentioned above).</p>
<p>O’Neal then goes further; instead of simply discarding bits, she propose to use some of the initial bits (which behave the most randomly) to either shift bits by a random amount or rotate bits by a random amount. This improves the statistical performance of the generator. The choice of how to do this gives the various members of the PCG family of generators. The details are fairly complicated (the PCG paper is 50-odd pages) and not important for our purposes here.</p>
<p>By default R uses something called the Mersenne twister, which is in the class of generalized feedback shift registers (GFSR). The basic idea of a GFSR is to come up with a deterministic generator of bits (i.e., a way to generate sequences of 0s and 1s), <span class="math inline">\(B_{i}\)</span>, <span class="math inline">\(i=1,2,3,\ldots\)</span>. The pseudo-random numbers are then determined as sequential subsequences of length <span class="math inline">\(L\)</span> from <span class="math inline">\(\{B_{i}\}\)</span>, considered as a base-2 number and dividing by <span class="math inline">\(2^{L}\)</span> to get a number in <span class="math inline">\((0,1)\)</span>. In general the sequence of bits is generated by taking <span class="math inline">\(B_{i}\)</span> to be the <em>exclusive or</em> [i.e., 0+0 = 0; 0 + 1 = 1; 1 + 0 = 1; 1 + 1 = 0] summation of two previous bits further back in the sequence where the lengths of the lags are carefully chosen.</p>
<p>numpy also provides access to the Mersenne Twister via the MT19937 generator; more on this below. It looks like PCG-64 only became available as of numpy version 1.17.</p>
<section id="additional-notes" class="level4">
<h4 class="anchored" data-anchor-id="additional-notes">Additional notes</h4>
<p>Generators should give you the same sequence of random numbers, starting at a given seed, whether you ask for a bunch of numbers at once, or sequentially ask for individual numbers.</p>
<p>When one invokes a RNG without a seed, they generally have a method for choosing a seed, often based on the system clock.</p>
<p>There have been some attempts to generate truly random numbers based on physical randomness. One that is based on quantum physics is <a href="http://www.idquantique.com/true-random-number-generator/quantis-usb-pcie-pci.html" class="uri">http://www.idquantique.com/true-random-number-generator/quantis-usb-pcie-pci.html</a>. Another approach is based on lava lamps!</p>
</section>
</section>
</section>
<section id="rng-in-python" class="level2">
<h2 class="anchored" data-anchor-id="rng-in-python">RNG in Python</h2>
<p>We can change the RNG for numpy using <code>np.random.&lt;name_of_generator&gt;</code> (e.g., <code>np.random.MT19937</code> for the Mersenne Twister). We can set the seed with <code>np.random.seed()</code> or with <code>np.random.default_rng()</code>.</p>
<p>In numpy, the <em>default_rng</em> RNG is PCG-64. It has a period of <span class="math inline">\(2^{128}\)</span> and supports advancing an arbitrary number of steps, as well as <span class="math inline">\(2^{127}\)</span> streams (both useful for generating random numbers when parallelizing). The state of the PCG-64 RNG is represented by two 128-bit unsigned integers, one the actual state and one the value of <span class="math inline">\(c\)</span> (the <em>increment</em>).</p>
<p>Strangely, while the <em>default</em> is PCG-64, simply using the functions available via <code>np.random</code> to generate random numbers seems to actually use the Mersenne Twister, so the meaning of <em>default</em> is unclear.</p>
<p>In R, the default RNG is the Mersenne twister (<code>?RNGkind</code>), which is considered to be state-of-the-art (by some; O’Neal criticizes it). It has some theoretical support, has performed reasonably on standard tests of pseudorandom numbers and has been used without evidence of serious failure. Plus it’s fast (because bitwise operations are fast). The particular Mersenne twister used has a periodicity of <span class="math inline">\(2^{19937}-1\approx10^{6000}\)</span>. Practically speaking this means that if we generated one random uniform per nanosecond for 10 billion years, then we would generate <span class="math inline">\(10^{25}\)</span> numbers, well short of the period. So we don’t need to worry about the periodicity! The seed for the Mersenne twister is a set of 624 32-bit integers plus a position in the set, where the position is <code>.Random.seed[2]</code>.</p>
<p>For the Mersenne Twister, we can set the seed by passing an integer to <code>np.random.seed()</code> in Python or <code>set.seed()</code> in R, which then sets as many actual seeds as required for the Mersenne Twister. Here I’ll refer to the single integer passed in as <em>the</em> seed. Ideally, nearby seeds generally should not correspond to getting sequences from the stream that are closer to each other than far away seeds. According to Gentle (CS, p.&nbsp;327) the input to <code>set.seed()</code> in R should be an integer, <span class="math inline">\(i\in\{0,\ldots,1023\}\)</span> , and each of these 1024 values produces positions in the RNG sequence that are “far away” from each other. I don’t see any mention of this in the R documentation for <code>set.seed()</code> and furthermore, you can pass integers larger than 1023 to <code>set.seed()</code>, so I’m not sure how much to trust Gentle’s claim. More on generating parallel streams of random numbers below.</p>
<p>So we get replicability by setting the seed to a specific value at the beginning of our simulation. We can then set the seed to that same value when we want to replicate the simulation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>np.random.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>np.random.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])</code></pre>
</div>
</div>
<p>We can also save the state of the RNG and pick up where we left off. So this code will pick where you had left off, ignoring what happened in between saving to <code>saved_state</code> and resetting.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>np.random.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>saved_state <span class="op">=</span> np.random.get_state()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>np.random.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([-2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038])</code></pre>
</div>
</div>
<p>Now we’ll do some arbitrary work with random numbers, and see that if we use the saved state we can pick up where we left off above.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>tmp <span class="op">=</span> np.random.choice(np.arange(<span class="dv">1</span>, <span class="dv">51</span>), size<span class="op">=</span><span class="dv">2000</span>, replace<span class="op">=</span><span class="va">True</span>) <span class="co"># arbitrary work</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Restore the state.</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>np.random.set_state(saved_state)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>np.random.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([-2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038])</code></pre>
</div>
</div>
<p>If we look at <code>saved_state</code>, we see it actually corresponds to the Mersenne Twister.</p>
<p>To do the equivalent with the PCG-64:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">1</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>rng.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 0.34558419,  0.82161814,  0.33043708, -1.30315723,  0.90535587])</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>saved_state <span class="op">=</span> rng.bit_generator.state</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>rng.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 0.44637457, -0.53695324,  0.5811181 ,  0.3645724 ,  0.2941325 ])</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>tmp <span class="op">=</span> rng.choice(np.arange(<span class="dv">1</span>, <span class="dv">51</span>), size<span class="op">=</span><span class="dv">2000</span>, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>rng.bit_generator.state <span class="op">=</span> saved_state</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>rng.normal(size <span class="op">=</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 0.44637457, -0.53695324,  0.5811181 ,  0.3645724 ,  0.2941325 ])</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>saved_state</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'bit_generator': 'PCG64', 'state': {'state': 216676376075457487203159048251690499413, 'inc': 194290289479364712180083596243593368443}, 'has_uint32': 0, 'uinteger': 0}</code></pre>
</div>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>saved_state[<span class="st">'state'</span>][<span class="st">'state'</span>]   <span class="co"># actual state</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>216676376075457487203159048251690499413</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>saved_state[<span class="st">'state'</span>][<span class="st">'inc'</span>]     <span class="co"># increment ('c')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>194290289479364712180083596243593368443</code></pre>
</div>
</div>
<p><code>saved_state</code> contains the actual state and the value of <code>c</code>, the increment.</p>
<p>The output of the PCG-64 is 64 bits while for the Mersenne Twister the output is 32 bits. This means you could get duplicated values in long runs, but this does not violate the comment about the periodicity of PCG-64 and Mersenne-Twister being longer than <span class="math inline">\(2^64\)</span> and <span class="math inline">\(2^32\)</span>, because the two values after the two duplicated numbers will not be duplicates of each other – as noted previously, there is a distinction between the output presented to the user and the state of the RNG algorithm.</p>
</section>
<section id="rng-in-parallel" class="level2">
<h2 class="anchored" data-anchor-id="rng-in-parallel">RNG in parallel</h2>
<p>We can generally rely on the RNG in Python and R to give a reasonable set of values. One time when we want to think harder is when doing work with RNG in parallel on multiple processors. The worst thing that could happen is that one sets things up in such a way that every process is using the same sequence of random numbers. This could happen if you mistakenly set the same seed in each process, e.g., using <code>np.random.seed(1)</code> on every process. More details on parallel RNG are given in Unit 6.</p>
</section>
</section>
<section id="generating-random-variables" class="level1">
<h1>5. Generating random variables</h1>
<p>There are a variety of methods for generating from common distributions (normal, gamma, beta, Poisson, t, etc.). Since these tend to be built into Python and R and presumably use good algorithms, we won’t go into them. A variety of statistical computing and Monte Carlo books describe the various methods. Many are built on the relationships between different distributions - e.g., a beta random variable (RV) can be generated from two gamma RVs.</p>
<section id="multivariate-distributions" class="level2">
<h2 class="anchored" data-anchor-id="multivariate-distributions">Multivariate distributions</h2>
<p>The <em>mvtnorm</em> package supplies code for working with the density and CDF of multivariate normal and t distributions.</p>
<p>To generate a multivariate normal, in Unit 10, we’ll see the standard method based on the Cholesky decomposition:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> np.linalg.cholesky(covMat) <span class="co"># L is lower-triangular</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> L <span class="op">@</span> np.random.normal(size <span class="op">=</span> covMat.shape[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Side note: for a singular covariance matrix we can use the Cholesky with pivoting, setting as many rows to zero as the rank deficiency. Then when we generate the multivariate normals, they respect the constraints implicit in the rank deficiency. However, you’ll need to reorder the resulting vector because of the reordering involved in the pivoted Cholesky.</p>
</section>
<section id="inverse-cdf" class="level2">
<h2 class="anchored" data-anchor-id="inverse-cdf">Inverse CDF</h2>
<p>Most of you know the inverse CDF method. To generate <span class="math inline">\(X\sim F\)</span> where <span class="math inline">\(F\)</span> is a CDF and is an invertible function, first generate <span class="math inline">\(Z\sim\mathcal{U}(0,1)\)</span>, then <span class="math inline">\(x=F^{-1}(z)\)</span>. For discrete CDFs, one can work with a discretized version. For multivariate distributions, one can work with a univariate marginal and then a sequence of univariate conditionals: <span class="math inline">\(f(x_{1})f(x_{2}|x_{1})\cdots f(x_{k}|x_{k-1},\ldots,x_{1})\)</span>, when the distribution allows this analytic decomposition.</p>
</section>
<section id="rejection-sampling" class="level2">
<h2 class="anchored" data-anchor-id="rejection-sampling">Rejection sampling</h2>
<p>The basic idea of rejection sampling (RS) relies on the introduction of an auxiliary variable, <span class="math inline">\(u\)</span>. Suppose <span class="math inline">\(X\sim F\)</span>. Then we can write <span class="math inline">\(f(x)=\int_{0}^{f(x)}du\)</span>. Thus <span class="math inline">\(f\)</span> is the marginal density of <span class="math inline">\(X\)</span> in the joint density, <span class="math inline">\((X,U)\sim\mathcal{U}\{(x,u):0&lt;u&lt;f(x)\}\)</span>. Now we’d like to use this in a way that relies only on evaluating <span class="math inline">\(f(x)\)</span> without having to draw from <span class="math inline">\(f\)</span>.</p>
<p>To implement this we draw from a larger set and then only keep draws for which <span class="math inline">\(u&lt;f(x)\)</span>. We choose a density, <span class="math inline">\(g\)</span>, that is easy to draw from and that can <em>majorize</em> <span class="math inline">\(f\)</span>, which means there exists a constant <span class="math inline">\(c\)</span> s.t. , <span class="math inline">\(cg(x)\geq f(x)\)</span> <span class="math inline">\(\forall x\)</span>. In other words we have that <span class="math inline">\(cg(x)\)</span> is an upper envelope for <span class="math inline">\(f(x)\)</span>. The algorithm is</p>
<ol type="1">
<li>generate <span class="math inline">\(x\sim g\)</span></li>
<li>generate <span class="math inline">\(u\sim\mathcal{U}(0,1)\)</span></li>
<li>if <span class="math inline">\(u\leq f(x)/cg(x)\)</span> then use <span class="math inline">\(x\)</span>; otherwise go back to step 1</li>
</ol>
<p>The intuition here is graphical: we generate from under a curve that is always above <span class="math inline">\(f(x)\)</span> and accept only when <span class="math inline">\(u\)</span> puts us under <span class="math inline">\(f(x)\)</span> relative to the majorizing density. A key here is that the majorizing density have fatter tails than the density of interest, so that the constant <span class="math inline">\(c\)</span> can exist. So we could use a <span class="math inline">\(t\)</span> to generate from a normal but not the reverse. We’d like <span class="math inline">\(c\)</span> to be small to reduce the number of rejections because it turns out that <span class="math inline">\(\frac{1}{c}=\frac{\int f(x)dx}{\int cg(x)dx}\)</span> is the acceptance probability. This approach works in principle for multivariate densities but as the dimension increases, the proportion of rejections grows, because more of the volume under <span class="math inline">\(cg(x)\)</span> is above <span class="math inline">\(f(x)\)</span>.</p>
<p>If <span class="math inline">\(f\)</span> is costly to evaluate, we can sometimes reduce calculation using a lower bound on <span class="math inline">\(f\)</span>. In this case we accept if <span class="math inline">\(u\leq f_{\mbox{low}}(y)/cg_{Y}(y)\)</span>. If it is not, then we need to evaluate the ratio in the usual rejection sampling algorithm. This is called squeezing.</p>
<p>One example of RS is to sample from a truncated normal. Of course we can just sample from the normal and then reject, but this can be inefficient, particularly if the truncation is far in the tail (a case in which inverse CDF suffers from numerical difficulties). Suppose the truncation point is greater than zero. Working with the standardized version of the normal, you can use an translated exponential with lower end point equal to the truncation point as the majorizing density (Robert 1995; Statistics and Computing, and see calculations in the demo code). For truncation less than zero, just make the values negative.</p>
</section>
<section id="adaptive-rejection-sampling-optional" class="level2">
<h2 class="anchored" data-anchor-id="adaptive-rejection-sampling-optional">Adaptive rejection sampling (optional)</h2>
<p>The difficulty of RS is finding a good enveloping function. Adaptive rejection sampling refines the envelope as the draws occur, in the case of a continuous, differentiable, log-concave density. The basic idea considers the log of the density and involves using tangents or secants to define an upper envelope and secants to define a lower envelope for a set of points in the support of the distribution. The result is that we have piecewise exponentials (since we are exponentiating from straight lines on the log scale) as the bounds. We can sample from the upper envelope based on sampling from a discrete distribution and then the appropriate exponential. The lower envelope is used for squeezing. We add points to the set that defines the envelopes whenever we accept a point that requires us to evaluate <span class="math inline">\(f(x)\)</span> (the points that are accepted based on squeezing are not added to the set).</p>
</section>
<section id="importance-sampling" class="level2">
<h2 class="anchored" data-anchor-id="importance-sampling">Importance sampling</h2>
<p>Importance sampling (IS) allows us to estimate expected values, with some commonalities with rejection sampling.</p>
<p><span class="math display">\[\phi=E_{f}(h(X))=\int h(x)\frac{f(x)}{g(x)}g(x)dx\]</span> so <span class="math inline">\(\hat{\phi}=\frac{1}{m}\sum_{i}h(x_{i})\frac{f(x_{i})}{g(x_{i})}\)</span> for <span class="math inline">\(x_{i}\)</span> drawn from <span class="math inline">\(g(x)\)</span>, where <span class="math inline">\(w_{i}=f(x_{i})/g(x_{i})\)</span> act as weights. (Often in Bayesian contexts, we know <span class="math inline">\(f(x)\)</span> only up to a normalizing constant. In this case we need to use <span class="math inline">\(w_{i}^{*}=w_{i}/\sum_{j}w_{j}\)</span>.</p>
<p>Here we don’t require the majorizing property, just that the densities have common support, but things can be badly behaved if we sample from a density with lighter tails than the density of interest. So in general we want <span class="math inline">\(g\)</span> to have heavier tails. More specifically for a low variance estimator of <span class="math inline">\(\phi\)</span>, we would want that <span class="math inline">\(f(x_{i})/g(x_{i})\)</span> is large only when <span class="math inline">\(h(x_{i})\)</span> is very small, to avoid having overly influential points.</p>
<p>This suggests we can reduce variance in an IS context by oversampling <span class="math inline">\(x\)</span> for which <span class="math inline">\(h(x)\)</span> is large and undersampling when it is small, since <span class="math inline">\(\mbox{Var}(\hat{\phi})=\frac{1}{m}\mbox{Var}(h(X)\frac{f(X)}{g(X)})\)</span>. An example is that if <span class="math inline">\(h\)</span> is an indicator function that is 1 only for rare events, we should oversample rare events and then the IS estimator corrects for the oversampling.</p>
<p>What if we actually want a sample from <span class="math inline">\(f\)</span> as opposed to estimating the expected value above? We can draw <span class="math inline">\(x\)</span> from the unweighted sample, <span class="math inline">\(\{x_{i}\}\)</span>, with weights <span class="math inline">\(\{w_{i}\}\)</span>. This is called sampling importance resampling (SIR).</p>
</section>
<section id="ratio-of-uniforms-optional" class="level2">
<h2 class="anchored" data-anchor-id="ratio-of-uniforms-optional">Ratio of uniforms (optional)</h2>
<p>If <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are uniform in <span class="math inline">\(C=\{(u,v):\,0\leq u\leq\sqrt{f(v/u)}\)</span> then <span class="math inline">\(X=V/U\)</span> has density proportion to <span class="math inline">\(f\)</span>. The basic algorithm is to choose a rectangle that encloses <span class="math inline">\(C\)</span> and sample until we find <span class="math inline">\(u\leq f(v/u)\)</span>. Then we use <span class="math inline">\(x=v/u\)</span> as our RV. The larger region enclosing <span class="math inline">\(C\)</span> is the majorizing region and a simple approach (if <span class="math inline">\(f(x)\)</span>and <span class="math inline">\(x^{2}f(x)\)</span> are bounded in <span class="math inline">\(C\)</span>) is to choose the rectangle, <span class="math inline">\(0\leq u\leq\sup_{x}\sqrt{f(x)}\)</span>, <span class="math inline">\(\inf_{x}x\sqrt{f(x)}\leq v\leq\sup_{x}x\sqrt{f(x)}\)</span>.</p>
<p>One can also consider truncating the rectangular region, depending on the features of <span class="math inline">\(f\)</span>.</p>
<p>Monahan recommends the ratio of uniforms, particularly a version for discrete distributions (p.&nbsp;323 of the 2nd edition).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../units/unit8-numbers.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Unit 8 (Precision)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../units/unit10-linalg.html" class="pagination-link">
        <span class="nav-page-text">Unit 10 (Linear Algebra)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>