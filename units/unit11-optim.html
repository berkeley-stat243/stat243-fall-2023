<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris Paciorek">
<meta name="dcterms.date" content="2023-11-03">

<title>Statistics 243 Fall 2023 - Optimization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../units/unit10-linalg.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Statistics 243 Fall 2023</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../office_hours.html" rel="" target="">
 <span class="menu-text">Office hours</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../schedule.html" rel="" target="">
 <span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-units" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Units</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-units">    
        <li>
    <a class="dropdown-item" href="../units/unit1-intro.html" rel="" target="">
 <span class="dropdown-text">Unit 1 (UNIX intro)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit2-dataTech.html" rel="" target="">
 <span class="dropdown-text">Unit 2 (Data technologies)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit3-bash.html" rel="" target="">
 <span class="dropdown-text">Unit 3 (Bash shell)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit4-goodPractices.html" rel="" target="">
 <span class="dropdown-text">Unit 4 (Good practices)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit5-programming.html" rel="" target="">
 <span class="dropdown-text">Unit 5 (Programming)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit6-parallel.html" rel="" target="">
 <span class="dropdown-text">Unit 6 (Parallelization)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit7-bigData.html" rel="" target="">
 <span class="dropdown-text">Unit 7 (Databases)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit8-numbers.html" rel="" target="">
 <span class="dropdown-text">Unit 8 (Precision)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit9-sim.html" rel="" target="">
 <span class="dropdown-text">Unit 9 (Simulation)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit10-linalg.html" rel="" target="">
 <span class="dropdown-text">Unit 10 (Linear Algebra)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../units/unit11-optim.html" rel="" target="">
 <span class="dropdown-text">Unit 11 (Optimization)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-labs" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Labs</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-labs">    
        <li>
    <a class="dropdown-item" href="../labs/lab0-setup.html" rel="" target="">
 <span class="dropdown-text">Lab 0: Setup</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab1-submission.html" rel="" target="">
 <span class="dropdown-text">Lab 1: Problem set submission</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab2-testing.html" rel="" target="">
 <span class="dropdown-text">Lab 2: Assertions, Exceptions, and Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab3-debugging.html" rel="" target="">
 <span class="dropdown-text">Lab 3: Debugging</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/lab5-codereview.html" rel="" target="">
 <span class="dropdown-text">Lab 5: Code Reviews</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/06/scf.html" rel="" target="">
 <span class="dropdown-text">Lab 6: SCF and Parallel Computing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/py_vs_R.html" rel="" target="">
 <span class="dropdown-text">Lab 7: R vs.&nbsp;Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../labs/09/collab_with_git.html" rel="" target="">
 <span class="dropdown-text">Lab 9: Collaboration with Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-how-tos" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">How tos</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-how-tos">    
        <li>
    <a class="dropdown-item" href="../howtos/accessingPython.html" rel="" target="">
 <span class="dropdown-text">Accessing Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/accessingUnixCommandLine.html" rel="" target="">
 <span class="dropdown-text">Accessing the Unix Command Line</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/gitInstall.html" rel="" target="">
 <span class="dropdown-text">Installing Git</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/quartoInstall.html" rel="" target="">
 <span class="dropdown-text">Installing Quarto</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../howtos/ps-submission.html" rel="" target="">
 <span class="dropdown-text">Problem Set Submissions</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Windows</li>
        <li>
    <a class="dropdown-item" href="../howtos/windowsAndLinux.html" rel="" target="">
 <span class="dropdown-text">Installing the Linux Subsystem on Windows</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://edstem.org/us/courses/42474/discussion/" rel="" target="">
 <span class="menu-text">Discussion</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://statistics.berkeley.edu/computing/training/tutorials" rel="" target="">
 <span class="menu-text">Tutorials</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/berkeley-stat243/stat243-fall-2023" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../units/unit11-optim.html">Unit 11 (Optimization)</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit1-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 1 (UNIX intro)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit2-dataTech.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 2 (Data technologies)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit3-bash.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 3 (Bash shell)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit4-goodPractices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 4 (Good practices)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit5-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 5 (Programming)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit6-parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 6 (Parallelization)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit7-bigData.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 7 (Databases)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit8-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 8 (Precision)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit9-sim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 9 (Simulation)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit10-linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 10 (Linear Algebra)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../units/unit11-optim.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Unit 11 (Optimization)</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#notation" id="toc-notation" class="nav-link active" data-scroll-target="#notation">1. Notation</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">2. Overview</a></li>
  <li><a href="#univariate-function-optimization" id="toc-univariate-function-optimization" class="nav-link" data-scroll-target="#univariate-function-optimization">3. Univariate function optimization</a>
  <ul class="collapse">
  <li><a href="#golden-section-search" id="toc-golden-section-search" class="nav-link" data-scroll-target="#golden-section-search">Golden section search</a></li>
  <li><a href="#bisection-method" id="toc-bisection-method" class="nav-link" data-scroll-target="#bisection-method">Bisection method</a></li>
  <li><a href="#newton-raphson-newtons-method" id="toc-newton-raphson-newtons-method" class="nav-link" data-scroll-target="#newton-raphson-newtons-method">Newton-Raphson (Newton’s method)</a>
  <ul class="collapse">
  <li><a href="#overview-1" id="toc-overview-1" class="nav-link" data-scroll-target="#overview-1">Overview</a></li>
  <li><a href="#secant-method-variation-on-n-r" id="toc-secant-method-variation-on-n-r" class="nav-link" data-scroll-target="#secant-method-variation-on-n-r">Secant method variation on N-R</a></li>
  <li><a href="#how-can-newtons-method-go-wrong" id="toc-how-can-newtons-method-go-wrong" class="nav-link" data-scroll-target="#how-can-newtons-method-go-wrong">How can Newton’s method go wrong?</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#convergence-ideas" id="toc-convergence-ideas" class="nav-link" data-scroll-target="#convergence-ideas">4. Convergence ideas</a>
  <ul class="collapse">
  <li><a href="#convergence-metrics" id="toc-convergence-metrics" class="nav-link" data-scroll-target="#convergence-metrics">Convergence metrics</a></li>
  <li><a href="#starting-values" id="toc-starting-values" class="nav-link" data-scroll-target="#starting-values">Starting values</a></li>
  <li><a href="#convergence-rates" id="toc-convergence-rates" class="nav-link" data-scroll-target="#convergence-rates">Convergence rates</a></li>
  </ul></li>
  <li><a href="#multivariate-optimization" id="toc-multivariate-optimization" class="nav-link" data-scroll-target="#multivariate-optimization">5. Multivariate optimization</a>
  <ul class="collapse">
  <li><a href="#profiling" id="toc-profiling" class="nav-link" data-scroll-target="#profiling">Profiling</a></li>
  <li><a href="#newton-raphson-newtons-method-1" id="toc-newton-raphson-newtons-method-1" class="nav-link" data-scroll-target="#newton-raphson-newtons-method-1">Newton-Raphson (Newton’s method)</a></li>
  <li><a href="#fisher-scoring-variant-on-n-r-optional" id="toc-fisher-scoring-variant-on-n-r-optional" class="nav-link" data-scroll-target="#fisher-scoring-variant-on-n-r-optional">Fisher scoring variant on N-R (optional)</a></li>
  <li><a href="#irls-iwls-for-generalized-linear-models-glms" id="toc-irls-iwls-for-generalized-linear-models-glms" class="nav-link" data-scroll-target="#irls-iwls-for-generalized-linear-models-glms">IRLS (IWLS) for Generalized Linear Models (GLMs)</a></li>
  <li><a href="#descent-methods-and-newton-like-methods" id="toc-descent-methods-and-newton-like-methods" class="nav-link" data-scroll-target="#descent-methods-and-newton-like-methods">Descent methods and Newton-like methods</a>
  <ul class="collapse">
  <li><a href="#descent-methods" id="toc-descent-methods" class="nav-link" data-scroll-target="#descent-methods">Descent methods</a></li>
  <li><a href="#quasi-newton-methods-such-as-bfgs" id="toc-quasi-newton-methods-such-as-bfgs" class="nav-link" data-scroll-target="#quasi-newton-methods-such-as-bfgs">Quasi-Newton methods such as BFGS</a></li>
  <li><a href="#stochastic-gradient-descent" id="toc-stochastic-gradient-descent" class="nav-link" data-scroll-target="#stochastic-gradient-descent">Stochastic gradient descent</a></li>
  </ul></li>
  <li><a href="#coordinate-descent-gauss-seidel" id="toc-coordinate-descent-gauss-seidel" class="nav-link" data-scroll-target="#coordinate-descent-gauss-seidel">Coordinate descent (Gauss-Seidel)</a></li>
  <li><a href="#nelder-mead" id="toc-nelder-mead" class="nav-link" data-scroll-target="#nelder-mead">Nelder-Mead</a></li>
  <li><a href="#simulated-annealing-sa-optional" id="toc-simulated-annealing-sa-optional" class="nav-link" data-scroll-target="#simulated-annealing-sa-optional">Simulated annealing (SA) (optional)</a></li>
  </ul></li>
  <li><a href="#basic-optimization-in-python" id="toc-basic-optimization-in-python" class="nav-link" data-scroll-target="#basic-optimization-in-python">6. Basic optimization in Python</a>
  <ul class="collapse">
  <li><a href="#core-optimization-functions" id="toc-core-optimization-functions" class="nav-link" data-scroll-target="#core-optimization-functions">Core optimization functions</a></li>
  <li><a href="#various-considerations-in-using-the-python-functions" id="toc-various-considerations-in-using-the-python-functions" class="nav-link" data-scroll-target="#various-considerations-in-using-the-python-functions">Various considerations in using the Python functions</a></li>
  </ul></li>
  <li><a href="#combinatorial-optimization-over-discrete-spaces" id="toc-combinatorial-optimization-over-discrete-spaces" class="nav-link" data-scroll-target="#combinatorial-optimization-over-discrete-spaces">7. Combinatorial optimization over discrete spaces</a></li>
  <li><a href="#convexity" id="toc-convexity" class="nav-link" data-scroll-target="#convexity">8. Convexity</a>
  <ul class="collapse">
  <li><a href="#mm-algorithm" id="toc-mm-algorithm" class="nav-link" data-scroll-target="#mm-algorithm">MM algorithm</a></li>
  <li><a href="#expectation-maximization-em" id="toc-expectation-maximization-em" class="nav-link" data-scroll-target="#expectation-maximization-em">Expectation-Maximization (EM)</a></li>
  </ul></li>
  <li><a href="#optimization-under-constraints" id="toc-optimization-under-constraints" class="nav-link" data-scroll-target="#optimization-under-constraints">9. Optimization under constraints</a>
  <ul class="collapse">
  <li><a href="#convex-optimization-convex-programming" id="toc-convex-optimization-convex-programming" class="nav-link" data-scroll-target="#convex-optimization-convex-programming">Convex optimization (convex programming)</a></li>
  <li><a href="#linear-programming-linear-system-linear-constraints" id="toc-linear-programming-linear-system-linear-constraints" class="nav-link" data-scroll-target="#linear-programming-linear-system-linear-constraints">Linear programming: Linear system, linear constraints</a></li>
  <li><a href="#general-system-equality-constraints" id="toc-general-system-equality-constraints" class="nav-link" data-scroll-target="#general-system-equality-constraints">General system, equality constraints</a></li>
  <li><a href="#the-dual-problem-optional" id="toc-the-dual-problem-optional" class="nav-link" data-scroll-target="#the-dual-problem-optional">The dual problem (optional)</a></li>
  <li><a href="#kkt-conditions-optional" id="toc-kkt-conditions-optional" class="nav-link" data-scroll-target="#kkt-conditions-optional">KKT conditions (optional)</a></li>
  <li><a href="#interior-point-methods" id="toc-interior-point-methods" class="nav-link" data-scroll-target="#interior-point-methods">Interior-point methods</a></li>
  <li><a href="#software-for-constrained-and-convex-optimization" id="toc-software-for-constrained-and-convex-optimization" class="nav-link" data-scroll-target="#software-for-constrained-and-convex-optimization">Software for constrained and convex optimization</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">10. Summary</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="unit11-optim.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Optimization</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chris Paciorek </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 3, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><a href="./unit11-optim.pdf" class="btn btn-primary">PDF</a></p>
<p>References:</p>
<ul>
<li>Gentle: <em>Computational Statistics</em></li>
<li>Lange: <em>Optimization</em></li>
<li>Monahan: <em>Numerical Methods of Statistics</em></li>
<li>Givens and Hoeting: <em>Computational Statistics</em></li>
<li>Materials online from Stanford’s <a href="http://www.stanford.edu/class/ee364a/lectures.html">EE364a course</a> on convex optimization, including <a href="https://web.stanford.edu/~boyd/cvxbook/">Boyd and Vandenberghe’s (online) book Convex Optimization</a>.</li>
</ul>
<p>Videos (optional):</p>
<p>There are various videos from 2020 in the bCourses Media Gallery that you can use for reference if you want to.</p>
<ul>
<li>Video 1. Convergence in optimization</li>
<li>Video 2. Profiling</li>
<li>Video 3. Multivariate Newton-Raphson</li>
<li>Video 4. Descent methods and Newton-like methods</li>
<li>Video 5. Stochastic gradient descent</li>
<li>Video 6. Coordinate descent</li>
<li>Video 7. Nelder-Mead</li>
<li>Video 8. Optimization in practice</li>
<li>Video 9. Introduction to optimization under constraints</li>
<li>Video 10. Optimization under equality constraints</li>
<li>Video 11. Barrier method for constrained optimization</li>
</ul>
<section id="notation" class="level1">
<h1>1. Notation</h1>
<p>We’ll make use of the first derivative (the gradient) and second derivative (the Hessian) of functions. We’ll generally denote univariate and multivariate functions (without distinguishing between them) as <span class="math inline">\(f(x)\)</span> with <span class="math inline">\(x=(x_{1},\ldots,x_{p})\)</span>. The (column) vector of first partial derivatives (the gradient) is <span class="math inline">\(f^{\prime}(x)=\nabla f(x)=(\frac{\partial f}{\partial x_{1}},\ldots,\frac{\partial f}{\partial x_{p}})^{\top}\)</span> and the matrix of second partial derivatives (the Hessian) is <span class="math display">\[f^{\prime\prime}(x)=\nabla^{2}f(x)=H_{f}(x)=\left(\begin{array}{cccc}
\frac{\partial^{2}f}{\partial x_{1}^{2}} &amp; \frac{\partial^{2}f}{\partial x_{1}\partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2}f}{\partial x_{1}\partial x_{p}}\\
\frac{\partial^{2}f}{\partial x_{1}\partial x_{2}} &amp; \frac{\partial^{2}f}{\partial x_{2}^{2}} &amp; \cdots &amp; \frac{\partial^{2}f}{\partial x_{2}\partial x_{p}}\\
\vdots &amp; \vdots &amp; \ddots\\
\frac{\partial^{2}f}{\partial x_{1}\partial x_{p}} &amp; \frac{\partial^{2}f}{\partial x_{2}\partial x_{p}} &amp; \cdots &amp; \frac{\partial^{2}f}{\partial x_{p}^{2}}
\end{array}\right).\]</span> In considering iterative algorithms, I’ll use <span class="math inline">\(x_{0},\,x_{1},\ldots,x_{t},\,x_{t+1}\)</span> to indicate the sequence of values as we search for the optimum, denoted <span class="math inline">\(x^{*}\)</span>. <span class="math inline">\(x_{0}\)</span> is the starting point, which we must choose (often carefully). If it’s unclear at any point whether I mean a value of <span class="math inline">\(x\)</span> in the sequence or a sub-element of the <span class="math inline">\(x\)</span> vector, let me know, but hopefully it will be clear from context most of the time.</p>
<p>I’ll try to use <span class="math inline">\(x\)</span> (or if we’re talking explicitly about a likelihood, <span class="math inline">\(\theta\)</span>) to indicate the argument with respect to which we’re optimizing and <span class="math inline">\(Y\)</span> to indicate data involved in a likelihood. I’ll try to use <span class="math inline">\(z\)</span> to indicate covariates/regressors so there’s no confusion with <span class="math inline">\(x\)</span>.</p>
</section>
<section id="overview" class="level1">
<h1>2. Overview</h1>
<p>The basic goal here is to optimize a function numerically when we cannot find the maximum (or minimum) analytically. Some examples:</p>
<ol type="1">
<li><p>Finding the MLE for a GLM</p></li>
<li><p>Finding least squares estimates for a nonlinear regression model, <span class="math display">\[Y_{i}\sim\mathcal{N}(g(z_{i};\beta),\sigma^{2})\]</span> where <span class="math inline">\(g(\cdot)\)</span> is nonlinear and we seek to find the value of <span class="math inline">\(\theta=(\beta,\sigma^{2})\)</span> that best fits the data.</p></li>
<li><p>Maximizing a likelihood under constraints</p></li>
<li><p>Fitting a machine learning prediction method</p></li>
</ol>
<p>Maximum likelihood estimation and variants thereof is a standard situation in which optimization comes up.</p>
<p>We’ll focus on <strong>minimization</strong>, since any maximization of <span class="math inline">\(f\)</span> can be treated as minimization of <span class="math inline">\(-f\)</span>. The basic setup is to find the <em>argument</em>, <span class="math inline">\(x\)</span>, that minimizes <span class="math inline">\(f(x)\)</span>: <span class="math display">\[x^{*}=\arg\min_{x\in D}f(x)\]</span> where <span class="math inline">\(D\)</span> is the domain. Sometimes <span class="math inline">\(D=\Re^{p}\)</span> but other times it imposes constraints on <span class="math inline">\(x\)</span>. When there are no constraints, this is unconstrained optimization, where any <span class="math inline">\(x\)</span> for which <span class="math inline">\(f(x)\)</span> is defined is a possible solution. We’ll assume that <span class="math inline">\(f\)</span> is continuous as there’s little that can be done systematically if we’re dealing with a discontinuous function.</p>
<p>In one dimension, minimization is the same as root-finding with the derivative function, since the minimum of a differentiable function can only occur at a point at which the derivative is zero. So with differentiable functions we’ll seek to find <span class="math inline">\(x^{*}\)</span> s.t. <span class="math inline">\(f^{\prime}(x^{*})=\nabla f(x^{*})=0\)</span>. To ensure a minimum, we want that for all <span class="math inline">\(y\)</span> in a neighborhood of <span class="math inline">\(x^{*}\)</span>, <span class="math inline">\(f(y)\geq f(x^{*})\)</span>, or (for twice differentiable functions) <span class="math inline">\(f^{\prime\prime}(x^{*})\geq0\)</span>.</p>
<p>In more than one dimension, we want that the Hessian evaluated at <span class="math inline">\(x^{*}\)</span> is positive semi-definite, which tells us that moving in any direction away from <span class="math inline">\(x^{*}\)</span> would not go downhill.</p>
<p>Different strategies are used depending on whether <span class="math inline">\(D\)</span> is discrete and countable, or continuous, dense and uncountable. We’ll concentrate on the continuous case but the discrete case can arise in statistics, such as in doing variable selection.</p>
<p>In general we rely on the fact that we can evaluate <span class="math inline">\(f\)</span>. Often we make use of analytic or numerical derivatives of <span class="math inline">\(f\)</span> as well.</p>
<p>To some degree, optimization is a solved problem, with good software implementations, so it raises the question of how much to discuss in this class. The basic motivation for going into some of the basic classes of optimization strategies is that the function being optimized changes with each problem and can be tricky to optimize, and I want you to know something about how to choose a good approach when you find yourself with a problem requiring optimization. Finding global, as opposed to local, minima can also be an issue.</p>
<p>Note that I’m not going to cover MCMC (Markov chain Monte Carlo) methods, which are used for approximating integrals and sampling from posterior distributions in a Bayesian context and in a variety of ways for optimization. If you take a Bayesian course you’ll cover this in detail, and if you don’t do Bayesian work, you probably won’t have much need for MCMC, though it comes up in MCEM (Monte Carlo EM) and simulated annealing, among other places.</p>
<section id="goals-for-the-unit" class="level4">
<h4 class="anchored" data-anchor-id="goals-for-the-unit">Goals for the unit</h4>
<p>Optimization is a big topic. Here’s what I would like you to get out of this:</p>
<ol type="1">
<li>an understanding of line searches (one-dimensional optimization),</li>
<li>an understanding of multivariate derivative-based optimization and how line searches are useful within this,</li>
<li>an understanding of derivative-free methods,</li>
<li>an understanding of the methods used in R’s optimization routines, their strengths and weaknesses, and various tricks for doing better optimization in R, and</li>
<li>a basic idea of what convex optimization is and when you might want to go learn more about it.</li>
</ol>
</section>
</section>
<section id="univariate-function-optimization" class="level1">
<h1>3. Univariate function optimization</h1>
<p>We’ll start with some strategies for univariate functions. These can be useful later on in dealing with multivariate functions.</p>
<section id="golden-section-search" class="level2">
<h2 class="anchored" data-anchor-id="golden-section-search">Golden section search</h2>
<p>This strategy requires only that the function be unimodal.</p>
<p>Assume we have a single minimum, in <span class="math inline">\([a,b]\)</span>. We choose two points in the interval and evaluate them, <span class="math inline">\(f(x_{1})\)</span> and <span class="math inline">\(f(x_{2})\)</span>. If <span class="math inline">\(f(x_{1})&lt;f(x_{2})\)</span> then the minimum must be in <span class="math inline">\([a,x_{2}]\)</span>, and if the converse in <span class="math inline">\([x_{1},b]\)</span>. We proceed by choosing a new point in the new, smaller interval and iterate. At each step we reduce the length of the interval in which the minimum must lie. The primary question involves what is an efficient rule to use to choose the new point at each iteration.</p>
<p>Suppose we start with <span class="math inline">\(x_{1}\)</span> and <span class="math inline">\(x_{2}\)</span> s.t. they divide <span class="math inline">\([a,b]\)</span> into three equal segments. Then we use <span class="math inline">\(f(x_{1})\)</span> and <span class="math inline">\(f(x_{2})\)</span> to rule out either the leftmost or rightmost segment based on whether <span class="math inline">\(f(x_{1})&lt;f(x_{2})\)</span>. If we have divided equally, we cannot place the next point very efficiently because either <span class="math inline">\(x_{1}\)</span> or <span class="math inline">\(x_{2}\)</span> equally divides the remaining space, so we are forced to divide the remaining space into relative lengths of 0.25, 0.25, and 0.5. The next time around, we may only rule out the shorter segment, which leads to inefficiency.</p>
<p>The efficient strategy is to maintain the <em>golden ratio</em> between the distances between the points using <span class="math inline">\(\phi=(\sqrt{5}-1)/2\approx.618\)</span> (the golden ratio), which is determined by solving for <span class="math inline">\(\phi\)</span> in this equation: <span class="math inline">\(\phi-\phi^{2}=2\phi-1\)</span>. We start with <span class="math inline">\(x_{1}=a+(1-\phi)(b-a)\)</span> and <span class="math inline">\(x_{2}=a+\phi(b-a)\)</span>. Then suppose <span class="math inline">\(f(x_{1})&lt;f(x_{2})\)</span> so the minimum must be in <span class="math inline">\([a,x_{2}]\)</span>. Since <span class="math inline">\(x_{1}-a&gt;x_{2}-x_{1}\)</span>, we now choose <span class="math inline">\(x_{3}\)</span> in the interval <span class="math inline">\([a,x_{1}]\)</span> to produce three subintervals, <span class="math inline">\([a,x_{3}],\,[x_{3},x_{1}],\,[x_{1},x_{2}]\)</span>. We choose to place <span class="math inline">\(x_{3}\)</span> s.t. it uses the golden ratio in the interval <span class="math inline">\([a,x_{1}]\)</span>, namely <span class="math inline">\(x_{3}=a+(1-\phi)(x_{2}-a)\)</span>. This means that the length of the first subinterval is <span class="math inline">\((\phi-\phi^{2})(b-a)\)</span> and the length of the third subinterval is <span class="math inline">\((2\phi-1)(b-a)\)</span>, but those lengths are equal because we found <span class="math inline">\(\phi\)</span> to satisfy <span class="math inline">\(\phi-\phi^{2}=2\phi-1\)</span>.</p>
<p>The careful choice of <span class="math inline">\(\phi\)</span> allows us to narrow the search interval by an equal proportion,<span class="math inline">\(1-\phi\)</span>, in each iteration. Eventually we have narrowed the minimum to between <span class="math inline">\(x_{t-1}\)</span> and <span class="math inline">\(x_{t}\)</span>, where the difference <span class="math inline">\(|x_{t}-x_{t-1}|\)</span> is sufficiently small (within some tolerance - see Section 4 for details), and we report <span class="math inline">\((x_{t}+x_{t-1})/2\)</span>.</p>
</section>
<section id="bisection-method" class="level2">
<h2 class="anchored" data-anchor-id="bisection-method">Bisection method</h2>
<p>The bisection method requires the existence of the first derivative but has the advantage over the golden section search of halving the interval at each step. We again assume unimodality.</p>
<p>We start with an initial interval <span class="math inline">\((a_{0},b_{0})\)</span> and proceed to shrink the interval. Let’s choose <span class="math inline">\(a_{0}\)</span> and <span class="math inline">\(b_{0}\)</span>, and set <span class="math inline">\(x_{0}\)</span> to be the mean of these endpoints. Now we update according to the following algorithm, assuming our current interval is <span class="math inline">\([a_{t},b_{t}]\)</span>.</p>
<ul>
<li>If <span class="math inline">\(f^{\prime}(a_{t})f^{\prime}(x_{t})&lt;0\)</span>, then <span class="math inline">\([a_{t+1},b_{t+1}] = [a_{t},x_{t}]\)</span></li>
<li>If <span class="math inline">\(f^{\prime}(a_{t}) f^{\prime}(x_{t})&gt;0\)</span>, then <span class="math inline">\([a_{t+1},b_{t+1}] = [x_{t},b_{t}]\)</span></li>
</ul>
<p>and set <span class="math inline">\(x_{t+1}\)</span> to the mean of <span class="math inline">\(a_{t+1}\)</span> and <span class="math inline">\(b_{t+1}\)</span>. The basic idea is that if the derivative at both <span class="math inline">\(a_{t}\)</span> and <span class="math inline">\(x_{t}\)</span> is negative, then the minimum must be between <span class="math inline">\(x_{t}\)</span> and <span class="math inline">\(b_{t}\)</span>, based on the intermediate value theorem. If the derivatives at <span class="math inline">\(a_{t}\)</span> and <span class="math inline">\(x_{t}\)</span> are of different signs, then the minimum must be between <span class="math inline">\(a_{t}\)</span> and <span class="math inline">\(x_{t}\)</span>.</p>
<p>Since the bisection method reduces the size of the search space by one-half at each iteration, one can work out that each decimal place of precision requires 3-4 iterations. Obviously bisection is more efficient than the golden section search because we reduce by <span class="math inline">\(0.5&gt;0.382=1-\phi\)</span>, so we’ve gained information by using the derivative. It requires an evaluation of the derivative however, while golden section just requires an evaluation of the original function.</p>
<p>Bisection is an example of a <em>bracketing</em> method, in which we trap the minimum within a nested sequence of intervals of decreasing length. These tend to be slow, but if the first derivative is continuous, they are robust and don’t require that a second derivative exist.</p>
</section>
<section id="newton-raphson-newtons-method" class="level2">
<h2 class="anchored" data-anchor-id="newton-raphson-newtons-method">Newton-Raphson (Newton’s method)</h2>
<section id="overview-1" class="level3">
<h3 class="anchored" data-anchor-id="overview-1">Overview</h3>
<p>We’ll talk about Newton-Raphson (N-R) as an optimization method rather than a root-finding method, but they’re just different perspectives on the same algorithm.</p>
<p>For N-R, we need two continuous derivatives that we can evaluate. The benefit is speed, relative to bracketing methods. We again assume the function is unimodal. The minimum must occur at <span class="math inline">\(x^{*}\)</span> s.t. <span class="math inline">\(f^{\prime}(x^{*})=0\)</span>, provided the second derivative is non-negative at <span class="math inline">\(x^{*}\)</span>. So we aim to find a zero (a root) of the first derivative function. Assuming that we have an initial value <span class="math inline">\(x_{0}\)</span> that is close to <span class="math inline">\(x^{*}\)</span>, we have the Taylor series approximation <span class="math display">\[f^{\prime}(x)\approx f^{\prime}(x_{0})+(x-x_{0})f^{\prime\prime}(x_{0}).\]</span> Now set <span class="math inline">\(f^{\prime}(x)=0\)</span>, since that is the condition we desire (the condition that holds when we are at <span class="math inline">\(x^{*}\)</span>), and solve for <span class="math inline">\(x\)</span> to get <span class="math display">\[x_{1}=x_{0}-\frac{f^{\prime}(x_{0})}{f^{\prime\prime}(x_{0})},\]</span> and iterate, giving us updates of the form <span class="math inline">\(x_{t+1}=x_{t}-\frac{f^{\prime}(x_{t})}{f^{\prime\prime}(x_{t})}\)</span>. What are we doing intuitively? Basically we are taking the tangent to <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(x_{0}\)</span> and extrapolating along that line to where it crosses the x-axis to find <span class="math inline">\(x_{1}\)</span>. We then reevaluate <span class="math inline">\(f(x_{1})\)</span> and continue to travel along the tangents.</p>
<p>One can prove that if <span class="math inline">\(f^{\prime}(x)\)</span> is twice continuously differentiable, is convex, and has a root, then N-R converges from any starting point.</p>
<p>Note that we can also interpret the N-R update as finding the analytic minimum of the quadratic Taylor series approximation to <span class="math inline">\(f(x)\)</span>.</p>
<p>Newton’s method converges very quickly (as we’ll discuss in Section 4), but if you start too far from the minimum, you can run into serious problems.</p>
</section>
<section id="secant-method-variation-on-n-r" class="level3">
<h3 class="anchored" data-anchor-id="secant-method-variation-on-n-r">Secant method variation on N-R</h3>
<p>Suppose we don’t want to calculate the second derivative required in the divisor of N-R. We might replace the analytic derivative with a discrete difference approximation based on the secant line joining <span class="math inline">\((x_{t},f^{\prime}(x_{t}))\)</span> and <span class="math inline">\((x_{t-1},f^{\prime}(x_{t-1}))\)</span>, giving an approximate second derivative: <span class="math display">\[f^{\prime\prime}(x_{t})\approx\frac{f^{\prime}(x_{t})-f^{\prime}(x_{t-1})}{x_{t}-x_{t-1}}.\]</span> For this variant on N-R, we need two starting points, <span class="math inline">\(x_{0}\)</span> and <span class="math inline">\(x_{1}\)</span>.</p>
<p>An alternative to the secant-based approximation is to use a standard discrete approximation of the derivative such as <span class="math display">\[f^{\prime\prime}(x_{t})\approx\frac{f^{\prime}(x_{t}+h)-f^{\prime}(x_{t}-h)}{2h}.\]</span></p>
</section>
<section id="how-can-newtons-method-go-wrong" class="level3">
<h3 class="anchored" data-anchor-id="how-can-newtons-method-go-wrong">How can Newton’s method go wrong?</h3>
<p>Let’s think about what can go wrong - namely when we could have <span class="math inline">\(f(x_{t+1})&gt;f(x_{t})\)</span>? To be concrete (and without loss of generality), let’s assume that <span class="math inline">\(f(x_{t})&gt;0\)</span>, in other words that <span class="math inline">\(x^{*}&lt;x_{t}\)</span>.</p>
<ol type="1">
<li>As usual, we can develop some intuition by starting with the worst case that <span class="math inline">\(f^{\prime\prime}(x_{t})\)</span> is 0, in which case the method would fail as <span class="math inline">\(x_{t+1}\)</span> would be <span class="math inline">\(-\infty\)</span>.</li>
<li>Now suppose that <span class="math inline">\(f^{\prime\prime}(x_{t})\)</span> is a small positive number. Basically, if <span class="math inline">\(f^{\prime}(x_{t})\)</span> is relatively flat, we can get that <span class="math inline">\(|x_{t+1}-x^{*}|&gt;|x_{t}-x^{*}|\)</span> because we divide by a small value for the second derivative, causing <span class="math inline">\(x_{t+1}\)</span> to be far from <span class="math inline">\(x_{t}\)</span> (though it does at least go in the correct direction). We’ll see an example on the board and the demo code (see below).</li>
<li>Newton’s method can also go uphill (going in the wrong direction, away from <span class="math inline">\(x^{*}\)</span>) when the second derivative is negative, with the method searching for a maximum, since we would have <span class="math inline">\(x_{t+1}&gt;x_{t}\)</span>. Another way to think of this is that Newton’s method does not automatically minimize the function, rather it finds local optima.</li>
</ol>
<p>In all these cases Newton’s method could diverge, failing to converge on the optimum.</p>
<section id="divergence" class="level4">
<h4 class="anchored" data-anchor-id="divergence">Divergence</h4>
<p>First let’s see an example of divergence. The left and middle panels show two cases of convergence, while the right panel shows divergence. In the right panel, the initial second derivative value is small enough that <span class="math inline">\(x_{2}\)</span> is further from <span class="math inline">\(x^{*}\)</span> than <span class="math inline">\(x_{1}\)</span> and then <span class="math inline">\(x_{3}\)</span> is yet further away. In all cases the sequence of <span class="math inline">\(x\)</span> values is indicated by the red letters.</p>
<div class="cell" data-fig-height="3" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fp(x, theta<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">## First derivative - we want the root of this.</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(x <span class="op">*</span> theta) <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(x <span class="op">*</span> theta)) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fpp(x, theta<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Second derivative - used to scale the optimization steps.</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(x <span class="op">*</span> theta) <span class="op">/</span> ((<span class="dv">1</span> <span class="op">+</span> np.exp(x <span class="op">*</span> theta)) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_plot(xs, xvals, fp, fpp, subplot, title):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    plt.plot(xs, fp(xs), <span class="st">'-'</span>, label<span class="op">=</span><span class="st">"f'(x)"</span>, color <span class="op">=</span> <span class="st">'grey'</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    plt.plot(xs, fpp(xs), <span class="st">'--'</span>, label<span class="op">=</span><span class="st">"f''(x)"</span>, color <span class="op">=</span> <span class="st">'grey'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(xvals)):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        plt.text(xvals[i], fp(xvals[i]), i, fontsize<span class="op">=</span><span class="dv">14</span>, color <span class="op">=</span> <span class="st">'red'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"f'(x)"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">300</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>xvals <span class="op">=</span> np.zeros(n)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co">## Good starting point</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>make_plot(xs, xvals, fp, fpp, <span class="dv">1</span>, <span class="st">"converges quickly"</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">## Ok starting point</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>make_plot(xs, xvals, fp, fpp, <span class="dv">2</span>, <span class="st">"converges"</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">## Bad starting point</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>make_plot(xs, xvals[np.<span class="bu">abs</span>(xvals) <span class="op">&lt;</span> <span class="dv">15</span>], fp, fpp, <span class="dv">3</span>, <span class="st">"diverges"</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co">## whoops!</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-2-output-1.png" width="600" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-2-output-2.png" width="600" height="449"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_3661545/3161030548.py:58: RuntimeWarning:

divide by zero encountered in double_scalars

/tmp/ipykernel_3661545/3161030548.py:6: RuntimeWarning:

invalid value encountered in double_scalars

/tmp/ipykernel_3661545/3161030548.py:10: RuntimeWarning:

invalid value encountered in double_scalars
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-2-output-4.png" width="600" height="449"></p>
</div>
</div>
</section>
<section id="multiple-optima-converging-to-the-wrong-optimum" class="level4">
<h4 class="anchored" data-anchor-id="multiple-optima-converging-to-the-wrong-optimum">Multiple optima: converging to the wrong optimum</h4>
<p>In the first row of the next figure, let’s see an example of climbing uphill and finding a local maximum rather than minimum. The other rows show convergence. In all cases the minimum is at <span class="math inline">\(x^{*}\approx3.14\)</span></p>
<div class="cell" data-fig-height="7" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the original function</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.cos(x)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the gradient</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fp(x):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.sin(x)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the second derivative</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fpp(x):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.cos(x)<span class="co"># original fxn</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_plot2(xs, xvals, f, fp, num, title):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gradient subplot</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, num)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    plt.plot(xs, fp(xs), <span class="st">'-'</span>, label<span class="op">=</span><span class="st">"f'(x)"</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    plt.scatter(np.pi, fp(np.pi))</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(xvals)):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        plt.text(xvals[i], fp(xvals[i]), i, fontsize<span class="op">=</span><span class="dv">14</span>, color <span class="op">=</span> <span class="st">'red'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"f'(x)"</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    plt.title(title[<span class="dv">0</span>])</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># function subplot</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, num<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    plt.plot(xs, f(xs), <span class="st">'-'</span>, label<span class="op">=</span><span class="st">"f(x)"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    plt.scatter(np.pi, f(np.pi))</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(xvals)):</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        plt.text(xvals[i], f(xvals[i]), i, fontsize<span class="op">=</span><span class="dv">14</span>, color <span class="op">=</span> <span class="st">'red'</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"f(x)"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    plt.title(title[<span class="dv">1</span>])</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, num<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="fl">5.5</span> <span class="co"># starting point</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>fp(x0) <span class="co"># positive</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>fpp(x0) <span class="co"># negative</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> x0 <span class="op">-</span> fp(x0)<span class="op">/</span>fpp(x0) <span class="co"># whoops, we've gone uphill </span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co">## because of the negative second derivative</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>xvals <span class="op">=</span> np.zeros(n)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>make_plot2(xs, xvals, f, fp, <span class="dv">1</span>, title <span class="op">=</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'uphill to local maximum, gradient view'</span>, <span class="st">'uphill to local maximum, function view'</span>])</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co">## In contrast, with better starting points we can find the minimum</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="co">## (but this nearly diverges).</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="fl">4.3</span> <span class="co"># ok starting point</span></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>fp(x0) </span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>fpp(x0) </span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> x0 <span class="op">-</span> fp(x0)<span class="op">/</span>fpp(x0)  <span class="co"># going downhill</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>make_plot2(xs, xvals, f, fp, <span class="dv">3</span>, title <span class="op">=</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'nearly diverges, gradient view'</span>, <span class="st">'nearly diverges, function view'</span>])</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a><span class="co">## With a better starting point, we converge quickly.</span></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="fl">3.8</span> <span class="co"># good starting point</span></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>fp(x0) </span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>fpp(x0) </span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> x0 <span class="op">-</span> fp(x0)<span class="op">/</span>fpp(x0)   <span class="co"># going downhill</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">10</span>):</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> fp(xvals[t<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a><span class="co">## print(xvals)</span></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a>make_plot2(xs, xvals, f, fp, <span class="dv">5</span>, title <span class="op">=</span></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>    [<span class="st">'better starting point, gradient view'</span>, <span class="st">'better starting point, function view'</span>])</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-3-output-1.png" width="830" height="597"></p>
</div>
</div>
</section>
<section id="improving-newtons-method" class="level4">
<h4 class="anchored" data-anchor-id="improving-newtons-method">Improving Newton’s method</h4>
<p>One nice, general idea is to use a fast method such as Newton’s method <em>safeguarded</em> by a robust, but slower method. Here’s how one can do this for N-R, safeguarding with a bracketing method such as bisection. Basically, we check the N-R proposed move to see if N-R is proposing a step outside of where the root is known to lie based on the previous steps and the gradient values for those steps. If so, we could choose the next step based on bisection.</p>
<p>Another approach is backtracking. If a new value is proposed that yields a larger value of the function, backtrack to find a value that reduces the function. One possibility is a line search but given that we’re trying to reduce computation, a full line search is often unwise computationally (also in the multivariate Newton’s method, we are in the middle of an iterative algorithm for which we will just be going off in another direction anyway at the next iteration). A basic approach is to keep backtracking in halves. A nice alternative is to fit a polynomial to the known information about that slice of the function, namely <span class="math inline">\(f(x_{t+1})\)</span>, <span class="math inline">\(f(x_{t})\)</span>, <span class="math inline">\(f^{\prime}(x_{t})\)</span> and <span class="math inline">\(f^{\prime\prime}(x_{t})\)</span> and find the minimum of the polynomial approximation.</p>
</section>
</section>
</section>
</section>
<section id="convergence-ideas" class="level1">
<h1>4. Convergence ideas</h1>
<section id="convergence-metrics" class="level2">
<h2 class="anchored" data-anchor-id="convergence-metrics">Convergence metrics</h2>
<p>We might choose to assess whether <span class="math inline">\(f^{\prime}(x_{t})\)</span> is near zero, which should assure that we have reached the critical point. However, in parts of the domain where <span class="math inline">\(f(x)\)</span> is fairly flat, we may find the derivative is near zero even though we are far from the optimum. Instead, we generally monitor <span class="math inline">\(|x_{t+1}-x_{t}|\)</span> (for the moment, assume <span class="math inline">\(x\)</span> is scalar). We might consider absolute convergence: <span class="math inline">\(|x_{t+1}-x_{t}|&lt;\epsilon\)</span> or relative convergence, <span class="math inline">\(\frac{|x_{t+1}-x_{t}|}{|x_{t}|}&lt;\epsilon\)</span>. Relative convergence is appealing because it accounts for the scale of <span class="math inline">\(x\)</span>, but it can run into problems when <span class="math inline">\(x_{t}\)</span> is near zero, in which case one can use <span class="math inline">\(\frac{|x_{t+1}-x_{t}|}{|x_{t}|+\epsilon}&lt;\epsilon\)</span>. We would want to account for machine precision in thinking about setting <span class="math inline">\(\epsilon\)</span>. For relative convergence a reasonable choice of <span class="math inline">\(\epsilon\)</span> would be to use the square root of machine epsilon or about <span class="math inline">\(1\times10^{-8}\)</span>.</p>
<p>Problems with the optimization may show up in a convergence measure that fails to decrease or cycles (oscillates). Software generally has a stopping rule that stops the algorithm after a fixed number of iterations; these can generally be changed by the user. When an algorithm stops because of the stopping rule before the convergence criterion is met, we say the algorithm has failed to converge. Sometimes we just need to run it longer, but often it indicates a problem with the function being optimized or with your starting value.</p>
<p>For multivariate optimization, we use a distance metric between <span class="math inline">\(x_{t+1}\)</span> and <span class="math inline">\(x_{t}\)</span>, such as <span class="math inline">\(\|x_{t+1}-x_{t}\|_{p}\)</span> , often with <span class="math inline">\(p=1\)</span> or <span class="math inline">\(p=2\)</span>.</p>
</section>
<section id="starting-values" class="level2">
<h2 class="anchored" data-anchor-id="starting-values">Starting values</h2>
<p>Good starting values are important because they can improve the speed of optimization, prevent divergence or cycling, and prevent finding local optima.</p>
<p>Using random or selected multiple starting values can help with multiple optima (aka multimodality).</p>
<p>Here’s a function (the Rastrigin function) with multiple optima that is commonly used for testing methods that claim to work well for multimodal problems. This is a hard function to optimize with respect to, particularly in higher dimensions (one can do it in higher dimensions than 2 by simply making the <span class="math inline">\(x\)</span> vector longer but having the same structure). In particular Rastrigin with 30 dimensions is considered to be very hard.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin(x):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A <span class="op">*</span> n <span class="op">+</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> A <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>const <span class="op">=</span> <span class="fl">5.12</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>nGrid <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>gr <span class="op">=</span> np.linspace(<span class="op">-</span>const, const, num<span class="op">=</span>nGrid)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of x values</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>x1, x2 <span class="op">=</span> np.meshgrid(gr, gr)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.column_stack((x1.ravel(), x2.ravel()))</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the Rastrigin function for each point in the grid</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.apply_along_axis(rastrigin, <span class="dv">1</span>, xs)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a plot</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.imshow(y.reshape((nGrid, nGrid)), extent<span class="op">=</span>[<span class="op">-</span>const, const, <span class="op">-</span>const, const], origin<span class="op">=</span><span class="st">'lower'</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Rastrigin Function'</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x1'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'x2'</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-4-output-1.png" width="588" height="523"></p>
</div>
</div>
</section>
<section id="convergence-rates" class="level2">
<h2 class="anchored" data-anchor-id="convergence-rates">Convergence rates</h2>
<p>Let <span class="math inline">\(\epsilon_{t}=|x_{t}-x^{*}|\)</span>. If the limit</p>
<p><span class="math display">\[\lim_{t\to\infty}\frac{|\epsilon_{t+1}|}{|\epsilon_{t}|^{\beta}}=c\]</span> exists for <span class="math inline">\(\beta&gt;0\)</span> and <span class="math inline">\(c\ne0\)</span>, then a method is said to have order of convergence <span class="math inline">\(\beta\)</span>. This basically measures how big the error at the <span class="math inline">\(t+1\)</span>th iteration is relative to that at the <span class="math inline">\(t\)</span>th iteration, with the approximation that <span class="math inline">\(|\epsilon_{t+1}|\approx c|\epsilon_{t}|^{\beta}\)</span>.</p>
<p>Bisection doesn’t formally satisfy the criterion needed to make use of this definition, but roughly speaking it has linear convergence (<span class="math inline">\(\beta=1\)</span>), so the magnitude of the error decreases by a factor of <span class="math inline">\(c\)</span> at each step. Next we’ll see that N-R has quadratic convergence (<span class="math inline">\(\beta=2\)</span>), which is fast.</p>
<p>To analyze convergence of N-R, we’ll assume that <span class="math inline">\(f^{\prime}(x)\)</span> is twice continuously differentiable and consider a Taylor expansion of the gradient at the minimum, <span class="math inline">\(x^{*}\)</span>, around the current value, <span class="math inline">\(x_{t}\)</span>: <span class="math display">\[f^{\prime}(x^{*})=f^{\prime}(x_{t})+(x^{*}-x_{t})f^{\prime\prime}(x_{t})+\frac{1}{2}(x^{*}-x_{t})^{2}f^{\prime\prime\prime}(\xi_{t})=0,\]</span> for some <span class="math inline">\(\xi_{t}\in[x^{*},x_{t}]\)</span>. Making use of the N-R update equation: <span class="math inline">\(x_{t+1}=x_{t}-\frac{f^{\prime}(x_{t})}{f^{\prime\prime}(x_{t})}\)</span> to substitute , and some algebra, we have <span class="math display">\[\frac{|\epsilon_{t+1}|}{|\epsilon_t|^{\beta}} = \frac{|x^{*}-x_{t+1}|}{(x^{*}-x_{t})^{2}}=\left| \frac{1}{2}\frac{f^{\prime\prime\prime}(\xi_{t})}{f^{\prime\prime}(x_{t})} \right|.\]</span> If the limit of the ratio on the right hand side exists (note the assumption of twice continuous differentiability) and is equal to <span class="math inline">\(c\)</span>: <span class="math display">\[c=\lim_{x_{t}\to x^{*}}\left|\frac{1}{2}\frac{f^{\prime\prime\prime}(\xi_{t})}{f^{\prime\prime}(x_{t})}\right|=\left|\frac{1}{2}\frac{f^{\prime\prime\prime}(x^{*})}{f^{\prime\prime}(x^{*})}\right|\]</span> then we see that <span class="math inline">\(\beta=2\)</span>.</p>
<p>If <span class="math inline">\(c\)</span> were one, then we see that if we have <span class="math inline">\(k\)</span> digits of accuracy at <span class="math inline">\(t\)</span>, we’d have <span class="math inline">\(2k\)</span> digits at <span class="math inline">\(t+1\)</span> (e.g., <span class="math inline">\(|\epsilon_{t}|=0.01\)</span> results in <span class="math inline">\(|\epsilon_{t+1}|=0.0001\)</span>), which justifies the characterization of quadratic convergence being fast. In practice <span class="math inline">\(c\)</span> will moderate the rate of convergence. The smaller <span class="math inline">\(c\)</span> the better, so we’d like to have the second derivative be large and the third derivative be small. The expression also indicates we’ll have a problem if <span class="math inline">\(f^{\prime\prime}(x_{t})=0\)</span> at any point (think about what this corresponds to graphically - what is our next step when <span class="math inline">\(f^{\prime\prime}(x_{t})=0\)</span>?). The characteristics of the derivatives determine the domain of attraction (the region in which we’ll converge rather than diverge) of the minimum.</p>
<p>Givens and Hoeting show that using the secant-based approximation to the second derivative in N-R has order of convergence, <span class="math inline">\(\beta\approx1.62\)</span>.</p>
<p>Here’s an example of convergence comparing bisection and N-R. First, Newton-Raphson:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(precision<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the original function</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.cos(x)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the gradient</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fp(x):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.sin(x)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the second derivative</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fpp(x):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.cos(x)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>xstar <span class="op">=</span> np.pi  <span class="co"># known minimum</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">## Newton-Raphson (N-R) method</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>n_it <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>xvals <span class="op">=</span> np.zeros(n_it)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_it):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    xvals[t] <span class="op">=</span> xvals[t <span class="op">-</span> <span class="dv">1</span>] <span class="op">-</span> fp(xvals[t <span class="op">-</span> <span class="dv">1</span>]) <span class="op">/</span> fpp(xvals[t <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xvals)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[2.           4.1850398633 2.4678936745 3.2661862776 3.1409439123
 3.1415926537 3.1415926536 3.1415926536 3.1415926536 3.1415926536]</code></pre>
</div>
</div>
<p>Next, here is bisection:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Bisection method</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bisec_step(interval, fp):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    interval <span class="op">=</span> interval.copy()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    xt <span class="op">=</span> np.mean(interval)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> fp(interval[<span class="dv">0</span>]) <span class="op">*</span> fp(xt) <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        interval[<span class="dv">1</span>] <span class="op">=</span> xt</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        interval[<span class="dv">0</span>] <span class="op">=</span> xt</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> interval</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>n_it <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>a0 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>b0 <span class="op">=</span> (<span class="dv">3</span> <span class="op">*</span> np.pi <span class="op">/</span> <span class="dv">2</span>) <span class="op">-</span> (xstar <span class="op">-</span> a0)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>interval <span class="op">=</span> np.zeros((n_it, <span class="dv">2</span>))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>interval[<span class="dv">0</span>,:] <span class="op">=</span> [a0, b0]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_it):</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    interval[t,:] <span class="op">=</span> bisec_step(interval[t<span class="op">-</span><span class="dv">1</span>,:], fp)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(interval, axis<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[2.7853981634 3.1780972451 2.9817477042 3.0799224747 3.1290098599
 3.1535535525 3.1412817062 3.1474176293 3.1443496678 3.142815687
 3.1420486966 3.1416652014 3.1414734538 3.1415693276 3.1416172645
 3.141593296  3.1415813118 3.1415873039 3.1415903    3.141591798
 3.141592547  3.1415929215 3.1415927343 3.1415926406 3.1415926875
 3.1415926641 3.1415926524 3.1415926582 3.1415926553 3.1415926538]</code></pre>
</div>
</div>
</section>
</section>
<section id="multivariate-optimization" class="level1">
<h1>5. Multivariate optimization</h1>
<p>Optimizing as the dimension of the space gets larger becomes increasingly difficult:</p>
<ol type="1">
<li><p>In high dimensions, there are many possible directions to go.</p></li>
<li><p>One can end up having to do calculations with large vectors and matrices.</p></li>
<li><p>Multimodality increasingly becomes a concern (and can be hard to detect).</p></li>
</ol>
<p>First we’ll discuss the idea of profiling to reduce dimensionality and then we’ll talk about various numerical techniques, many of which build off of Newton’s method (using second derivative information). We’ll finish by talking about methods that only use the gradient (and not the second derivative) and methods that don’t use any derivative information.</p>
<section id="profiling" class="level2">
<h2 class="anchored" data-anchor-id="profiling">Profiling</h2>
<p>A core technique for likelihood optimization is to analytically maximize over any parameters for which this is possible. Suppose we have two sets of parameters, <span class="math inline">\(\theta_{1}\)</span> and <span class="math inline">\(\theta_{2}\)</span>, and we can analytically maximize w.r.t <span class="math inline">\(\theta_{2}\)</span>. This will give us <span class="math inline">\(\hat{\theta}_{2}(\theta_{1})\)</span>, a function of the remaining parameters over which analytic maximization is not possible. Plugging in <span class="math inline">\(\hat{\theta}_{2}(\theta_{1})\)</span> into the objective function (in this case generally the likelihood or log likelihood) gives us the profile (log) likelihood solely in terms of the obstinant parameters. For example, suppose we have the regression likelihood with correlated errors: <span class="math display">\[Y\sim\mathcal{N}(X\beta,\sigma^{2}\Sigma(\rho)),\]</span> where <span class="math inline">\(\Sigma(\rho)\)</span> is a correlation matrix that is a function of a parameter, <span class="math inline">\(\rho\)</span>. The maximum w.r.t. <span class="math inline">\(\beta\)</span> is easily seen to be the GLS estimator <span class="math inline">\(\hat{\beta}(\rho)=(X^{\top}\Sigma(\rho)^{-1}X)^{-1}X^{\top}\Sigma(\rho)^{-1}Y\)</span>. (In general such a maximum is a function of all of the other parameters, but conveniently it’s only a function of <span class="math inline">\(\rho\)</span> here.) This gives us the initial profile likelihood <span class="math display">\[\frac{1}{(\sigma^{2})^{n/2}|\Sigma(\rho)|^{1/2}}\exp\left(-\frac{(Y-X\hat{\beta}(\rho))^{-\top}\Sigma(\rho)^{-1}(Y-X\hat{\beta}(\rho))}{2\sigma^{2}}\right).\]</span> We then notice that the likelihood is maximized w.r.t. <span class="math inline">\(\sigma^{2}\)</span> at <span class="math display">\[\hat{\sigma^{2}}(\rho)=\frac{(Y-X\hat{\beta}(\rho))^{\top}\Sigma(\rho)^{-1}(Y-X\hat{\beta}(\rho))}{n}.\]</span> This gives us the final profile likelihood, <span class="math display">\[\frac{1}{|\Sigma(\rho)|^{1/2}}\frac{1}{(\hat{\sigma^{2}}(\rho))^{n/2}}\exp(-\frac{1}{2}n),\]</span> a function of <span class="math inline">\(\rho\)</span> only, for which numerical optimization is much simpler.</p>
</section>
<section id="newton-raphson-newtons-method-1" class="level2">
<h2 class="anchored" data-anchor-id="newton-raphson-newtons-method-1">Newton-Raphson (Newton’s method)</h2>
<p>For multivariate <span class="math inline">\(x\)</span> we have the Newton-Raphson update <span class="math inline">\(x_{t+1}=x_{t}-f^{\prime\prime}(x_{t})^{-1}f^{\prime}(x_{t})\)</span>, or in our other notation, <span class="math display">\[x_{t+1}=x_{t}-H_{f}(x_{t})^{-1}\nabla f(x_{t}).\]</span></p>
<p>Let’s consider a very simple example of nonlinear least squares. We’ll use the famous Mauna Loa atmospheric carbon dioxide record.</p>
<p>Let’s suppose (I have no real reason to think this) that we think that the data can be well-represented by this nonlinear model: <span class="math display">\[Y_{i}=\beta_{0}+\beta_{1}\exp(t_i/\beta_{2})+\epsilon_{i}.\]</span></p>
<p>Some of the things we need to worry about with Newton’s method in general about are (1) good starting values, (2) positive definiteness of the Hessian, and (3) avoiding errors in deriving the derivatives.</p>
<p>A note on the positive definiteness: since the Hessian may not be positive definite (although it may well be, provided the function is approximately locally quadratic), one can consider modifying the Cholesky decomposition of the Hessian to enforce positive definiteness by adding diagonal elements to <span class="math inline">\(H_{f}\)</span> as necessary.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(os.path.join(<span class="st">'..'</span>,<span class="st">'data'</span>, <span class="st">'co2_annmean_mlo.csv'</span>),</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    header <span class="op">=</span> <span class="dv">0</span>, names <span class="op">=</span> [<span class="st">'year'</span>,<span class="st">'co2'</span>,<span class="st">'unc'</span>])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(data.year, data.co2)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'year'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"CO2"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Center years for better numerical behavior</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>data.year <span class="op">=</span> data.year <span class="op">-</span> np.mean(data.year)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">### Linear fit - not a good model</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(data.year)  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(data.co2, X).fit()</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(data.year, data.co2)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.plot(data.year, model.fittedvalues, <span class="st">'-'</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-7-output-1.png" width="593" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-7-output-2.png" width="575" height="411"></p>
</div>
</div>
<p>We need some starting values. Having centered the year variable, <span class="math inline">\(\beta_2\)</span> seems plausibly like it would be order of magnitude of 10, which is about the magnitude of the year values.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>beta2_init <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>implicit_covar <span class="op">=</span> np.exp(data.year<span class="op">/</span>beta2_init)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(implicit_covar)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(data.co2, X).fit()</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>beta0_init, beta1_init <span class="op">=</span> model.params</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(data.year, data.co2)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(params):</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> params[<span class="dv">0</span>] <span class="op">+</span> params[<span class="dv">1</span>] <span class="op">*</span> np.exp(data.year <span class="op">/</span> params[<span class="dv">2</span>])</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> (beta0_init, beta1_init, beta2_init)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.plot(data.year, fit(beta), <span class="st">'-'</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-8-output-1.png" width="575" height="411"></p>
</div>
</div>
<p>That’s not great. How about changing the scale of beta2 more?</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>beta2_init <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>implicit_covar <span class="op">=</span> np.exp(data.year<span class="op">/</span>beta2_init)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(implicit_covar)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(data.co2, X).fit()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>beta0_init, beta1_init <span class="op">=</span> model.params</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(data.year, data.co2)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> (beta0_init, beta1_init, beta2_init)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.plot(data.year, fit(beta), <span class="st">'-'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-9-output-1.png" width="575" height="411"></p>
</div>
</div>
<p>Let’s get derivative information using automatic differentation (the algorithmic implementation of the chain rule for derivatives also used in gradient descent in deep learning, as well as various other contexts). We’ll use Jax, but PyTorch or Tensorflow are other options. We need to use the Jax versions of various numpy operations in order to be able to get the derivatives.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss(params):</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    fitted <span class="op">=</span> params[<span class="dv">0</span>] <span class="op">+</span> params[<span class="dv">1</span>]<span class="op">*</span>jnp.exp(jnp.array(data.year)<span class="op">/</span>params[<span class="dv">2</span>])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jnp.<span class="bu">sum</span>((fitted <span class="op">-</span> jnp.array(data.co2))<span class="op">**</span><span class="fl">2.0</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>deriv1 <span class="op">=</span> jax.grad(loss)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>deriv2 <span class="op">=</span> jax.hessian(loss)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>deriv1(jnp.array([beta0_init, beta1_init, beta2_init]))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>hess <span class="op">=</span> deriv2(jnp.array([beta0_init, beta1_init, beta2_init]))</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>hess</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>np.linalg.eig(hess)[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>array([ 2.6369040e+02, -2.5794024e-03,  1.3906310e+01], dtype=float32)</code></pre>
</div>
</div>
<p>The Hessian is not positive definite. We could try tricks such as adding to the diagonal of the Hessian or using the pseudo-inverse (i.e., setting all negative eigenvalues in the inverse to zero).</p>
<p>Instead, let’s try a bit more to find starting values where the Hessian is positive definite. The order of magnitude of our initial value for <span class="math inline">\(\beta_2\)</span> seems about right, so let’s try halving or doubling it.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>beta2_init <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>implicit_covar <span class="op">=</span> np.exp(data.year<span class="op">/</span>beta2_init)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(implicit_covar)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(data.co2, X).fit()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>beta0_init, beta1_init <span class="op">=</span> model.params</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>hess <span class="op">=</span> deriv2(jnp.array([beta0_init, beta1_init, beta2_init]))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>np.linalg.eig(hess)[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>array([3.0403909e+02, 2.4109183e-01, 5.5710766e+01], dtype=float32)</code></pre>
</div>
</div>
<p>That seems better. Let’s try with that.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>n_it <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>xvals <span class="op">=</span> np.zeros(shape <span class="op">=</span> (n_it, <span class="dv">3</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>xvals[<span class="dv">0</span>, :] <span class="op">=</span> (beta0_init, beta1_init, beta2_init)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_it):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  jxvals <span class="op">=</span> jnp.array(xvals[t<span class="op">-</span><span class="dv">1</span>, :])</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  hess <span class="op">=</span> deriv2(jxvals)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  e <span class="op">=</span> np.linalg.eig(hess)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(np.<span class="bu">any</span>(e[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="dv">0</span>)):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"not positive definite"</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  xvals[t, :] <span class="op">=</span> xvals[t<span class="op">-</span><span class="dv">1</span>, :] <span class="op">-</span> np.linalg.solve(hess, deriv1(jxvals))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(loss(xvals[t,:]))</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="op">=</span> xvals[t,:]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(data.year, data.co2)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>plt.plot(data.year, fit(beta_hat), <span class="st">'r-'</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>38.304596
30.817617
30.444086
30.442629
30.44241
30.442383
30.442421
30.442448
30.442455</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="unit11-optim_files/figure-html/cell-12-output-2.png" width="575" height="411"></p>
</div>
</div>
<p>That looks pretty good, but the lack of positive definiteness/sensitivity to starting values should make us cautious. That said, in this case we can visually assess the fit and see that it looks pretty good.</p>
<p>Next we’ll see that some optimization methods used commonly for statistical models (in particular Fisher scoring and iterative reweighted least squares (IRLS or IWLS) are just Newton-Raphson in disguise.</p>
</section>
<section id="fisher-scoring-variant-on-n-r-optional" class="level2">
<h2 class="anchored" data-anchor-id="fisher-scoring-variant-on-n-r-optional">Fisher scoring variant on N-R (optional)</h2>
<p>The Fisher information (FI) is the expected value of the outer product of the gradient of the log-likelihood with itself</p>
<p><span class="math display">\[I(\theta)=E_{f}(\nabla f(y)\nabla f(y)^{\top}),\]</span></p>
<p>where the expected value is with respect to the data distribution. Under regularity conditions (true for exponential families), the expectation of the Hessian of the log-likelihood is minus the Fisher information, <span class="math inline">\(E_{f}H_{f}(y)=-I(\theta)\)</span>. We get the observed Fisher information by plugging the data values into either expression instead of taking the expected value.</p>
<p>Thus, standard N-R can be thought of as using the observed Fisher information to find the updates. Instead, if we can compute the expectation, we can use minus the FI in place of the Hessian. The result is the Fisher scoring (FS) algorithm. Basically instead of using the Hessian for a given set of data, we are using the FI, which we can think of as the average Hessian over repeated samples of data from the data distribution. FS and N-R have the same convergence properties (i.e., quadratic convergence) but in a given problem, one may be computationally or analytically easier. Givens and Hoeting comment that FS works better for rapid improvements at the beginning of iterations and N-R better for refinement at the end. <span class="math display">\[\begin{aligned}
(NR):\,\theta_{t+1} &amp; = &amp; \theta_{t}-H_{f}(\theta_{t})^{-1}\nabla f(\theta_{t})\\
(FS):\,\theta_{t+1} &amp; = &amp; \theta_{t}+I(\theta_{t})^{-1}\nabla f(\theta_{t})\end{aligned}\]</span></p>
<p>The Gauss-Newton algorithm for nonlinear least squares involves using the FI in place of the Hessian in determining a Newton-like step. <code>nls()</code> in R uses this approach.</p>
<section id="connections-between-statistical-uncertainty-and-ill-conditionedness" class="level4">
<h4 class="anchored" data-anchor-id="connections-between-statistical-uncertainty-and-ill-conditionedness">Connections between statistical uncertainty and ill-conditionedness</h4>
<p>When either the observed or expected FI matrix is nearly singular this means we have a small eigenvalue in the inverse covariance (the precision), which means a large eigenvalue in the covariance matrix. This indicates some linear combination of the parameters has low precision (high variance), and that in that direction the likelihood is nearly flat. As we’ve seen with N-R, convergence slows with shallow gradients, and we may have numerical problems in determining good optimization steps when the likelihood is sufficiently flat. So convergence problems and statistical uncertainty go hand in hand. One, but not the only, example of this occurs when we have nearly collinear regressors.</p>
</section>
</section>
<section id="irls-iwls-for-generalized-linear-models-glms" class="level2">
<h2 class="anchored" data-anchor-id="irls-iwls-for-generalized-linear-models-glms">IRLS (IWLS) for Generalized Linear Models (GLMs)</h2>
<p>As many of you know, iterative reweighted least squares (also called iterative weighted least squares) is the standard method for estimation with GLMs. It involves linearizing the model and using working weights and working variances and solving a weighted least squares (WLS) problem (recalling that the generic WLS solution is <span class="math inline">\(\hat{\beta}=(X^{\top}WX)^{-1}X^{\top}WY\)</span>).</p>
<p>Exponential families can be expressed as <span class="math display">\[f(y;\theta,\phi)=\exp((y\theta-b(\theta))/a(\phi)+c(y,\phi)),\]</span> with <span class="math inline">\(E(Y)=b^{\prime}(\theta)\)</span> and <span class="math inline">\(\mbox{Var}(Y)=b^{\prime\prime}(\theta)\)</span>. If we have a GLM in the canonical parameterization (log link for Poisson data, logit for binomial), we have the natural parameter <span class="math inline">\(\theta\)</span> equal to the linear predictor, <span class="math inline">\(\theta=\eta\)</span>. A standard linear predictor would simply be <span class="math inline">\(\eta=X\beta\)</span>.</p>
<p>Considering N-R for a GLM in the canonical parameterization (and ignoring <span class="math inline">\(a(\phi)\)</span>, which is one for logistic and Poisson regression), one can show that the gradient of the GLM log-likelihood is the inner product of the covariates and a residual vector, <span class="math inline">\(\nabla l(\beta)=(Y-E(Y))^{\top}X\)</span>, and the Hessian is <span class="math inline">\(H_{l}(\beta)=-X^{\top}WX\)</span> where <span class="math inline">\(W\)</span> is a diagonal matrix with <span class="math inline">\(\{\mbox{Var}(Y_{i})\}\)</span> on the diagonal (the working weights). Note that both <span class="math inline">\(E(Y)\)</span> and the variances in <span class="math inline">\(W\)</span> depend on <span class="math inline">\(\beta\)</span>, so these will change as we iteratively update <span class="math inline">\(\beta\)</span>. Therefore, the N-R update is <span class="math display">\[\beta_{t+1}=\beta_{t}+(X^{\top}W_{_{t}}X)^{-1}X^{\top}(Y-E(Y)_{t})\]</span> where <span class="math inline">\(E(Y)_{t}\)</span> and <span class="math inline">\(W_{t}\)</span> are the values at the current parameter estimate, <span class="math inline">\(\beta_{t}\)</span> . For example, for logistic regression (here with <span class="math inline">\(n_{i}=1\)</span>), <span class="math inline">\(W_{t,ii}=p_{ti}(1-p_{ti})\)</span> and <span class="math inline">\(E(Y)_{ti}=p_{ti}\)</span> where <span class="math inline">\(p_{ti}=\frac{\exp(X_{i}^{\top}\beta_{t})}{1+\exp(X_{i}^{\top}\beta_{t})}\)</span>. In the canonical parameterization of a GLM, the Hessian does not depend on the data, so the observed and expected FI are the same, and therefore N-R and FS are the same.</p>
<p>The update above can be rewritten in the standard form of IRLS as a WLS problem, <span class="math display">\[\begin{aligned}
\beta_{t+1} &amp; = \beta_{t}+(X^{\top}W_{_{t}}X)^{-1}X^{\top}(Y-E(Y)_{t})\\
&amp; = (X^{\top}W_{_{t}}X)^{-1}(X^{\top}W_{_{t}}X)\beta_{t}+(X^{\top}W_{_{t}}X)^{-1}X^{\top}(Y-E(Y)_{t})\\
&amp; = (X^{\top}W_{_{t}}X)^{-1}X^{\top}W_{t}\left[X\beta_{t}+W_{t}^{-1}(Y-E(Y)_{t})\right]\\
&amp; = (X^{\top}W_{_{t}}X)^{-1}X^{\top}W_{t}\tilde{Y}_{t},\end{aligned}\]</span> where the so-called working observations are <span class="math inline">\(\tilde{Y}_{t}=X\beta_{t}+W_{t}^{-1}(Y-E(Y)_{t})\)</span>. Note that these are on the scale of the linear predictor. The interpretation is that the working observations are equal to the current fitted values, <span class="math inline">\(X\beta_{t}\)</span>, plus weighted residuals where the weight (the inverse of the variance) takes the actual residuals and scales to the scale of the linear predictor.</p>
<p>While IRLS is standard for GLMs, you can also use general purpose optimization routines.</p>
<p>IRLS is a special case of the general Gauss-Newton method for nonlinear least squares.</p>
</section>
<section id="descent-methods-and-newton-like-methods" class="level2">
<h2 class="anchored" data-anchor-id="descent-methods-and-newton-like-methods">Descent methods and Newton-like methods</h2>
<p>More generally a Newton-like method has updates of the form <span class="math display">\[x_{t+1}=x_{t}-\alpha_{t}M_{t}^{-1}f^{\prime}(x_{t}).\]</span> We can choose <span class="math inline">\(M_{t}\)</span> in various ways, including as an approximation to the second derivative.</p>
<p>This opens up several possibilities:</p>
<ol type="1">
<li><p>using more computationally efficient approximations to the second derivative,</p></li>
<li><p>avoiding steps that do not go in the correct direction (i.e., go uphill when minimizing), and</p></li>
<li><p>scaling by <span class="math inline">\(\alpha_{t}\)</span> so as not to step too far.</p></li>
</ol>
<p>Let’s consider a variety of strategies.</p>
<section id="descent-methods" class="level3">
<h3 class="anchored" data-anchor-id="descent-methods">Descent methods</h3>
<p>The basic strategy is to choose a good direction and then choose the longest step for which the function continues to decrease. Suppose we have a direction, <span class="math inline">\(p_{t}\)</span>. Then we need to move <span class="math inline">\(x_{t+1}=x_{t}+\alpha_{t}p_{t}\)</span>, where <span class="math inline">\(\alpha_{t}\)</span> is a scalar, choosing a good <span class="math inline">\(\alpha_{t}\)</span>. We might use a line search (e.g., bisection or golden section search) to find the local minimum of <span class="math inline">\(f(x_{t}+\alpha_{t}p_{t})\)</span> with respect to <span class="math inline">\(\alpha_{t}\)</span>. However, we often would not want to run to convergence, since we’ll be taking additional steps anyway.</p>
<p>Steepest descent chooses the direction as the steepest direction downhill, setting <span class="math inline">\(M_{t}=I\)</span>, since the gradient gives the steepest direction uphill (the negative sign in the equation below has us move directly downhill rather than directly uphill). Given the direction, we want to scale the step <span class="math display">\[x_{t+1}=x_{t}-\alpha_{t}f^{\prime}(x_{t})\]</span> where the contraction, or step length, parameter <span class="math inline">\(\alpha_{t}\)</span> is chosen sufficiently small to ensure that we descend, via some sort of line search. The critical downside to steepest descent is that when the contours are elliptical, it tends to zigzag; here’s an example.</p>
<p>My original code for this was in R, so I’m just leaving it that way rather than having to do a lot of fine-tuning to get the image to display the way I want in Python.</p>
<p>(Note that I do a full line search (using the golden section method via <code>optimize()</code>) at each step in the direction of steepest descent - this is generally computationally wasteful, but I just want to illustrate how steepest descent can go wrong, even if you go the “right” amount in each direction.)</p>
<pre><code>par(mai = c(.5,.4,.1,.4))
f &lt;- function(x){
    x[1]^2/1000 + 4*x[1]*x[2]/1000 + 5*x[2]^2/1000
}
fp &lt;- function(x){
    c(2 * x[1]/1000 + 4 * x[2]/1000,
    4 * x[1]/1000 + 10 * x[2]/1000)
}
lineSearch &lt;- function(alpha, xCurrent, direction, FUN){
    newx &lt;- xCurrent + alpha * direction
    FUN(newx)
}
nIt &lt;- 50
xvals &lt;- matrix(NA, nr = nIt, nc = 2)
xvals[1, ] &lt;- c(7, -4)
for(t in 2:50){
    newalpha &lt;- optimize(lineSearch, interval = c(-5000, 5000),
        xCurrent = xvals[t-1, ], direction = fp(xvals[t-1, ]),
        FUN = f)$minimum 
    xvals[t, ] &lt;- xvals[t-1, ] + newalpha * fp(xvals[t-1, ])
}
x1s &lt;- seq(-5, 8, len = 100); x2s = seq(-5, 2, len = 100)
fx &lt;- apply(expand.grid(x1s, x2s), 1, f)
## plot f(x) surface on log scale
fields::image.plot(x1s, x2s, matrix(log(fx), 100, 100), 
    xlim = c(-5, 8), ylim = c(-5,2)) 
lines(xvals) ## overlay optimization path</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="steep-descent.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Path of steepest descent</figcaption>
</figure>
</div>
<p>If the contours are circular, steepest descent works well. Newton’s method deforms elliptical contours based on the Hessian. Another way to think about this is that steepest descent does not take account of the rate of change in the gradient, while Newton’s method does.</p>
<p>The general descent algorithm is <span class="math display">\[x_{t+1}=x_{t}-\alpha_{t}M_{t}^{-1}f'(x_{t}),\]</span> where <span class="math inline">\(M_{t}\)</span> is generally chose to approximate the Hessian and <span class="math inline">\(\alpha_{t}\)</span> allows us to adjust the step in a smart way. Basically, since the negative gradient tells us the direction that descends (at least within a small neighborhood), if we don’t go too far, we should be fine and should work our way downhill. One can work this out formally using a Taylor approximation to <span class="math inline">\(f(x_{t+1})-f(x_{t})\)</span> and see that we make use of <span class="math inline">\(M_{t}\)</span> being positive definite. (Unfortunately backtracking with positive definite <span class="math inline">\(M_{t}\)</span> does not give a theoretical guarantee that the method will converge. We also need to make sure that the steps descend sufficiently quickly and that the algorithm does not step along a level contour of <span class="math inline">\(f\)</span>.)</p>
<p>The conjugate gradient algorithm for iteratively solving large systems of equations is all about choosing the direction and the step size in a smart way given the optimization problem at hand.</p>
</section>
<section id="quasi-newton-methods-such-as-bfgs" class="level3">
<h3 class="anchored" data-anchor-id="quasi-newton-methods-such-as-bfgs">Quasi-Newton methods such as BFGS</h3>
<p>Other replacements for the Hessian matrix include estimates that do not vary with <span class="math inline">\(t\)</span> and finite difference approximations. When calculating the Hessian is expensive, it can be very helpful to substitute an approximation.</p>
<p>A basic finite difference approximation requires us to compute finite differences in each dimension, but this could be computationally burdensome. A more efficient strategy for choosing <span class="math inline">\(M_{t+1}\)</span> is to (1) make use of <span class="math inline">\(M_{t}\)</span> and (2) make use of the most recent step to learn about the curvature of <span class="math inline">\(f^{\prime}(x)\)</span> in the direction of travel. One approach is to use a rank one update to <span class="math inline">\(M_{t}\)</span>.</p>
<p>A basic strategy is to choose <span class="math inline">\(M_{t+1}\)</span> such that the secant condition is satisfied: <span class="math display">\[M_{t+1}(x_{t+1}-x_{t})=\nabla f(x_{t+1})-\nabla f(x_{t}),\]</span> which is motivated by the fact that the secant approximates the gradient in the direction of travel. Basically this says to modify <span class="math inline">\(M_{t}\)</span> in such a way that we incorporate what we’ve learned about the gradient from the most recent step. <span class="math inline">\(M_{t+1}\)</span> is not fully determined based on this, and we generally impose other conditions, in particular that <span class="math inline">\(M_{t+1}\)</span> is symmetric and positive definite. Defining <span class="math inline">\(s_{t}=x_{t+1}-x_{t}\)</span> and <span class="math inline">\(y_{t}=\nabla f(x_{t+1})-\nabla f(x_{t})\)</span>, the unique, symmetric rank one update (why is the following a rank one update?) that satisfies the secant condition is <span class="math display">\[M_{t+1}=M_{t}+\frac{(y_{t}-M_{t}s_{t})(y_{t}-M_{t}s_{t})^{\top}}{(y_{t}-M_{t}s_{t})^{\top}s_{t}}.\]</span> If the denominator is positive, <span class="math inline">\(M_{t+1}\)</span> may not be positive definite, but this is guaranteed for non-positive values of the denominator. One can also show that one can achieve positive definiteness by shrinking the denominator toward zero sufficiently.</p>
<p>A standard approach to updating <span class="math inline">\(M_{t}\)</span> is a commonly-used rank two update that generally results in <span class="math inline">\(M_{t+1}\)</span> being positive definite is <span class="math display">\[M_{t+1}=M_{t}-\frac{M_{t}s_{t}(M_{t}s_{t})^{\top}}{s_{t}^{\top}M_{t}s_{t}}+\frac{y_{t}y_{t}^{\top}}{s_{t}^{\top}y_{t}},\]</span> which is known as the Broyden-Fletcher-Goldfarb-Shanno (BFGS) update. This is one of the methods used in R in <em>optim()</em>.</p>
<p>Question: how can we update <span class="math inline">\(M_{t}^{-1}\)</span> to <span class="math inline">\(M_{t+1}^{-1}\)</span> efficiently? It turns out there is a way to update the Cholesky of <span class="math inline">\(M_{t}\)</span> efficiently and this is a better approach than updating the inverse.</p>
<p>The order of convergence of quasi-Newton methods is generally slower than the quadratic convergence of N-R because of the approximations but still faster than linear. In general, quasi-Newton methods will do much better if the scales of the elements of <span class="math inline">\(x\)</span> are similar. Lange suggests using a starting point for which one can compute the expected information, to provide a good starting value <span class="math inline">\(M_{0}\)</span>.</p>
<p>Note that for estimating a covariance based on the numerical information matrix, we would not want to rely on <span class="math inline">\(M_{t}\)</span> from the final iteration, as the approximation may be poor. Rather we would spend the effort to better estimate the Hessian directly at <span class="math inline">\(x^{*}\)</span>.</p>
</section>
<section id="stochastic-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent">Stochastic gradient descent</h3>
<p>Stochastic gradient descent (SGD) is the hot method in machine learning, commonly used for fitting deep neural networks. It allows you to optimize an objective function with respect to what is often a very large number of parameters even when the data size is huge.</p>
<p>Gradient descent is a simplification of Newton’s method that does not rely on the second derivative, but rather chooses the direction using the gradient and then a step size, <span class="math inline">\(\alpha_{t}\)</span>: <span class="math display">\[x_{t+1}=x_{t}-\alpha_{t}f^{\prime}(x_{t})\]</span></p>
<p>The basic idea of stochastic gradient descent is to replace the gradient with a function whose expected value is the gradient, <span class="math inline">\(E(g(x_{t}))=f^{\prime}(x_{t})\)</span>: <span class="math display">\[x_{t+1}=x_{t}-\alpha_{t}g(x_{t})\]</span> Thus on average we should go in a good (downhill) direction. Given that we know that strictly following the gradient can lead to slow convergence, it makes some intuitive sense that we could still do ok without using the exact gradient. One can show formally that SGD will converge for convex functions.</p>
<p>SGD can be used in various contexts, but the common one we will focus on is when <span class="math display">\[\begin{aligned}
f(x) &amp; = \sum_{i=1}^{n}f_{i}(x)\\
f^{\prime}(x) &amp; = \sum_{i=1}^{n}f^{\prime}_{i}(x)\end{aligned}\]</span> for large <span class="math inline">\(n\)</span>. Thus calculation of the gradient is <span class="math inline">\(O(n)\)</span>, and we may not want to incur that computational cost. How could we implement SGD in such a case? At each iteration we could randomly choose an observation and compute the contribution to the gradient from that data point, or we could choose a random subset of the data (this is <em>mini-batch SGD</em>), or there are variations where we systematically cycle through the observations or cycle through subsets. However, in some situations, convergence is actually much faster when using randomness. And if the data are ordered in some meaningful way we definitely do not want to cycle through the observations in that order, as this can result in a biased estimate of the gradient and slow convergence. So one generally randomly shuffles the data before starting SGD. Note that using subsets rather than individual observations is likely to be more effective as it can allow us to use optimized matrix/vector computations.</p>
<p>How should one choose the step size, <span class="math inline">\(\alpha_{t}\)</span> (also called the learning rate)? One might think that as one gets close to the optimum, if one isn’t careful, one might simply bounce around near the optimum in a random way, without actually converging to the optimum. So intuition suggests that <span class="math inline">\(\alpha_{t}\)</span> should decrease with <span class="math inline">\(t\)</span>. Some choices of step size have included:</p>
<ul>
<li><span class="math inline">\(\alpha_{t}=1/t\)</span></li>
<li>set a schedule, such that for <span class="math inline">\(T\)</span> iterations, <span class="math inline">\(\alpha_{t}=\alpha\)</span>, then for the next <span class="math inline">\(T\)</span>, <span class="math inline">\(\alpha_{t}=\alpha\gamma\)</span>, then for the next <span class="math inline">\(T\)</span>, <span class="math inline">\(\alpha_{t}=\alpha\gamma^{2}\)</span>. A heuristic is for <span class="math inline">\(\gamma\in(0.8,0.9)\)</span>.</li>
<li>run with <span class="math inline">\(\alpha_{t}=\alpha\)</span> for <span class="math inline">\(T\)</span> iterations, then with <span class="math inline">\(\alpha_{t}=\alpha/2\)</span> for <span class="math inline">\(2T\)</span>, then with <span class="math inline">\(\alpha_{t}=\alpha/4\)</span> for <span class="math inline">\(4T\)</span> and so forth.</li>
</ul>
</section>
</section>
<section id="coordinate-descent-gauss-seidel" class="level2">
<h2 class="anchored" data-anchor-id="coordinate-descent-gauss-seidel">Coordinate descent (Gauss-Seidel)</h2>
<p>Gauss-Seidel is also known a back-fitting or cyclic coordinate descent. The basic idea is to work element by element rather than having to choose a direction for each step. For example backfitting used to be used to fit generalized additive models of the form <span class="math inline">\(E(Y)=f_{1}(z_{1})+f_{2}(z_{2})+\ldots+f_{p}(z_{p})\)</span>.</p>
<p>The basic strategy is to consider the <span class="math inline">\(j\)</span>th component of <span class="math inline">\(f^{\prime}(x)\)</span> as a univariate function of <span class="math inline">\(x_{j}\)</span> only and find the root, <span class="math inline">\(x_{j,t+1}\)</span> that gives <span class="math inline">\(f^{\prime}_{j}(x_{j,t+1})=0\)</span>. One cycles through each element of <span class="math inline">\(x\)</span> to complete a single cycle and then iterates. The appeal is that univariate root-finding/minimization is easy, often more stable than multivariate, and quick.</p>
<p>However, Gauss-Seidel can zigzag, since you only take steps in one dimension at a time, as we see here. (Again the code is in R.)</p>
<pre><code>f &lt;- function(x){
    return(x[1]^2/1000 + 4*x[1]*x[2]/1000 + 5*x[2]^2/1000)
}
f1 &lt;- function(x1, x2){ # f(x) as a function of x1
    return(x1^2/1000 + 4*x1*x2/1000 + 5*x2^2/1000)
}
f2 &lt;- function(x2, x1){ # f(x) as a function of x2
    return(x1^2/1000 + 4*x1*x2/1000 + 5*x2^2/1000)
}
x1s &lt;- seq(-5, 8, len = 100); x2s = seq(-5, 2, len = 100)
fx &lt;- apply(expand.grid(x1s, x2s), 1, f)
fields::image.plot(x1s, x2s, matrix(log(fx), 100, 100))
nIt &lt;- 49
xvals &lt;- matrix(NA, nr = nIt, nc = 2)
xvals[1, ] &lt;- c(7, -4)
## 5, -10
for(t in seq(2, nIt, by = 2)){
    ## Note that full optimization along each axis is unnecessarily
    ## expensive (since we are going to just take another step in the next
    ## iteration. Just using for demonstration here.
    newx1 &lt;- optimize(f1, x2 = xvals[t-1, 2], interval = c(-40, 40))$minimum
    xvals[t, ] &lt;- c(newx1, xvals[t-1, 2])
    newx2 &lt;- optimize(f2, x1 = newx1, interval = c(-40, 40))$minimum
    xvals[t+1, ] &lt;- c(newx1, newx2)
}
lines(xvals)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gauss-seidel.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Coordinate descent</figcaption>
</figure>
</div>
<p>In the notes for Unit 9 on linear algebra, I discussed the use of Gauss-Seidel to iteratively solve <span class="math inline">\(Ax=b\)</span> in situations where factorizing <span class="math inline">\(A\)</span> (which of course is <span class="math inline">\(O(n^{3})\)</span>) is too computationally expensive.</p>
<section id="the-lasso" class="level4">
<h4 class="anchored" data-anchor-id="the-lasso">The lasso</h4>
<p>The <em>lasso</em> uses an L1 penalty in regression and related contexts. A standard formulation for the lasso in regression is to minimize <span class="math display">\[\|Y-X\beta\|_{2}^{2}+\lambda\sum_{j}|\beta_{j}|\]</span> to find <span class="math inline">\(\hat{\beta}(\lambda)\)</span> for a given value of the penalty parameter, <span class="math inline">\(\lambda\)</span>. A standard strategy to solve this problem is to use coordinate descent, either cyclically, or by using directional derivatives to choose the coordinate likely to decrease the objective function the most (a greedy strategy). We need to use directional derivatives because the penalty function is not differentiable, but does have directional derivatives in each direction. The directional derivative of the objective function for <span class="math inline">\(\beta_{j}\)</span> is <span class="math display">\[-2\sum_{i}x_{ij}(Y_{i}-X_{i}^{\top}\beta)\pm\lambda\]</span> where we add <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(\beta_{j}\geq0\)</span> and you subtract <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(\beta_{j}&lt;0\)</span>. If <span class="math inline">\(\beta_{j,t}\)</span> is 0, then a step in either direction contributes <span class="math inline">\(+\lambda\)</span> to the derivative as the contribution of the penalty.</p>
<p>Once we have chosen a coordinate, we set the directional derivative to zero and solve for <span class="math inline">\(\beta_{j}\)</span> to obtain <span class="math inline">\(\beta_{j,t+1}\)</span>.</p>
<p>The <code>glmnet</code> package in R (described in <a href="http://www.jstatsoft.org/article/view/v033i01">this Journal of Statistical Software paper</a>) implements such optimization for a variety of penalties in linear model and GLM settings, including the lasso. This <a href="http://biostatistics.oxfordjournals.org/content/early/2013/10/04/biostatistics.kxt043.short">Mittal et al. paper</a> describes similar optimization for survival analysis with very large <span class="math inline">\(p\)</span>, exploiting sparsity in the <span class="math inline">\(X\)</span> matrix for computational efficiency; note that they do not use Newton-Raphson because the matrix operations are infeasible computationally.</p>
<p>One nice idea that is used in lasso and related settings is the idea of finding the regression coefficients for a variety of values of <span class="math inline">\(\lambda\)</span>, combined with “warm starts”. A general approach is to start with a large value of <span class="math inline">\(\lambda\)</span> for which all the coefficients are zero and then decrease <span class="math inline">\(\lambda\)</span>. At each new value of <span class="math inline">\(\lambda\)</span>, use the estimated coefficients from the previous value as the starting values. This should allow for fast convergence and gives what is called the “solution path”. Often <span class="math inline">\(\lambda\)</span> is chosen based on cross-validation.</p>
<p>The LARS (least angle regression) algorithm uses a similar strategy that allows one to compute <span class="math inline">\(\hat{\beta}_{\lambda}\)</span> for all values of <span class="math inline">\(\lambda\)</span> at once.</p>
<p>The lasso can also be formulated as the constrained minimization of <span class="math inline">\(\|Y-X\beta\|_{2}^{2}\)</span> s.t. <span class="math inline">\(\sum_{j}|\beta_{j}|\leq c\)</span>, with <span class="math inline">\(c\)</span> now playing the role of the penalty parameter. Solving this minimization problem would take us in the direction of quadratic programming, a special case of convex programming, discussed in Section 9.</p>
</section>
</section>
<section id="nelder-mead" class="level2">
<h2 class="anchored" data-anchor-id="nelder-mead">Nelder-Mead</h2>
<p>This approach avoids using derivatives or approximations to derivatives. This makes it robust, but also slower than Newton-like methods. The basic strategy is to use a simplex, a polytope of <span class="math inline">\(p+1\)</span> points in <span class="math inline">\(p\)</span> dimensions (e.g., a triangle when searching in two dimensions, tetrahedron in three dimensions...) to explore the space, choosing to shift, expand, or contract the polytope based on the evaluation of <span class="math inline">\(f\)</span> at the points.</p>
<p>The algorithm relies on four tuning factors: a reflection factor, <span class="math inline">\(\alpha&gt;0\)</span>; an expansion factor, <span class="math inline">\(\gamma&gt;1\)</span>; a contraction factor, <span class="math inline">\(0&lt;\beta&lt;1\)</span>; and a shrinkage factor, <span class="math inline">\(0&lt;\delta&lt;1\)</span>. First one chooses an initial simplex: <span class="math inline">\(p+1\)</span> points that serve as the vertices of a convex hull.</p>
<ol type="1">
<li><p>Evaluate and order the points, <span class="math inline">\(x_{1},\ldots,x_{p+1}\)</span> based on <span class="math inline">\(f(x_{1})\leq\ldots\leq f(x_{p+1})\)</span>. Let <span class="math inline">\(\bar{x}\)</span> be the average of the first <span class="math inline">\(p\)</span> <span class="math inline">\(x\)</span>’s.</p></li>
<li><p>(Reflection) Reflect <span class="math inline">\(x_{p+1}\)</span> across the hyperplane (a line when <span class="math inline">\(p+1=3\)</span>) formed by the other points to get <span class="math inline">\(x_{r}\)</span>, based on <span class="math inline">\(\alpha\)</span>.</p>
<ul>
<li><span class="math inline">\(x_{r}=(1+\alpha)\bar{x}-\alpha x_{p+1}\)</span></li>
</ul></li>
<li><p>If <span class="math inline">\(f(x_{r})\)</span> is between the best and worst of the other points, the iteration is done, with <span class="math inline">\(x_{r}\)</span> replacing <span class="math inline">\(x_{p+1}\)</span>. We’ve found a good direction to move.</p></li>
<li><p>(Expansion) If <span class="math inline">\(f(x_{r})\)</span> is better than all of the other points, expand by extending <span class="math inline">\(x_{r}\)</span> to <span class="math inline">\(x_{e}\)</span> based on <span class="math inline">\(\gamma\)</span>, because this indicates the optimum may be further in the direction of reflection. If <span class="math inline">\(f(x_{e})\)</span> is better than <span class="math inline">\(f(x_{r})\)</span>, use <span class="math inline">\(x_{e}\)</span> in place of <span class="math inline">\(x_{p+1}\)</span>. If not, use <span class="math inline">\(x_{r}\)</span>. The iteration is done.</p>
<ul>
<li><span class="math inline">\(x_{e}=\gamma x_{r}+(1-\gamma)\bar{x}\)</span></li>
</ul></li>
<li><p>If <span class="math inline">\(f(x_{r})\)</span> is worse than all the other points, but better than <span class="math inline">\(f(x_{p+1})\)</span>, let <span class="math inline">\(x_{h}=x_{r}\)</span>. Otherwise <span class="math inline">\(f(x_{r})\)</span> is worse than <span class="math inline">\(f(x_{p+1})\)</span> so let <span class="math inline">\(x_{h}=x_{p+1}\)</span>. In either case, we want to concentrate our polytope toward the other points.</p>
<ol type="a">
<li><p>(Contraction) Contract <span class="math inline">\(x_{h}\)</span> toward the hyperplane formed by the other points, based on <span class="math inline">\(\beta\)</span>, to get <span class="math inline">\(x_{c}\)</span>. If the result improves upon <span class="math inline">\(f(x_{h})\)</span> replace <span class="math inline">\(x_{p+1}\)</span> with <span class="math inline">\(x_{c}\)</span>. Basically, we haven’t found a new point that is better than the other points, so we want to contract the simplex away from the bad point.</p>
<ul>
<li><span class="math inline">\(x_{c}=\beta x_{h}+(1-\beta)\bar{x}\)</span></li>
</ul></li>
<li><p>(Shrinkage) Otherwise (if <span class="math inline">\(x_{c}\)</span> is not better than <span class="math inline">\(x_{h}\)</span>), replace <span class="math inline">\(x_{p+1}\)</span> with <span class="math inline">\(x_{h}\)</span> and shrink the simplex toward <span class="math inline">\(x_{1}\)</span>. Basically this suggests our step sizes are too large and we should shrink the simplex, shrinking towards the best point.</p>
<ul>
<li><span class="math inline">\(x_{i}=\delta x_{i}+(1-\delta)x_{1}\)</span> for <span class="math inline">\(i=2,\ldots,p+1\)</span></li>
</ul></li>
</ol></li>
</ol>
<p>Convergence is assessed based on the sample variance of the function values at the points, the total of the norms of the differences between the points in the new and old simplexes, or the size of the simplex. In class we’ll work through some demo code (not shown here) that illustrates the individual steps in an iteration of Nelder-Mead.</p>
<p>We can see the points at which the function was evaluated in the same quadratic example we saw in previous sections. The left hand panel shows the steps from a starting point somewhat far from the optimum, with the first 9 points numbered. In this case, we start with points 1, 2, and 3. Point 4 is a reflection. At this point, it looks like point 5 is a contraction but that doesn’t exactly follow the algorithm above (since Point 4 is between Points 2 and 3 so the iteration should end without a contraction), so perhaps the algorithm as implemented is a bit different than as described above. In any event, the new set is (2, 3, 4). Then point 6 and point 7 are reflection and expansion steps and the new set is (3, 4, 6). Points 8 and 9 are again reflection and expansion steps. The right hand panel shows the steps from a starting point near (actually at) the optimum. Points 4 and 5 are reflection and expansion steps, with the next set being (1, 2, 5). Now step 6 is a reflection but it is the worst of all the points, so point 7 is a contraction of point 2 giving the next set (1, 5, 7). Point 8 is then a reflection and point 9 is a contraction of point 5.</p>
<p>(Again some code in R.)</p>
<pre><code>f &lt;- function(x, plot = TRUE, verbose = FALSE) {
    result &lt;- x[1]^2/1000 + 4*x[1]*x[2]/1000 + 5*x[2]^2/1000
    if(verbose) print(result)
    if(plot &amp;&amp; cnt &lt; 10) {
        points(x[1], x[2], pch = as.character(cnt))
        if(cnt &lt; 10) cnt &lt;&lt;- cnt + 1 else cnt &lt;&lt;- 1
        if(interactive())
            invisible(readline(prompt = "Press &lt;Enter&gt; to continue..."))
    } else if(plot) points(x[1], x[2])
    return(result)
}

par(mfrow = c(1,2), mgp = c(1.8,.7,0), mai = c(.5,.45,.1,.5), cex = 0.7)

x1s &lt;- seq(-5, 10, len = 100); x2s = seq(-5, 2, len = 100)
fx &lt;- apply(expand.grid(x1s, x2s), 1, f, FALSE)
cnt &lt;- 1
fields::image.plot(x1s, x2s, matrix(log(fx), 100, 100))
init &lt;- c(7, -4)
optim(init, f, method = "Nelder-Mead", verbose = FALSE)

par(cex = 0.7)
x1s &lt;- seq(-.2, .2, len = 100); x2s = seq(-.12, .12, len = 100)
fx &lt;- apply(expand.grid(x1s, x2s), 1, f, FALSE)
cnt &lt;- 1
fields::image.plot(x1s, x2s, matrix(log(fx), 100, 100))
init &lt;- c(-0, 0)
optim(init, f, method = "Nelder-Mead", verbose = FALSE)</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nelder-mead.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Nelder-Mead</figcaption>
</figure>
</div>
<p>Here’s an <a href="http://www.benfrederickson.com/numerical-optimization/">online graphical illustration</a> of Nelder-Mead.</p>
<p>This is the default in <code>optim()</code> in R. It is an option (by specifying <code>method='Nelder-mead'</code>) for <code>scipy.optimize.minimize</code> (BFGS or a variant is the default).</p>
</section>
<section id="simulated-annealing-sa-optional" class="level2">
<h2 class="anchored" data-anchor-id="simulated-annealing-sa-optional">Simulated annealing (SA) (optional)</h2>
<p>Simulated annealing is a <em>stochastic</em> descent algorithm, unlike the deterministic algorithms we’ve already discussed. It has a couple critical features that set it aside from other approaches. First, uphill moves are allowed; second, whether a move is accepted is stochastic, and finally, as the iterations proceed the algorithm becomes less likely to accept uphill moves.</p>
<p>Assume we are minimizing a negative log likelihood as a function of <span class="math inline">\(\theta\)</span>, <span class="math inline">\(f(\theta)\)</span>.</p>
<p>The basic idea of simulated annealing is that one modifies the objective function, <span class="math inline">\(f\)</span> in this case, to make it less peaked at the beginning, using a “temperature” variable that changes over time. This helps to allow moves away from local minima, when combined with the ability to move uphill. The name comes from an analogy to heating up a solid to its melting temperature and cooling it slowly - as it cools the atoms go through rearrangements and slowly freeze into the crystal configuration that is at the lowest energy level.</p>
<p>Here’s the algorithm. We divide up iterations into stages, <span class="math inline">\(j=1,2,\ldots\)</span> in which the temperature variable, <span class="math inline">\(\tau_{j}\)</span>, is constant. Like MCMC, we require a proposal distribution to propose new values of <span class="math inline">\(\theta\)</span>.</p>
<ol type="1">
<li><p>Propose to move from <span class="math inline">\(\theta_{t}\)</span> to <span class="math inline">\(\tilde{\theta}\)</span> from a proposal density, <span class="math inline">\(g_{t}(\cdot|\theta_{t})\)</span>, such as a normal distribution centered at <span class="math inline">\(\theta_{t}\)</span>.</p></li>
<li><p>Accept <span class="math inline">\(\tilde{\theta}\)</span> as <span class="math inline">\(\theta_{t+1}\)</span> according to the probability <span class="math inline">\(\min(1,\exp((f(\theta_{t})-f(\tilde{\theta}))/\tau_{j})\)</span> - i.e., accept if a uniform random deviate is less than that probability. Otherwise set <span class="math inline">\(\theta_{t+1}=\theta_{t}\)</span>. Notice that for larger values of <span class="math inline">\(\tau_{j}\)</span> the differences between the function values at the two locations are reduced (just like a large standard deviation spreads out a distribution). So the exponentiation smooths out the objective function when <span class="math inline">\(\tau_{j}\)</span> is large.</p></li>
<li><p>Repeat steps 1 and 2 <span class="math inline">\(m_{j}\)</span> times.</p></li>
<li><p>Increment the temperature and cooling schedule: <span class="math inline">\(\tau_{j}=\alpha(\tau_{j-1})\)</span> and <span class="math inline">\(m_{j}=\beta(m_{j-1})\)</span>. Back to step 1.</p></li>
</ol>
<p>The temperature should slowly decrease to 0 while the number of iterations, <span class="math inline">\(m_{j}\)</span>, should be large. Choosing these ‘schedules’ is at the core of implementing SA. Note that we always accept downhill moves in step 2 but we sometimes accept uphill moves as well.</p>
<p>For each temperature, SA produces an MCMC based on the Metropolis algorithm. So if <span class="math inline">\(m_{j}\)</span> is long enough, we should sample from the stationary distribution of the Markov chain, <span class="math inline">\(\exp(-f(\theta)/\tau_{j}))\)</span>. Provided we can move between local minima, the chain should gravitate toward the global minima because these are increasingly deep (low values) relative to the local minima as the temperature drops. Then as the temperature cools, <span class="math inline">\(\theta_{t}\)</span> should get trapped in an increasingly deep well centered on the global minimum. There is a danger that we will get trapped in a local minimum and not be able to get out as the temperature drops, so the temperature schedule is quite important in trying to avoid this.</p>
<p>A wide variety of schedules have been tried. One approach is to set <span class="math inline">\(m_{j}=1\forall j\)</span> and <span class="math inline">\(\alpha(\tau_{j-1})=\frac{\tau_{j-1}}{1+a\tau_{j-1}}\)</span> for a small <span class="math inline">\(a\)</span>. For a given problem it can take a lot of experimentation to choose <span class="math inline">\(\tau_{0}\)</span> and <span class="math inline">\(m_{0}\)</span> and the values for the scheduling functions. For the initial temperature, it’s a good idea to choose it large enough that <span class="math inline">\(\exp((f(\theta_{i})-f(\theta_{j}))/\tau_{0})\approx1\)</span> for any pair <span class="math inline">\(\{\theta_{i},\theta_{j}\}\)</span> in the domain, so that the algorithm can visit the entire space initially.</p>
<p>Simulated annealing can converge slowly. Multiple random starting points or stratified starting points can be helpful for finding a global minimum. However, given the slow convergence, these can also be computationally burdensome.</p>
</section>
</section>
<section id="basic-optimization-in-python" class="level1">
<h1>6. Basic optimization in Python</h1>
<section id="core-optimization-functions" class="level2">
<h2 class="anchored" data-anchor-id="core-optimization-functions">Core optimization functions</h2>
<p>Scipy provides various useful optimization functions via <code>scipy.optimize</code>, including many of the algorithms discussed in this unit.</p>
<ul>
<li><code>minimize_scalar</code> implements golden section search (<code>golden</code>) and interpolation combined with golden section search (<code>brent</code>, akin to <code>optimize</code> in R).</li>
<li><code>minimize</code> implements various methods for multivariate optimization including Nelder-Mead, BFGS and conjugate gradients (discussed a bit in Unit 9). You can choose which method you prefer and can try multiple methods. You can supply a gradient function for use with the Newton-related methods but it can also calculate numerical derivatives on the fly. You can have the BFGS implementation in <code>minimize</code> return the Hessian at the optimum (based on a numerical estimate), which then allows straighforward calculation of asymptotic variances based on the information matrix.</li>
<li>One can provide a variety of nonlinear, linear, and simple bounds constraints as well, though certain types of constraints can only be used with certain algorithms.</li>
</ul>
<p>In the demo code (not shown here; see the source qmd file), we’ll work our way through a real example of optimizing a likelihood for some climate data on extreme precipitation.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> os.path.join(<span class="st">'..'</span>, <span class="st">'data'</span>, <span class="st">'precipData.txt'</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>y_hundredths <span class="op">=</span> np.genfromtxt(data_file, missing_values <span class="op">=</span> <span class="st">'NA'</span>)  <span class="co"># precip in hundredths of inches</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>y_hundredths <span class="op">=</span> y_hundredths[<span class="op">~</span>np.isnan(y_hundredths)]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y_hundredths <span class="op">/</span> <span class="dv">100</span>  <span class="co"># precip now in inches</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>npy<span class="op">=</span><span class="dv">31</span><span class="op">+</span><span class="dv">28</span><span class="op">+</span><span class="dv">31</span> <span class="co"># number of days in winter season</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>cutoff <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> <span class="fl">25.4</span>  <span class="co"># Convert 1 mm to inches</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> np.percentile(y[y <span class="op">&gt;</span> cutoff], <span class="dv">98</span>,)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of the data</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>plt.hist(y, bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Precipitation (inches)'</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of All Data'</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>plt.hist(y[y <span class="op">&gt;</span> thresh], bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Precipitation (inches)'</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Histogram of Wet Days (Precip &gt; </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(thresh,<span class="dv">2</span>)<span class="sc">}</span><span class="ss"> inches)'</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Define objective (negative log-likelihood) function</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pp_negloglik(par, y, thresh, npy):</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    mu, sc, sh <span class="op">=</span> par</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    uInd <span class="op">=</span> y <span class="op">&gt;</span> thresh</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Invalid parameter values or data/parameter combos:</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sc <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1e6</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="dv">1</span> <span class="op">+</span> ((sh <span class="op">*</span> (thresh <span class="op">-</span> mu)) <span class="op">/</span> sc) <span class="op">&lt;</span> <span class="dv">0</span>):</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1e6</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> (y <span class="op">-</span> mu) <span class="op">/</span> sc</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> sh <span class="op">*</span> y</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.<span class="bu">min</span>(y[uInd]) <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1e6</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>        ytmp <span class="op">=</span> y.copy()</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>        ytmp[<span class="op">~</span>uInd] <span class="op">=</span> <span class="dv">1</span> <span class="co"># 'zeroes' out those below the threshold after applying the log in next line</span></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>        l <span class="op">=</span> np.<span class="bu">sum</span>(uInd <span class="op">*</span> np.log(sc)) <span class="op">+</span> np.<span class="bu">sum</span>(uInd <span class="op">*</span> np.log(ytmp) <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> sh <span class="op">+</span> <span class="dv">1</span>)) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>                   (<span class="bu">len</span>(y) <span class="op">/</span> npy) <span class="op">*</span> np.mean((<span class="dv">1</span> <span class="op">+</span> (sh <span class="op">*</span> (thresh <span class="op">-</span> mu)) <span class="op">/</span> sc) <span class="op">**</span> (<span class="op">-</span><span class="dv">1</span> <span class="op">/</span> sh))</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>                   </span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> l</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial parameter values</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>y_exc <span class="op">=</span> y[y <span class="op">&gt;</span> thresh]</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>in2 <span class="op">=</span> np.sqrt(<span class="dv">6</span> <span class="op">*</span> np.var(y_exc)) <span class="op">/</span> np.pi</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>in1 <span class="op">=</span> np.mean(y_exc) <span class="op">-</span> <span class="fl">0.57722</span> <span class="op">*</span> in2</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>init0 <span class="op">=</span> [in1, in2, <span class="fl">0.1</span>]</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimization using Nelder-Mead</span></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>fit1 <span class="op">=</span> minimize(pp_negloglik, init0, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'Nelder-Mead'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nelder-Mead Optimization:"</span>)</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(fit1)</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution Time:"</span>, end_time <span class="op">-</span> start_time, <span class="st">"seconds"</span>)</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimization using BFGS</span></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>fit2 <span class="op">=</span> minimize(pp_negloglik, init0, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'BFGS'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">BFGS Optimization:"</span>)</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(fit2)</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution Time:"</span>, end_time <span class="op">-</span> start_time, <span class="st">"seconds"</span>)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>mle <span class="op">=</span> fit2.x</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>var <span class="op">=</span> fit2.hess_inv</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> np.sqrt(np.diag(fit2.hess_inv))</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Different starting values</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>init1 <span class="op">=</span> [np.mean(y[y <span class="op">&gt;</span> thresh]), np.std(y[y <span class="op">&gt;</span> thresh]), <span class="op">-</span><span class="fl">0.1</span>]</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>fit1a <span class="op">=</span> minimize(pp_negloglik, init1, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'Nelder-Mead'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>fit2a <span class="op">=</span> minimize(pp_negloglik, init1, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'BFGS'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Bad starting value for BFGS</span></span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>init2 <span class="op">=</span> [thresh, <span class="fl">0.01</span>, <span class="fl">.5</span>]</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>fit1b <span class="op">=</span> minimize(pp_negloglik, init2, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'Nelder-Mead'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>fit2b <span class="op">=</span> minimize(pp_negloglik, init2, args<span class="op">=</span>(y, thresh, npy), method<span class="op">=</span><span class="st">'BFGS'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>fit2b.hess_inv</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Data on a different scale</span></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>y_exc2 <span class="op">=</span> y[y <span class="op">&gt;</span> thresh] <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> y <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>thresh2 <span class="op">=</span> thresh <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>init3 <span class="op">=</span> [np.mean(y_exc2), np.std(y_exc2), <span class="fl">0.1</span>]</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>fit3 <span class="op">=</span> minimize(pp_negloglik, init3, args<span class="op">=</span>(y2, thresh2, npy), method<span class="op">=</span><span class="st">'Nelder-Mead'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>fit4 <span class="op">=</span> minimize(pp_negloglik, init3, args<span class="op">=</span>(y2, thresh2, npy), method<span class="op">=</span><span class="st">'BFGS'</span>, options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>fit4.hess_inv</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the objective function</span></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a>n_grid <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>loc_vals <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, n_grid)</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>scale_vals <span class="op">=</span> np.linspace(<span class="fl">0.1</span>, <span class="dv">3</span>, n_grid)</span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a>shape_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>, <span class="dv">16</span>)</span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>loc_grid, scale_grid, shape_grid <span class="op">=</span> np.meshgrid(loc_vals, scale_vals, shape_vals, indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a>par_grid <span class="op">=</span> np.column_stack((loc_grid.ravel(), scale_grid.ravel(), shape_grid.ravel()))</span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a>obj <span class="op">=</span> np.apply_along_axis(pp_negloglik, <span class="dv">1</span>, par_grid, y<span class="op">=</span>y, thresh<span class="op">=</span>thresh, npy<span class="op">=</span>npy)</span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, shape_value <span class="kw">in</span> <span class="bu">enumerate</span>(shape_vals):</span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>]</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>    obj_matrix <span class="op">=</span> np.array(obj[par_grid[:,<span class="dv">2</span>] <span class="op">==</span> shape_value]).reshape(n_grid, n_grid).T</span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax.imshow(obj_matrix, extent<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="fl">0.1</span>, <span class="dv">3</span>), cmap<span class="op">=</span><span class="st">'viridis'</span>, vmin<span class="op">=</span><span class="dv">40</span>, vmax<span class="op">=</span><span class="dv">80</span>, aspect<span class="op">=</span><span class="st">'auto'</span>, origin<span class="op">=</span><span class="st">'lower'</span>)</span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"shape = </span><span class="sc">{</span>shape_value<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im, ax<span class="op">=</span>axes, label<span class="op">=</span><span class="st">"Objective Function Value"</span>)</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="various-considerations-in-using-the-python-functions" class="level2">
<h2 class="anchored" data-anchor-id="various-considerations-in-using-the-python-functions">Various considerations in using the Python functions</h2>
<p>As we’ve seen, initial values are important both for avoiding divergence (e.g., in N-R), for increasing speed of convergence, and for helping to avoid local optima. So it is well worth the time to try to figure out a good starting value or multiple starting values for a given problem.</p>
<p>Scaling can be important. One useful step is to make sure the problem is well-scaled, namely that a unit step in any parameter has a comparable change in the objective function, preferably approximately a unit change at the optimum. Basically if <span class="math inline">\(x_{j}\)</span> is varying at <span class="math inline">\(p\)</span> orders of magnitude smaller than the other <span class="math inline">\(x\)</span>s, we want to reparameterize to <span class="math inline">\(x_{j}^{*}=x_{j}\cdot10^{p}\)</span> and then convert back to the original scale after finding the answer. Or we may want to work on the log scale for some variables, reparameterizing as <span class="math inline">\(x_{j}^{*}=\log(x_{j})\)</span>.</p>
<p>As far as I can see one needs to do this manually with <code>minimize</code> in Python but <code>optim()</code> in R allows you to supply scaling information through the <code>parscale</code> component of the <code>control</code> argument.</p>
<p>If the function itself gives very large or small values near the solution, you may want to rescale the entire function to avoid calculations with very large or small numbers. This can avoid problems such as having apparent convergence because a gradient is near zero, simply because the scale of the function is small. In <code>optim()</code> in R, this can be controlled with the <code>fnscale</code> component of <code>control</code>.</p>
<p><strong>Always</strong> consider your answer and make sure it makes sense, in particular that you haven’t ‘converged’ to an extreme value on the boundary of the space.</p>
<p>Venables and Ripley suggest that it is often worth supplying analytic first derivatives rather than having a routine calculate numerical derivatives but not worth supplying analytic second derivatives. One possibility is using software such as Mathematica to do symbolic (i.e., analytic) differentiation and then writing code to implement the math of the result. Another is using software that can give derivatives using automatic differentiation such as <code>PyTorch</code>, <code>jax</code> and <code>tensorflow</code>. We saw an example of using Jax earlier in the unit.</p>
<p>In general for software development it’s obviously worth putting more time into figuring out the best optimization approach and supplying derivatives. For a one-off analysis, you can try a few different approaches and assess sensitivity.</p>
<p>The nice thing about likelihood optimization is that the asymptotic theory tells us that with large samples, the likelihood is approximately quadratic (i.e., the asymptotic normality of MLEs), which makes for a nice surface over which to do optimization. When optimizing with respect to variance components and other parameters that are non-negative, one approach to dealing with the constraints is to optimize with respect to the log of the parameter.</p>
</section>
</section>
<section id="combinatorial-optimization-over-discrete-spaces" class="level1">
<h1>7. Combinatorial optimization over discrete spaces</h1>
<p>Many statistical optimization problems involve continuous domains, but sometimes there are problems in which the domain is discrete. Variable selection is an example of this.</p>
<p><em>Simulated annealing</em> can be used for optimizing in a discrete space. Another approach uses <em>genetic algorithms</em>, in which one sets up the dimensions as loci grouped on a chromosome and has mutation and crossover steps in which two potential solutions reproduce. An example would be in high-dimensional variable selection.</p>
<p><em>Stochastic search variable selection</em> is a popular Bayesian technique for variable selection that involves MCMC.</p>
</section>
<section id="convexity" class="level1">
<h1>8. Convexity</h1>
<p>Many optimization problems involve (or can be transformed into) convex functions. Convex optimization (also called convex programming) is a big topic and one that we’ll only brush the surface of in Sections 8 and 9. The goal here is to give you enough of a sense of the topic that you know when you’re working on a problem that might involve convex optimization, in which case you’ll need to go learn more.</p>
<p>Optimization for convex functions is simpler than for ordinary functions because we don’t have to worry about local optima - any stationary point (point where the gradient is zero) is a global minimum. A set <span class="math inline">\(S\)</span> in <span class="math inline">\(\Re^{p}\)</span> is convex if any line segment between two points in <span class="math inline">\(S\)</span> lies entirely within <span class="math inline">\(S\)</span>. More generally, <span class="math inline">\(S\)</span> is convex if any convex combination is itself in <span class="math inline">\(S\)</span>, i.e., <span class="math inline">\(\sum_{i=1}^{m}\alpha_{i}x_{i}\in S\)</span> for non-negative weights, <span class="math inline">\(\alpha_{i}\)</span>, that sum to 1. Convex functions are defined on convex sets - <span class="math inline">\(f\)</span> is convex if for points in a convex set, <span class="math inline">\(x_{i}\in S\)</span>, we have <span class="math inline">\(f(\sum_{i=1}^{m}\alpha_{i}x_{i})\leq\sum_{i=1}^{m}\alpha_{i}f(x_{i})\)</span>. Strict convexity is when the inequality is strict (no equality).</p>
<p>The first-order convexity condition relates a convex function to its first derivative: <span class="math inline">\(f\)</span> is convex if and only if <span class="math inline">\(f(x)\geq f(y)+\nabla f(y)^{\top}(x-y)\)</span> for <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> in the domain of <span class="math inline">\(f\)</span>. We can interpret this as saying that the first order Taylor approximation to <span class="math inline">\(f\)</span> is tangent to and below (or touching) the function at all points.</p>
<p>The second-order convexity condition is that a function is convex if (provided its first derivative exists), the derivative is non-decreasing, in which case we have <span class="math inline">\(f^{\prime\prime}(x)\geq0\,\,\forall x\)</span> (for univariate functions). If we have <span class="math inline">\(f^{\prime\prime}(x)\leq0\,\,\forall x\)</span> (a concave, or convex down function) we can always consider <span class="math inline">\(-f(x)\)</span>, which is convex. Convexity in multiple dimensions means that the gradient is nondecreasing in all dimensions. If <span class="math inline">\(f\)</span> is twice differentiable, then if the Hessian is positive semi-definite, <span class="math inline">\(f\)</span> is convex.</p>
<p>There are a variety of results that allow us to recognize and construct convex functions based on knowing what operations create and preserve convexity. The Boyd book is a good source for material on such operations. Note that norms are convex functions (based on the triangle inequality), <span class="math inline">\(\|\sum_{i=1}^{n}\alpha_{i}x_{i}\|\leq\sum_{i=1}^{n}\alpha_{i}\|x_{i}\|\)</span>.</p>
<p>We’ll talk about a general algorithm that works for convex functions (the MM algorithm) and about the EM algorithm that is well-known in statistics, and is a special case of MM.</p>
<section id="mm-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="mm-algorithm">MM algorithm</h2>
<p>The MM algorithm is really more of a principle for constructing problem specific algorithms. MM stands for majorize-minorize. We’ll use the majorize part of it to minimize functions - the minorize part is the counterpart for maximizing functions.</p>
<p>Suppose we want to minimize a convex function, <span class="math inline">\(f(x)\)</span>. The idea is to construct a majorizing function, at <span class="math inline">\(x_{t}\)</span>, which we’ll call <span class="math inline">\(g\)</span>. <span class="math inline">\(g\)</span> majorizes <span class="math inline">\(f\)</span> at <span class="math inline">\(x_{t}\)</span> if <span class="math inline">\(f(x_{t})=g(x_{t})\)</span> and <span class="math inline">\(f(x)\leq g(x)\forall x\)</span>.</p>
<p>The iterative algorithm is as follows. Given <span class="math inline">\(x_{t}\)</span>, construct a majorizing function <span class="math inline">\(g_{t}(x).\)</span> Then minimize <span class="math inline">\(g_{t}\)</span> w.r.t. <span class="math inline">\(x\)</span> (or at least move downhill, such as with a modified Newton step) to find <span class="math inline">\(x_{t+1}\)</span>. Then we iterate, finding the next majorizing function, <span class="math inline">\(g_{t+1}(x)\)</span>. The algorithm is obviously guaranteed to go downhill, and ideally we use a function <span class="math inline">\(g\)</span> that is easy to work with (i.e., to minimize or go downhill with respect to). Note that we haven’t done any matrix inversions or computed any derivatives of <span class="math inline">\(f\)</span>. Furthermore, the algorithm is numerically stable - it does not over- or undershoot the optimum. The downside is that convergence can be quite slow.</p>
<p>The tricky part is finding a good majorizing function. Basically one needs to gain some skill in working with inequalities. The Lange book has some discussion of this.</p>
<p>An example is for estimating regression coefficients for median regression (aka least absolute deviation regression), which minimizes <span class="math inline">\(f(\theta)=\sum_{i=1}^{n}|y_{i}-z_{i}^{\top}\theta|=\sum_{i=1}^{n}|r_{i}(\theta)|\)</span>. Note that <span class="math inline">\(f(\theta)\)</span> is convex because affine functions (in this case <span class="math inline">\(y_{i}-z_{i}^{\top}\theta\)</span>) are convex, convex functions of affine functions are convex, and the summation preserves the convexity. We want to minimize <span class="math display">\[\begin{aligned}
f(\theta) &amp; = \sum_{i=1}^{n}|r_{i}(\theta)|\\
&amp; = \sum_{i=1}^{n}\sqrt{r_{i}(\theta)^{2}}\end{aligned}\]</span></p>
<p>Next, <span class="math inline">\(h(x)=\sqrt{x}\)</span> is concave, so we can use the following (commonly-used) inequality, <span class="math inline">\(h(x)\leq h(y)+h^{\prime}(y)(x-y)\)</span> which holds for any concave function, <span class="math inline">\(h\)</span>, and note that we have equality when <span class="math inline">\(y=x\)</span>. For <span class="math inline">\(y=\theta_{t}\)</span>, the current value in the iterative optimization, we have: <span class="math display">\[\begin{aligned}
f(\theta) &amp; = \sum_{i=1}^{n}\sqrt{r_{i}(\theta)^{2}}\\
&amp; \leq \sum_{i=1}^{n}\sqrt{r_{i}(\theta_{t})^{2}}+\frac{r_{i}(\theta)^{2}-r_{i}(\theta_{t})^{2}}{2\sqrt{r_{i}(\theta_{t})^{2}}}\\
&amp; = g_{t}(\theta)\end{aligned}\]</span> where the term on the right of the second equation is our majorizing function <span class="math inline">\(g(\theta)\)</span> for the current <span class="math inline">\(\theta_{t}\)</span>. We then have <span class="math display">\[\begin{aligned}
g_{t}(\theta) &amp; = \sum_{i=1}^{n}\sqrt{r_{i}(\theta_{t})^{2}}+\frac{1}{2}\sum_{i=1}^{n}\frac{r_{i}(\theta)^{2}-r_{i}(\theta_{t})^{2}}{2\sqrt{r_{i}(\theta_{t})^{2}}}\\
&amp; = \frac{1}{2}\sum_{i=1}^{n}\sqrt{r_{i}(\theta_{t})^{2}}+\frac{1}{2}\sum_{i=1}^{n}\frac{r_{i}(\theta)^{2}}{\sqrt{r_{i}(\theta_{t})^{2}}}\end{aligned}\]</span> Our job in this iteration of the algorithm is to minimize <span class="math inline">\(g\)</span> with respect to <span class="math inline">\(\theta\)</span> (recall that <span class="math inline">\(\theta_{t}\)</span> is a fixed value), so we can ignore the first sum, which doesn’t involve <span class="math inline">\(\theta\)</span>. Minimizing the second sum can be seen as a weighted least squares problem, where the numerator is the usual sum of squared residuals and the weights are <span class="math inline">\(w_{i}=\frac{1}{\sqrt{(y_{i}-z_{i}^{\top}\theta_{t})^{2}}}\)</span>. Intuitively this makes sense: the weight is large when the magnitude of the residual is small this makes up for the fact that we are using least squares when we want to mimimize absolute deviations. So our update is: <span class="math display">\[\theta_{t+1}=(Z^{\top}W(\theta_{t})Z)^{-1}Z^{\top}W(\theta_{t})Y,\]</span> where <span class="math inline">\(W(\theta_{t})\)</span> is a diagonal matrix with elements <span class="math inline">\(w_{1},\ldots,w_{n}.\)</span></p>
<p>As usual, we want to think about what could go wrong numerically. If we have some very small magnitude residuals, they will get heavily upweighted in this procedure, which might cause instability in our optimization.</p>
<p>For an example of MM being used in practice for a real problem, see Jung et al.&nbsp;(2014): Biomarker Detection in Association Studies: Modeling SNPs Simultaneously via Logistic ANOVA, Journal of the American Statistical Association 109:1355.</p>
</section>
<section id="expectation-maximization-em" class="level2">
<h2 class="anchored" data-anchor-id="expectation-maximization-em">Expectation-Maximization (EM)</h2>
<p>It turns out the EM algorithm that many of you have heard about is a special case of MM. For our purpose here, we’ll consider maximization.</p>
<p>The EM algorithm is most readily motivated from a missing data perspective. Suppose you want to maximize <span class="math inline">\(L(\theta|x)=f(x;\theta)\)</span> based on available data in a missing data context. Denote the complete data as <span class="math inline">\(Y=(X,Z)\)</span> with <span class="math inline">\(Z\)</span> is missing. As we’ll see, in many cases, <span class="math inline">\(Z\)</span> is actually a set of latent variables that we introduce into the problem to formulate it so we can use EM. The canonical example is when <span class="math inline">\(Z\)</span> are membership indicators in a mixture modeling context. (Note that in the case where you introduce <span class="math inline">\(Z\)</span>, that also means that one could also just directly maximize <span class="math inline">\(L(\theta|x)\)</span>, which in many cases may work better than using the EM algorithm.)</p>
<p>In general, <span class="math inline">\(\log L(\theta;x)\)</span> may be hard to optimize because it involves an integral over the missing data, <span class="math inline">\(Z\)</span>: <span class="math display">\[f(x;\theta)=\int f(x,z;\theta)dz,\]</span> but the EM algorithm provides a recipe that makes the optimization straightforward for many problems.</p>
<p>The algorithm is as follows. Let <span class="math inline">\(\theta^{t}\)</span> be the current value of <span class="math inline">\(\theta\)</span>. Then define <span class="math display">\[Q(\theta|\theta^{t})=E(\log L(\theta|Y)|x;\theta^{t})\]</span>.</p>
<p>That expectation is an expectation with respect to the conditional distribution, $ f(z|x; = ^t)$.</p>
<p>The algorithm is</p>
<ol type="1">
<li><p>E step: Compute <span class="math inline">\(Q(\theta|\theta^{t})\)</span>, ideally calculating the expectation over the missing data in closed form. Note that <span class="math inline">\(\log L(\theta|Y)\)</span> is a function of <span class="math inline">\(\theta\)</span> so <span class="math inline">\(Q(\theta|\theta^{t})\)</span> will involve both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\theta^{t}\)</span>.</p></li>
<li><p>M step: Maximize <span class="math inline">\(Q(\theta|\theta^{t})\)</span> with respect to <span class="math inline">\(\theta\)</span>, finding <span class="math inline">\(\theta^{t+1}\)</span>.</p></li>
<li><p>Continue until convergence.</p></li>
</ol>
<p>Ideally both the E and M steps can be done analytically. When the M step cannot be done analytically, one can employ some of the numerical optimization tools we’ve already seen. When the E step cannot be done analytically, one standard approach is to estimate the expectation by Monte Carlo, which produces Monte Carlo EM (MCEM). The strategy is to draw from <span class="math inline">\(z_{j}\)</span> from <span class="math inline">\(f(z|x,\theta^{t})\)</span> and approximate <span class="math inline">\(Q\)</span> as a Monte Carlo average of <span class="math inline">\(\log f(x,z_{j};\theta)\)</span>, and then optimize over this approximation to the expectation. If one can’t draw in closed form from the conditional density, one strategy is to do a short MCMC to draw a (correlated) sample.</p>
<p>EM can be show to increase the value of the function at each step using Jensen’s inequality (equivalent to the information inequality that holds with regard to the Kullback-Leibler divergence between two distributions) (Givens and Hoeting, p.&nbsp;95, go through the details). Furthermore, one can show that it amounts, at each step, to maximizing a minorizing function for <span class="math inline">\(\log L(\theta)\)</span> - the minorizing function (effectively <span class="math inline">\(Q\)</span>) is tangent to <span class="math inline">\(\log L(\theta)\)</span> at <span class="math inline">\(\theta^{t}\)</span> and lies below <span class="math inline">\(\log L(\theta)\)</span>.</p>
<p>A standard example is a mixture model. (Here we’ll assume a mixture of normal distributions, but other distributions could be used.) Therefore we have <span class="math display">\[f(x;\theta)=\sum_{k=1}^{K}\pi_{k}f_{k}(x;\mu_{k},\sigma_{k})\]</span> where we have <span class="math inline">\(K\)</span> mixture components and <span class="math inline">\(\pi_{k}\)</span> are the (marginal) probabilities of being in each component. The complete parameter vector is <span class="math inline">\(\theta=\{\{\pi_{k}\},\{\mu_{k}\},\{\sigma_{k}\}\}\)</span>. Note that the likelihood is a complicated product (over observations) over the sum (over components), so maximization may be difficult. Furthermore, such likelihoods are well-known to be multimodal because of label switching.</p>
<p>To use EM, we take the group membership indicators for each observation as the missing data. For the <span class="math inline">\(i\)</span>th observation, we have <span class="math inline">\(z_{i}\in\{1,2,\ldots,K\}\)</span>. Introducing these indicators “breaks the mixture”. If we know the memberships for all the observations, it’s often easy to estimate the parameters for each group based on the observations from that group. For example if the <span class="math inline">\(\{f_{k}\}\)</span>’s were normal densities, then we can estimate the mean and variance of each normal density using the sample mean and sample variance of the <span class="math inline">\(x_{i}\)</span>’s that belong to each mixture component. EM will give us a variation on this that uses “soft” (i.e., probabilistic) weighting.</p>
<p>The complete log likelihood given <span class="math inline">\(z\)</span> and <span class="math inline">\(x\)</span> is <span class="math display">\[\log\prod_{i}f(x_{i}|z_{i};\theta)\mbox{Pr}(Z_{i}=z_{i};\theta)\]</span> which can be expressed as<br>
<br>
<span class="math display">\[\begin{aligned}
\log L(\theta|x,z) &amp; = &amp; \sum_{i}\log f(x_{i};\mu_{z_{i}},\sigma_{z_{i}})+\log\pi_{z_{i}}\\
&amp; = &amp; \sum_{i}\sum_{k}I(z_{i}=k)(\log f_{k}(x_{i};\mu_{k},\sigma_{k})+\log\pi_{k})\end{aligned}\]</span> with <span class="math inline">\(Q\)</span> equal to <span class="math display">\[Q(\theta|\theta^{t})=\sum_{i}\sum_{k}E(I(z_{i}=k)|x_{i};\theta^{t})(\log f_{k}(x_{i};\mu_{k},\sigma_{k})+\log\pi_{k})\]</span> where <span class="math inline">\(E(I(z_{i}=k)|x_{i};\theta^{t})\)</span> is equal to the probability that the <span class="math inline">\(i\)</span>th observation is in the <span class="math inline">\(k\)</span>th group given <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(\theta_{t}\)</span>, which is calculated from Bayes theorem as <span class="math display">\[p_{ik}^{t}=\frac{\pi_{k}^{t}f_{k}(x_{i};\mu_{k}^{t},\sigma_{k}^{t})}{\sum_{j}\pi_{j}^{t}f_{j}(x_{i};\mu_{k}^{t},\sigma_{k}^{t})}\]</span> We can now separately maximize <span class="math inline">\(Q(\theta|\theta^{t})\)</span> with respect to <span class="math inline">\(\pi_{k}\)</span> and <span class="math inline">\(\mu_{k},\sigma_{k}\)</span> to find <span class="math inline">\(\pi_{k}^{t+1}\)</span> and <span class="math inline">\(\mu_{k}^{t+1},\sigma_{k}^{t+1}\)</span>, since the expression is the sum of a term involving the parameters of the distributions and a term involving the mixture probabilities. In the latter case, if the <span class="math inline">\(f_{k}\)</span> are normal distributions, you end up with a weighted sum of normal distributions, for which the estimators of the mean and variance parameters are the weighted mean of the observations and the weighted variance.</p>
</section>
</section>
<section id="optimization-under-constraints" class="level1">
<h1>9. Optimization under constraints</h1>
<p>Constrained optimization is harder than unconstrained, and inequality constraints harder to deal with than equality constraints.</p>
<p>Constrained optimization can sometimes be avoided by reparameterizing. Some examples include: - working on the log scale (e.g., to optimize w.r.t. a variance component or other non-negative parameter) - using the logit transformation to optimize with respect to a parameter on <span class="math inline">\((0,1)\)</span> (or more generally some other bounded interval, after shifting and scaling to <span class="math inline">\((0,1)\)</span>.</p>
<p>Optimization under constraints often goes under the name of ‘programming’, with different types of programming for different types of objective functions combined with different types of constraints.</p>
<section id="convex-optimization-convex-programming" class="level2">
<h2 class="anchored" data-anchor-id="convex-optimization-convex-programming">Convex optimization (convex programming)</h2>
<p>Convex programming minimizes <span class="math inline">\(f(x)\)</span> s.t. <span class="math inline">\(h_{j}(x)\leq0,\,j=1,\ldots,m\)</span> and <span class="math inline">\(a_{i}^{\top}x=b_{i},\,i=1,\ldots,q\)</span>, where both <span class="math inline">\(f\)</span> and the constraint functions are convex. Note that this includes more general equality constraints, as we can write <span class="math inline">\(g(x)=b\)</span> as two inequalities <span class="math inline">\(g(x)\leq b\)</span> and <span class="math inline">\(g(x)\geq b\)</span>. It also includes <span class="math inline">\(h_{j}(x)\geq b_{j}\)</span> by taking <span class="math inline">\(-h_{j}(x)\)</span>. Note that we can always have <span class="math inline">\(h_{j}(x)\leq b_{j}\)</span> and convert to the above form by subtracting <span class="math inline">\(b_{j}\)</span> from each side (note that this preserves convexity). A vector <span class="math inline">\(x\)</span> is said to be feasible, or in the feasible set, if all the constraints are satisfied for <span class="math inline">\(x\)</span>.</p>
<p>There are good algorithms for convex programming, and it’s possible to find solutions when we have hundreds or thousands of variables and constraints. It is often difficult to recognize if one has a convex program (i.e., if <span class="math inline">\(f\)</span> and the constraint functions are convex), but there are many tricks to transform a problem into a convex program and many problems can be solved through convex programming. So the basic challenge is in recognizing or transforming a problem to one of convex optimization; once you’ve done that, you can rely on existing methods to find the solution.</p>
<p>Linear programming, quadratic programming, second order cone programming and semidefinite programming are all special cases of convex programming. In general, these types of optimization are progressively more computationally complex.</p>
<p>First let’s see some of the special cases and then discuss the more general problem.</p>
</section>
<section id="linear-programming-linear-system-linear-constraints" class="level2">
<h2 class="anchored" data-anchor-id="linear-programming-linear-system-linear-constraints">Linear programming: Linear system, linear constraints</h2>
<p>Linear programming seeks to minimize <span class="math display">\[f(x)=c^{\top}x\]</span> subject to a system of <span class="math inline">\(m\)</span> inequality constraints, <span class="math inline">\(a_{i}^{\top}x\leq b_{i}\)</span> for <span class="math inline">\(i=1,\ldots,m\)</span>, where <span class="math inline">\(A\)</span> is of full row rank. This can also be written in terms of generalized inequality notation, <span class="math inline">\(Ax\preceq b\)</span>. There are standard algorithms for solving linear programs, including the simplex method and interior point methods.</p>
<p>Note that each equation in the set of equations <span class="math inline">\(Ax=b\)</span> defines a hyperplane, so each inequality in <span class="math inline">\(Ax\preceq b\)</span> defines a half-space. Minimizing a linear function (presuming that the minimum exists) must mean that we push in the correct direction towards the boundaries formed by the hyperplanes, with the solution occuring at a corner (vertex) of the solid formed by the hyperplanes. The simplex algorithm starts with a feasible solution at a corner and moves along edges in directions that improve the objective function.</p>
</section>
<section id="general-system-equality-constraints" class="level2">
<h2 class="anchored" data-anchor-id="general-system-equality-constraints">General system, equality constraints</h2>
<p>Suppose we have an objective function <span class="math inline">\(f(x)\)</span> and we have equality constraints, <span class="math inline">\(Ax=b\)</span>. We can manipulate this into an unconstrained problem. The null space of <span class="math inline">\(A\)</span> is the set of <span class="math inline">\(\delta\)</span> s.t. <span class="math inline">\(A\delta=0\)</span>. So if we start with a candidate <span class="math inline">\(x_{c}\)</span> s.t. <span class="math inline">\(Ax_{c}=b\)</span> (e.g., by using the pseudo inverse, <span class="math inline">\(A^{+}b\)</span>), we can form all other candidates (a candidate is an <span class="math inline">\(x\)</span> s.t. <span class="math inline">\(Ax=b\)</span>) as <span class="math inline">\(x=x_{c}+\delta=x_{c}+Bz\)</span> where <span class="math inline">\(B\)</span> is a set of column basis functions for the null space of <span class="math inline">\(A\)</span> and <span class="math inline">\(z\in\Re^{p-m}\)</span>. Consider <span class="math inline">\(h(z)=f(x_{c}+Bz)\)</span> and note that <span class="math inline">\(h\)</span> is a function of <span class="math inline">\(p-m\)</span> rather than <span class="math inline">\(p\)</span> inputs. Namely, we are working in a reduced dimension space with no constraints. If we assume differentiability of <span class="math inline">\(f\)</span>, we can express <span class="math inline">\(\nabla h(z)=B^{\top}\nabla f(x_{c}+Bz)\)</span> and <span class="math inline">\(H_{h}(z)=B^{\top}H_{f}(x_{c}+Bz)B\)</span>. Then we can use unconstrained methods to find the point at which <span class="math inline">\(\nabla h(z)=0\)</span>.</p>
<p>How do we find <span class="math inline">\(B\)</span>? One option is to use the <span class="math inline">\(p-m\)</span> columns of <span class="math inline">\(V\)</span> in the SVD of <span class="math inline">\(A\)</span> that correspond to singular values that are zero. A second option is to take the QR decomposition of <span class="math inline">\(A^{\top}\)</span>. Then <span class="math inline">\(B\)</span> is the columns of <span class="math inline">\(Q_{2}\)</span>, where these are the columns of the (non-skinny) Q matrix corresponding to the rows of <span class="math inline">\(R\)</span> that are zero.</p>
<p>For more general (nonlinear) equality constraints, <span class="math inline">\(g_{i}(x)=b_{i}\)</span>, <span class="math inline">\(i=1,\ldots,q\)</span>, we can use the Lagrange multiplier approach to define a new objective function, <span class="math display">\[L(x,\lambda)=f(x)+\lambda^{\top}(g(x)-b)\]</span> for which, if we set the derivative (with respect to both <span class="math inline">\(x\)</span> and the Lagrange multiplier vector, <span class="math inline">\(\lambda\)</span>) equal to zero, we have a critical point of the original function and we respect the constraints.</p>
<p>An example occurs with quadratic programming, under the simplification of affine equality constraints (quadratic programming in general optimizes a quadratic function under affine inequality constraints - i.e., constraints of the form <span class="math inline">\(Ax-b\preceq0\)</span>). For example we might solve a least squares problem subject to linear equality constraints, <span class="math inline">\(f(x)=\frac{1}{2}x^{\top}Qx+m^{\top}x+c\)</span> s.t. <span class="math inline">\(Ax=b\)</span>, where <span class="math inline">\(Q\)</span> is positive semi-definite. The Lagrange multiplier approach gives the objective function <span class="math display">\[L(x,\lambda)=\frac{1}{2}x^{\top}Qx+m^{\top}x+c+\lambda^{\top}(Ax-b)\]</span> and differentiating gives the equations <span class="math display">\[\begin{aligned}
\frac{\partial L(x,\lambda)}{\partial x} &amp; =m+Qx+A^{\top}\lambda  =  0\\
\frac{\partial L(x,\lambda)}{\partial\lambda} &amp; =Ax  =  b,\end{aligned}\]</span> which gives us a system of equations that leads to the solution <span class="math display">\[\left(\begin{array}{c} x \\ \lambda \end{array} \right) =
\left( \begin{array}{cc} Q &amp; A^{\top} \\ A &amp; 0 \end{array}\right)^{-1}
\left(\begin{array}{c} -m \\ b \end{array}\right).\label{eq:quadProg}\]</span></p>
<p>Using known results for inverses of matrices split into blocks, one gets that <span class="math inline">\(x^{*}=-Q^{-1}m+Q^{-1}A^{\top}(AQ^{-1}A^{\top})^{-1}(AQ^{-1}m+b)\)</span>. This can be readily coded up using strategies from Unit 10.</p>
</section>
<section id="the-dual-problem-optional" class="level2">
<h2 class="anchored" data-anchor-id="the-dual-problem-optional">The dual problem (optional)</h2>
<p>Sometimes a reformulation of the problem eases the optimization. There are different kinds of dual problems, but we’ll just deal with the Lagrangian dual. Let <span class="math inline">\(f(x)\)</span> be the function we want to minimize, under constraints <span class="math inline">\(g_{i}(x)=0;\,i=1,\ldots,q\)</span> and <span class="math inline">\(h_{j}(x)\leq0;\,j=1,\ldots,m\)</span>. Here I’ve explicitly written out the equality constraints to follow the notation in Lange. Consider the Langrangian, <span class="math display">\[L(x,\lambda,\mu)=f(x)+\sum_{i}\lambda_{i}g_{i}(x)+\sum_{j}\mu_{j}h_{j}(x).\]</span></p>
<p>Solving that can be shown to be equivalent to this optimization: <span class="math display">\[\inf_{x}\sup_{\lambda,\mu:\mu_{j}\geq0}L(x,\lambda,\mu)\]</span> where the supremum ensures that the constraints are satisfied because the Lagrangian is infinity if the constraints are not satisfied.</p>
<p>Let’s consider interchanging the minimization and maximization. For <span class="math inline">\(\mu\succeq0\)</span>, one can show that <span class="math display">\[\sup_{\lambda,\mu:\mu_{j}\geq0}\inf_{x}L(x,\lambda,\mu)\leq\inf_{x}\sup_{\lambda,\mu:\mu_{j}\geq0}L(x,\lambda,\mu),\]</span> because <span class="math inline">\(\inf_{x}L(x,\lambda,\mu)\leq f(x^{*})\)</span> for the minimizing value <span class="math inline">\(x^{*}\)</span> (p.&nbsp;216 of the Boyd book). This gives us the Lagrange dual function: <span class="math display">\[d(\lambda,\mu)=\inf_{x}L(x,\lambda,\mu),\]</span> and the Lagrange dual problem is to find the best lower bound: <span class="math display">\[\sup_{\lambda,\mu:\mu_{j}\geq0}d(\lambda,\mu).\]</span></p>
<p>The dual problem is always a convex optimization problem because <span class="math inline">\(d(\lambda,\mu)\)</span> is concave (because <span class="math inline">\(d(\lambda,\mu)\)</span> is a pointwise infimum of a family of affine functions of <span class="math inline">\((\lambda,\mu)\)</span>). If the optima of the primal (original) problem and that of the dual do not coincide, there is said to be a “duality gap”. For convex programming, if certain conditions are satisfied (called <em>constraint qualifications</em>), then there is no duality gap, and one can solve the dual problem to solve the primal problem. Usually with the standard form of convex programming, there is no duality gap. Provided we can do the minimization over <span class="math inline">\(x\)</span> in closed form we then maximize <span class="math inline">\(d(\lambda,\mu)\)</span> w.r.t. the Lagrangian multipliers in a new constrained problem that is sometimes easier to solve, giving us <span class="math inline">\((\lambda^{*},\mu^{*})\)</span>.</p>
<p>One can show (p.&nbsp;242 of the Boyd book) that <span class="math inline">\(\mu_{i}^{*}=0\)</span> unless the <span class="math inline">\(i\)</span>th constraint is active at the optimum <span class="math inline">\(x^{*}\)</span> and that <span class="math inline">\(x^{*}\)</span> minimizes <span class="math inline">\(L(x,\lambda^{*},\mu^{*})\)</span>. So once one has <span class="math inline">\((\lambda^{*},\mu^{*})\)</span>, one is in the position of minimizing an unconstrained convex function. If <span class="math inline">\(L(x,\lambda^{*},\mu^{*})\)</span> is strictly convex, then <span class="math inline">\(x^{*}\)</span> is the unique optimum provided <span class="math inline">\(x^{*}\)</span> satisfies the constraints, and no optimum exists if it does not.</p>
<p>Here’s a simple example: suppose we want to minimize <span class="math inline">\(x^{\top}x\)</span> s.t. <span class="math inline">\(Ax=b\)</span>. The Lagrangian is <span class="math inline">\(L(x,\lambda)=x^{\top}x+\lambda^{\top}(Ax-b)\)</span>. Since <span class="math inline">\(L(x,\lambda)\)</span> is quadratic in <span class="math inline">\(x\)</span>, the infimum is found by setting <span class="math inline">\(\nabla_{x}L(x,\lambda)=2x+A^{\top}\lambda=0\)</span>, yielding <span class="math inline">\(x=-\frac{1}{2}A^{\top}\lambda\)</span>. So the dual function is obtained by plugging this value of <span class="math inline">\(x\)</span> into <span class="math inline">\(L(x,\lambda)\)</span>, which gives <span class="math display">\[d(\lambda)=-\frac{1}{4}\lambda^{\top}AA^{\top}\lambda-b^{\top}\lambda,\]</span> which is concave quadratic. In this case we can solve the original constrained problem in terms of this unconstrained dual problem.</p>
<p>Another example is the primal and dual forms for finding the SVM classifier (see <a href="https://en.wikipedia.org/wiki/Support_vector_machine#Primal_form">the Wikipedia article</a>). In this algorithm, we want to develop a classifier using <span class="math inline">\(n\)</span> pairs of <span class="math inline">\(y\in\Re^{1}\)</span> and <span class="math inline">\(x\in\Re^{p}\)</span>. The dual form is easily derived because the minimization over <span class="math inline">\(x\)</span> occurs in a function that is quadratic in <span class="math inline">\(x\)</span>. Expressing the problem in the primal form gives an optimization in <span class="math inline">\(\Re^{p}\)</span> while doing so in the dual form gives an optimization in <span class="math inline">\(\Re^{n}\)</span>. So one reason to use the dual form would be if you have <span class="math inline">\(n\ll p\)</span>.</p>
</section>
<section id="kkt-conditions-optional" class="level2">
<h2 class="anchored" data-anchor-id="kkt-conditions-optional">KKT conditions (optional)</h2>
<p>Karush-Kuhn-Tucker (KKT) theory provides sufficient conditions under which a constrained optimization problem has a minimum, generalizing the Lagrange multiplier approach. The Lange and Boyd books have whole sections on this topic.</p>
<p>Suppose that the function and the constraint functions are continuously differentiable near <span class="math inline">\(x^{*}\)</span> and that we have the Lagrangian as before: <span class="math display">\[L(x,\lambda,\mu)=f(x)+\sum_{i}\lambda_{i}g_{i}(x)+\sum_{j}\mu_{j}h_{j}(x).\]</span></p>
<p>For nonconvex problems, if <span class="math inline">\(x^{*}\)</span> and <span class="math inline">\((\lambda^{*},\mu^{*})\)</span> are the primal and dual optimal points and there is no duality gap, then the KKT conditions hold: <span class="math display">\[\begin{aligned}
h_{j}(x^{*}) &amp; \leq &amp; 0\\
g_{i}(x^{*}) &amp; = &amp; 0\\
\mu_{j}^{*} &amp; \geq &amp; 0\\
\mu_{j}^{*}h_{j}(x^{*}) &amp; = &amp; 0\\
\nabla f(x^{*})+\sum_{i}\lambda_{i}^{*}\nabla g_{i}(x^{*})+\sum_{j}\mu_{j}^{*}\nabla h_{j}(x^{*}) &amp; = &amp; 0.\end{aligned}\]</span></p>
<p>For convex problems, we also have that if the KKT conditions hold, then <span class="math inline">\(x^{*}\)</span> and <span class="math inline">\((\lambda^{*},\mu^{*})\)</span> are primal and dual optimal and there is no duality gap.</p>
<p>We can consider this from a slightly different perspective, in this case requiring that the Lagrangian be twice differentiable.</p>
<p>First we need a definition. A <em>tangent direction</em>, <span class="math inline">\(w\)</span>, with respect to <span class="math inline">\(g(x)\)</span>, is a vector for which <span class="math inline">\(\nabla g_{i}(x)^{\top}w=0\)</span>. If we are at a point, <span class="math inline">\(x^{*}\)</span>, at which the constraint is satisfied, <span class="math inline">\(g_{i}(x^{*})=0\)</span>, then we can move in the tangent direction (orthogonal to the gradient of the constraint function) (i.e., along the level curve) and still satisfy the constraint. This is the only kind of movement that is legitimate (gives us a feasible solution).</p>
<p>If the gradient of the Lagrangian with respect to <span class="math inline">\(x\)</span> is equal to 0, <span class="math display">\[\nabla f(x^{*})+\sum_{i}\lambda_{i}\nabla g_{i}(x^{*})+\sum_{j}\mu_{j}\nabla h_{j}(x^{*})=0,\]</span> and if <span class="math inline">\(w^{\top}H_{L}(x^{*},\lambda,\mu)w&gt;0\)</span> (with <span class="math inline">\(H_{L}\)</span> being the Hessian of the Lagrangian) for all vectors <span class="math inline">\(w\)</span> s.t. <span class="math inline">\(\nabla g(x^{*})^{\top}w=0\)</span> and, for all active constraints,<span class="math inline">\(\nabla h(x^{*})^{\top}w=0\)</span>, then <span class="math inline">\(x^{*}\)</span> is a local minimum. An active constraint is an inequality for which <span class="math inline">\(h_{j}(x^{*})=0\)</span> (rather than <span class="math inline">\(h_{j}(x^{*})&lt;0\)</span>, in which case it is inactive). Basically we only need to worry about the inequality constraints when we are on the boundary, so the goal is to keep the constraints inactive.</p>
<p>Some basic intuition is that we need positive definiteness only for directions that stay in the feasible region. That is, our only possible directions of movement (the tangent directions) keep us in the feasible region, and for these directions, we need the objective function to be increasing to have a minimum. If we were to move in a direction that goes outside the feasible region, it’s ok for the quadratic form involving the Hessian to be negative.</p>
<p>Many algorithms for convex optimization can be interpreted as methods for solving the KKT conditions.</p>
</section>
<section id="interior-point-methods" class="level2">
<h2 class="anchored" data-anchor-id="interior-point-methods">Interior-point methods</h2>
<p>We’ll briefly discuss one of the standard methods for solving a convex optimization problem. The barrier method is one type of interior-point algorithm. It turns out that Newton’s method can be used to solve a constrained optimization problem, with twice-differentiable <span class="math inline">\(f\)</span> and linear equality constraints. So the basic strategy of the barrier method is to turn the more complicated constraint problem into one with only linear equality constraints.</p>
<p>Recall our previous notation, in which convex programming minimizes <span class="math inline">\(f(x)\)</span> s.t. <span class="math inline">\(h_{i}(x)\leq0,\,j=1,\ldots,m\)</span> and <span class="math inline">\(a_{i}^{\top}x=b_{i},\,i=1,\ldots,q\)</span>, where both <span class="math inline">\(f\)</span> and the constraint functions are convex. The strategy begins with moving the inequality constraints into the objective function: <span class="math display">\[f(x)+\sum_{j=1}^{m}I_{-}(h_{j}(x))\]</span> where <span class="math inline">\(I_{-}(u)=0\)</span> if <span class="math inline">\(u\leq0\)</span> and <span class="math inline">\(I_{-}(u)=\infty\)</span> if <span class="math inline">\(u&gt;0\)</span>.</p>
<p>This is fine, but the new objective function is not differentiable so we can’t use a Newton-like approach. Instead, we approximate the indicator function with a logarithmic function, giving the new objective function <span class="math display">\[\tilde{f}(x)=f(x)+\sum_{j=1}^{m}-(1/t^{*})\log(-h_{j}(x)),\]</span> which is convex and differentiable. The new term pushes down the value of the overall objective function when <span class="math inline">\(x\)</span> approaches the boundary, nearing points for which the inequality constraints are not met. The <span class="math inline">\(-\sum(1/t^{*})\log(-h_{j}(x))\)</span> term is called the log barrier, since it keeps the solution in the feasible set (i.e., the set where the inequality constraints are satisfied), provided we start at a point in the feasible set. Newton’s method with equality constraints (<span class="math inline">\(Ax=b\)</span>) is then applied. The key thing is then to have <span class="math inline">\(t^{*}\)</span> get larger (i.e., <span class="math inline">\(t^{*}\)</span> is some increasing function of iteration time <span class="math inline">\(t\)</span>) as the iterations proceed, which allows the solution to get closer to the boundary if that is indeed where the minimum lies.</p>
<p>The basic ideas behind Newton’s method with equality constraints are (1) start at a feasible point, <span class="math inline">\(x_{0}\)</span>, such that <span class="math inline">\(Ax_{0}=b\)</span>, and (2) make sure that each step is in a feasible direction, <span class="math inline">\(A(x_{t+1}-x_{t})=0\)</span>. To make sure the step is in a feasible direction we have to solve a linear system similar to that in the simplified quadratic programming problem: <span class="math display">\[\left(\begin{array}{c}
x_{t+1}-x_{t}\\
\lambda
\end{array}\right)=\left(\begin{array}{cc}
H_{\tilde{f}}(x_{t}) &amp; A^{\top}\\
A &amp; 0
\end{array}\right)^{-1}\left(\begin{array}{c}
-\nabla\tilde{f}(x_{t})\\
0
\end{array}\right),\]</span> which shouldn’t be surprising since the whole idea of Newton’s method is to substitute a quadratic approximation for the actual objective function.</p>
</section>
<section id="software-for-constrained-and-convex-optimization" class="level2">
<h2 class="anchored" data-anchor-id="software-for-constrained-and-convex-optimization">Software for constrained and convex optimization</h2>
<p>For general convex optimization in Python see the <code>cvxopt</code> package. Some other resources to consider are</p>
<ul>
<li>MATLAB, in particular the <code>fmincon()</code> function, the CVX system, and MATLAB’s linear and quadratic programming abilities.</li>
<li>The CVXR package in R.</li>
</ul>
<p>I haven’t looked into CVXR in detail but given the developers include Stephen Boyd, who is a convex optimization guru, it’s worth checking out.</p>
<p><code>cvxopt</code> has specific solves (see <code>help(cvxopt.solvers)</code> for different kinds of convex optimization. A general purpose one is <code>cvxopt.solvers.cp</code>. Specifying the problem (the objective function, nonlinear constraints, and linear constraints) using the software is somewhat involved, so I haven’t worked out an example here.</p>
</section>
</section>
<section id="summary" class="level1">
<h1>10. Summary</h1>
<p>The different methods of optimization have different advantages and disadvantages.</p>
<p>According to Lange, MM and EM are numerically stable and computationally simple but can converge very slowly. Newton’s method shows very fast convergence but has the downsides we’ve discussed. Quasi-Newton methods fall in between. Convex optimization generally comes up when optimizing under constraints.</p>
<p>One caution about optimizing under constraints is that you just get a point estimate; quantifying uncertainty in your estimator is more difficult. One strategy is to ignore the inactive inequality constraints and reparameterize (based on the active equality constraints) to get an unconstrained problem in a lower-dimensional space. Then you can make use of the Hessian in the usual fashion to estimate the information matrix.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../units/unit10-linalg.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Unit 10 (Linear Algebra)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>