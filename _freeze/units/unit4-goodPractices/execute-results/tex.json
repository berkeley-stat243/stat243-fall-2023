{
  "hash": "bb1859e4624b73237fbc1c3732adc5b6",
  "result": {
    "markdown": "---\ntitle: \"Good practices: coding practices, debugging, and reproducible research\"\nauthor: \"Chris Paciorek\"\ndate: \"2023-07-26\"\nformat:\n  pdf:\n    documentclass: article\n    margin-left: 30mm\n    margin-right: 30mm\n    toc: true\n  html:\n    theme: cosmo\n    css: ../styles.css\n    toc: true\n    code-copy: true\n    code-block-background: true\nexecute:\n  freeze: auto\nfrom: markdown+tex_math_single_backslash\n---\n\n::: {.cell}\n\n:::\n\n\n[PDF](./unit4-goodPractices.pdf){.btn .btn-primary}\n\nSources:\n\n-   The Python [PEP8 Style Guide](https://peps.python.org/pep-0008)\n-   Murrell, Introduction to Data Technologies, Ch. 2\n-   [Journal of Statistical Software vol. 42: 19 Ways of Looking at\n    Statistical Software](http://www.jstatsoft.org/v42/i02)\n-   [Wilson et at., Best practices for scientific computing,\n    ArXiv:1210:0530](http://arxiv.org/abs/1210.0530)\n-   [Gentzkow and Shapiro tutorial for social\n    scientists](https://web.stanford.edu/~gentzkow/research/CodeAndData.pdf)\n-   [Millman and Perez article about reproducible research](https://github.com/berkeley-stat243/stat243-fall-2014/blob/master/section/millman-perez.pdf)\n-   [Chapter 11 of Transparent and Reproducible Social Science\n    Research](https://california.degruyter.com/view/title/568658?tab_body=toc)\n\nThis unit covers good coding/software development practices, debugging\n(and practices for avoiding bugs), and doing reproducible research. As\nin later units of the course, the material is generally not specific to\nPython, but some details and the examples are in Python.\n\n# 1. Good coding practices\n\nSome of these tips apply more to software development and some more to\nanalyses done for specific projects; hopefully it will be clear in most\ncases.\n\n## Editors\n\nUse an editor that supports the language you are using (e.g., *Atom*, *Emacs*/*Aquamacs*, *Sublime*, *vim*, *VSCode*, *TextMate*, *WinEdt*, or the built-in editor in *RStudio* [you can use Python from within RStudio]). Some advantages of this can include:\n\n  1. helpful color coding of different types of syntax and of strings,\n  2. automatic indentation and spacing,\n  3. code can often be run or compiled from within the editor,\n  4. parenthesis matching,\n  5. line numbering (good for finding bugs).\n\n## Coding syntax\n\nThe PEP 8 style guide is your go-to reference for Python style.\nI've highlighted some details here as well as included some general\nsuggestions of my own.\n\n- Header information: put metainfo on the code into the first few\n    lines of the file as comments. Include who, when, what, how the code\n    fits within a larger program (if appropriate), possibly the versions\n    of Python and key packages that you used.\n- Write docstrings for public modules, classes, functions, and methods.\n    For non-public items, a comment after the `def` line is sufficient\n    to describe the purpose of the item.\n- Indentation: Python is strict about indentation of course, which\n    helps to enforce clear indentation more than in other languages.\n    This helps you and others to read and understand the code and can\n    help in detecting errors in your code because it can expose lack of\n    symmetry.\n    - use 4 spaces per indentation level (avoid tabs if possible).\n- Whitespace: use it in a variety of places. Some places where it is good to have it\n    are\n    - around operators (assignment and arithmetic);\n    - between function arguments;\n    - between list/tuple elements; and\n    - between matrix/array indices.\n- Use blank lines to separate blocks of code with comments to say what\n    the block does.\n- Avoid code lines longer than 79 characters and comment/docstring lines\n    longer than 72 characters.\n- Use whitespaces or parentheses for clarity even if not needed for order of\n    operations. For example, `a/y*x` will work but is not easy to read\n    and you can easily induce a bug if you forget the order of ops. Instead,\n    use `a/y * x`.\n- Comments: add lots of comments (but don't belabor the\n    obvious, such as `x = x + 1  # increment x`).\n    - Remember that in a few months, you may not follow your own\n    code any better than a stranger.\n    - Some key things to document: (1)\n      summarizing a block of code, (2) explaining a very complicated piece\n      of code - recall our complicated regular expressions, and (3) explaining\n      arbitrary constant values.\n    - Comments should generally be complete sentences.\n- For software development, break code into separate files\n    (2000-3000 lines per file) with meaningful file names and related\n    functions grouped within a file.\n- Being consistent about the naming style for objects and functions is hard, but try to be consistent. PEP8 suggests:\n    - Class names should be UpperCamelCase.\n    - Function, method, and variable names should be snake_case, e.g., `number_of_its` or `n_its`.\n    - Non-public methods and variables should have a leading underscore.\n- Try to have the names be informative without being overly long.\n- Don't overwrite names of objects/functions that already exist in Python. E.g., don't use `len`. That said, the namespace system helps with the unavoidable cases where there are name conflicts.\n- Use active names for functions (e.g., `calc_loglik`, `calc_log_lik`\n    rather than `loglik` or `loglik_calc`). The idea is that a function\n    in a programming language is like a verb in regular language (a\n    function *does* something), so use a verb to name it.\n- Learn from others' code\n\nThis semester, someone will be reading your code - the GSI and and me when we\nlook at your assignments. So to help us in understanding your code and\ndevelop good habits, put these ideas into practice in your assignments.\n\nWhile not Python examples, the files [goodCode.R](goodCode.R) and [badCode.R](badCode.R) in the `units` directory of the\nclass repository provide examples of code written such that it does and\ndoes not conform to the general ideas listed above (leaving aside the different syntax of Python and R).\n\n\n## Coding style\n\nThis is particularly focused on software development, but some of the\nideas are useful for data analysis as well.\n\n- Break down tasks into core units\n- Write reusable code for core functionality and keep a single copy of\n    the code (using version control or at least with a reasonable backup strategy) so you\n    only need to make changes to a piece of code in one place\n- Smaller functions are easier to debug, easier to understand, and can\n    be combined in a modular fashion (like the UNIX utilities)\n- Write functions that take data as an argument and not lines of code\n    that operate on specific data objects. Why? Functions allow us to\n    reuse blocks of code easily for later use and for recreating an\n    analysis (reproducible research). It's more transparent than\n    sourcing a file of code because the inputs and outputs are specified\n    formally, so you don't have to read through the code to figure out\n    what it does.\n- Functions should:\n    - be modular (having a single task);\n    - have meaningful name; and\n    - have a doc string describing their purpose, inputs and outputs.\n- Write tests for each function (i.e., unit tests)\n- Don't hard code numbers - use variables (e.g., number of iterations,\n    parameter values in simulations), even if you don't expect to change\n    the value, as this makes the code more readable. For example, the speed of light is a constant in a scientific sense, but best to make it a variable in code: `speed_of_light = 3e8`\n- Use lists or tuples to keep disparate parts of related data together\n- Practice defensive programming (see also the discussion below on assertions)\n    - check function inputs and warn users if the code will do something they might not expect or makes particular choices;\n    - check inputs to *if*:\n        - Note that in Python, an expression used as the condition of an `if` will be equivalent to `True` unless it is one of `False`, `0`, `None`, or an empty list/tuple/string.\n    - provide reasonable default arguments;\n    - document the range of valid inputs;\n    - check that the output produced is valid; and\n    - stop execution based on checks and give an informative error message.\n- Try to avoid system-dependent code that only runs on a specific\n    version of an OS or specific OS\n- Learn from others' code\n- Consider rewriting your code once you know all the settings and\n    conditions; often analyses and projects meander as we do our work\n    and the initial plan for the code no longer makes sense and the code\n    is no longer designed specifically for the job being done.\n\n## Assertions and testing\n\nBoth tests and assertions are critically important for writing robust\ncode that is less likely to contain bugs.\n\nAssertions are checks in your code that the state of the program is as\nyou expect, including arguments provided by users. Here's an example of\nusing the `assert` statement in Python, with a clear assertion message\ntelling the user what the problem is.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnumber = -42\nassert number > 0, f\"number greater than 0 expected, got: {number}\"\n## Produces this error:\n## Traceback (most recent call last):\n##   File \"<stdin>\", line 1, in <module>\n## AssertionError: number greater than 0 expected, got: -42\n```\n:::\n\n\nVarious operators/functions are commonly used in assertions, including\n\n\n::: {.cell}\n\n```{.python .cell-code}\nassert x in y\nassert x not in y\nassert x is y\nassert x is not y\nassert isinstance(x, <some_type>)\nassert all(x)\nassert any(x)\n```\n:::\n\n\nTests evaluate whether your code operates correctly. This can include\ntests that your code provides correct and useful errors when something\ngoes wrong (so that means that a test might be to see if problematic\ninput correctly produces an error). *Unit tests* are intended to test\nthe behavior of small pieces (units) of code, generally individual\nfunctions. Unit tests naturally work well with the ideas above of\nwriting small, modular functions. I recommend the `pytest` package,\nwhich is designed to make it easier to write sets of good tests.\n\nIn lab, we'll go over assertions and testing in\ndetail.\n\n## Version control\n\n- Use it! Even for projects that only you are working on.\n- Use an issues tracker (e.g., the GitHub issues tracker is quite\n    nice), or at least a simple to-do file, noting changes you'd like to\n    make in the future.\n- In addition to good commit messages, it's a good idea to keep good\n    running notes documenting your projects.\n\nWe've already seen Git some and will see it in a lot more detail later\nin the semester, so I don't have more to say here.\n\n# 2. Debugging and recommendations for avoiding bugs\n\nPython's `pdb` package provides a standard debugger. JupyterLab also has a debugger.\n\n\n## Basic debugging strategies\n\nHere we'll discuss some basic strategies for finding and fixing bugs. Other useful locations for tips on debugging include:\n\n  - [Efficient Debugging by Goldspink](https://www.codementor.io/mattgoldspink/how-to-debug-code-efficiently-and-effectively-du107u9jh)\n  - [Debugging for Beginners by Brody](https://blog.hartleybrody.com/debugging-code-beginner/)\n\nRead and think about the error message (the *traceback*), starting from the bottom of the traceback. Sometimes it's inscrutable, but often it just needs a bit of deciphering. Looking up a given error message by simply doing a web search with the exact message in double quotes can be a good strategy, or you could look specifically on Stack Overflow.\n\nBelow we'll see how one can view the stack trace. Usually when an error occurs, it occurs in a function call that is nested in a series of function calls. This series of calls is the *call stack* and the *traceback* or *stack trace* shows that series of calls that led to the error. To debug, you'll often need to focus on the function being executed at the time the error occurred (which will be at the top of the call stack but the bottom of the traceback) and the arguments passed into that function. However, if the error occurs in a function you didn't write, the problem will often be with the arguments that your code provided at the last point in the call stack at which code that you wrote was run. Check the arguments that your code passed into that first function that is not a function of yours. \n\nWhen running code that produces multiple errors, fix errors from the top down - fix the first error that is reported, because later errors are often caused by the initial error. It's common to have a string of many errors, which looks daunting, caused by a single initial error.\n\nIs the bug reproducible - does it always happen in the same way at at the same point? It can help to restart Python and see if the bug persists - this can sometimes help in figuring out if there is a scoping issue and we are using a global variable that we did not mean to. \n\nIf you can't figure out where the error occurs based on the error messages, a basic strategy is to build up code in pieces (or tear it back in pieces to a simpler version). This allows you to isolate where the error is occurring. You might use a binary search strategy. Figure out which half of the code the error occurs in. Then split the 'bad' half in half and figure out which half the error occurs in. Repeat until you've isolated the problem.\n\nIf you've written your code modularly with lots of functions, you can test individual functions. Often the error will be in what gets passed into and out of each function.\n\nAt the beginning of time (the 1970s?), the standard debugging strategy was to insert print statements in one's code to see the value of a variable and thereby decipher what could be going wrong. We have better tools nowadays. But sometimes we still need to fall back to inserting print statements.\n\nPython is a scripting language, so you can usually run your code line by line to figure out what is happening. This can be a decent approach, particularly for simple code. However, when you are trying to find errors that occur within a series of many nested function calls or when the errors involve variable scoping (how Python looks for variables that are not local to a function), or in other complicated situations, using formal debugging tools can be much more effective.  Finally, if the error occurs inside of functions provided by Python, rather than ones you write, it can be hard to run the code in those functions line by line. \n\n## Using pdb\n\nWe can activate the debugger in various ways:\n\n  - by inserting `breakpoint()` (or equivalently `import pdb; pdb.set_trace()`) inside a function or module at a location of interest (and then running the function or module)\n  - by using `pdb.pm()` after an error (i.e., an *exception*) has occurred to invoke the browser at the point the error occurred\n  - by running a function under debugger control with `pdb.run()`\n  - by starting python with `python -m pdb file.py` and adding breakpoints \n\n\n### Using `breakpoint`\n\nLet's define a function that will run a stratified analysis, in this case fitting a regression to each of the strata (groups/clusters) in some data.\nOur function is in `stratified_with_break.py`, and it contains `breakpoint` at the point where we want to invoke the debugger.\n\nNow I can call the function and will be put into debugging mode just before the next line is called:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport run_with_break as run\nrun.fit(run.data, run.n_cats)\n```\n:::\n\n\nWhen I run this, I see this:\n\n```\n>>> run.fit(data, n_cats)\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_with_break.py(10)fit()\n-> sub = data[data['cats'] == i]\n(Pdb) \n```\n\nThis indicates I am debugging at line 10 of `run_with_break.py`, which is the line that creates `sub`, but\nI haven't yet created `sub`.\n\nI can type `n` to run that line and go to the next one:\n\n```\n(Pdb) n\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_with_break.py(11)fit()\n-> model = statsmodels.api.OLS(sub['y'], statsmodels.api.add_constant(sub['x']))\n```\n\nat which point the debugger is about to execute line 11, which fits the regression.\n\nI can type `c` to continue until the next breakpoint:\n\n```\n(Pdb) c\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_with_break.py(10)fit()\n-> sub = data[data['cats'] == i]\n```\n\nNow if I print `i`, I see that it has incremented to `1`.\n\n```\n(Pdb) p i\n1\n```\n\nWe could keep hitting `n` or `c` until hitting the stratum where an error occurs, but that would be tedious.\n\nLet's hit `q` to quit out of the debugger.\n\n```\n(Pdb) q\n>>>\n```\n\nNext let's see how we can enter debugging mode only at point an error occurs.\n\n### Post-mortem debugging\n\nWe'll use a version of the module without the `breakpoint()` command.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pdb\nimport run_no_break as run \n\nrun.fit(run.data, run.n_cats)\npdb.pm()\n```\n:::\n\n\nThat puts us into debugging mode at the point the error occurred:\n\n```\n> /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py(86)_wrapreduction()\n-> return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n(Pdb)\n```\n\nwhich turns out to be in some internal Python function that calls a `reduce` function, which is where\nthe error occurs (presumably the debugger doesn't enter this function because it calls compiled code):\n\n```\n(Pdb) l\n 81  \t            if dtype is not None:\n 82  \t                return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)\n 83  \t            else:\n 84  \t                return reduction(axis=axis, out=out, **passkwargs)\n 85  \t\n 86  ->\t    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n 87  \t\n 88  \t\n 89  \tdef _take_dispatcher(a, indices, axis=None, out=None, mode=None):\n 90  \t    return (a, out)\n 91  \t\n```\n\nWe can enter `u` multiple times (it's only shown once below) to go up in the stack of function calls until we recognize code that we wrote:\n\n```\n(Pdb) u\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break.py(10)fit()\n-> model = statsmodels.api.OLS(sub['y'], statsmodels.api.add_constant(sub['x']))\n```\n\nNow let's use `p` to print variable values to understand the problem:\n\n```\n(Pdb)  p i\n29\n(Pdb) p sub\nEmpty DataFrame\nColumns: [y, x, cats]\nIndex: []\n```\n\nAh, so in the 29th stratum there are no data!\n\nIn addition using the IPython magic `%debug` will put you into the debugger in \nin post-mortem mode when an error occurs.\n\n### pdb commands\n\nHere's a list of useful pdb commands (some of which we saw above) that you can use once you've entered debugging mode. \n\n  - `h` or `help`: shows all the commands\n  - `l` or `list`: show the code around where the debugger is currently operating\n  - `c` or `continue`: continue running the code until the next breakpoint\n  - `p` or `print`: print a variable\n  - `n` or `next`: run the current line and go to the next line in the current function\n  - `s` or `step`: jump (step) into the function called in the current line (if it's a Python function)\n  - `r` or `run`: exit out of the current function (e.g., if you accidentally stepped into a function) (but note this stops at breakpoints)\n  - `unt` or `until`: run until the next line (or `unt <number>` to run until reaching line number <number>); this is useful for letting a loop run until completion\n  - `b` or `break`: set a breakpoint\n  - `tbreak`: one-time breakpoint\n  - `where`: shows call stack\n  - `u` (or `up`) and `d` (or `down`): move up and down the call stack\n  - `q` quit out of the debugger\n  - `<return>`: runs the previous pdb command again\n\n### Invoking pdb on a function or block of code\n\nWe can use `pdb.run()` to run a function under the debugger. We need to make sure to use `s` as the first pdb command\nin order to actually step into the function. From there, we can debug as normal as if we had set a breakpoint at the start\nof the function.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport run_with_break as run\nimport pdb\npdb.run(\"run.fit(run.data, run.n_cats)\")\n(Pdb) s\n```\n:::\n\n\n### Invoking pdb on a module\n\nWe can also invoke pdb when we start Python, executing a file (module). Here we've added `fit(data, n_cats)`\nat the end of `run_no_break2.py` so that we can have that run under the debugger.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npython -m pdb run_no_break2.py\n```\n:::\n\n\n```\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break2.py(1)<module>()\n-> import numpy as np\n(Pdb) \n```\n\nLet's set a breakpoint at the same place we did with `breakpoint()` but using a line number (this avoids having to actually modify our code):\n\n```\n(Pdb) b 9\nBreakpoint 1 at /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break.py:9\n```\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(Pdb) c\n> /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break2.py(9)fit()\n-> model = statsmodels.api.OLS(sub['y'], statsmodels.api.add_constant(sub['x']))\n```\n:::\n\n\nSo we've broken at the same point where we manually added `breakpoint()` in `run_with_break.py`.\n\nOr we could have set a breakpoint at the start of the function:\n\n```\n(Pdb) disable 1\nDisabled breakpoint 1 at /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break2.py:9\n(Pdb) b fit\nBreakpoint 1 at /accounts/vis/paciorek/teaching/243fall22/stat243-fall-2023/units/run_no_break.py:6\n```\n\n## Some common causes of bugs \n\nSome of these are Python-specific, while others are common to a variety of languages.\n\n - Parenthesis mis-matches\n - `==` vs. `=` \n - Comparing real numbers exactly using `==` is dangerous because numbers on a computer are only represented to limited numerical precision. For example,\n \n\n    ::: {.cell}\n    \n    ```{.python .cell-code}\n    1/3 == 4*(4/12-3/12)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    False\n    ```\n    :::\n    :::\n\n    \n - You expect a single value but execution of the code gives an array\n - Silent type conversion when you don't want it, or lack of coercion where you're expecting it\n - Using the wrong function or variable name\n - Giving unnamed arguments to a function in the wrong order\n - Forgetting to define a variable in the environment of a function and having Python, via lexical scoping, get that variable as a global variable from one of the enclosing scope. At best the types are not compatible and you get an error; at worst, you use a garbage value and the bug is hard to trace. In some cases your code may work fine when you develop the code (if the variable exists in the enclosing environment), but then may not work when you restart Python if the variable no longer exists or is different.\n - Python (usually helpfully) drops matrix and array dimensions that are extraneous. This can sometimes confuse later code that expects an object of a certain dimension. More on this below.\n\n## Tips for avoiding bugs and catching errors\n\n### Practice defensive programming\n\nWhen writing functions, and software more generally, you'll want to warn the user or stop execution when there is an error and exit gracefully, giving the user some idea of what happened. Here are some things to consider:\n\n - check function inputs and warn users if the code will do something they might not expect or makes particular choices;\n - check inputs to `if` and the ranges in `for` loops;\n - provide reasonable default arguments;\n - document the range of valid inputs;\n - check that the output produced is valid; and\n - stop execution based on assertions, `try` or `raise` with an informative error message.\n\n\nHere's an example of building a robust square root function:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport warnings\n\ndef mysqrt(x):\n    assert not isinstance(x, str), f\"what is the square root of '{x}'?\"\n    if isinstance(x, int) or isinstance(x, float):\n        if x < 0:\n            warnings.warn(\"Input value is negative.\", UserWarning)\n            return float('nan')   # avoid complex number result\n        else:\n            return x**0.5\n    else:\n        raise ValueError(f\"Cannot take the square root of {x}\")\n\n\nmysqrt(3.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.760681686165901\n```\n:::\n\n```{.python .cell-code}\nmysqrt(-3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnan\n\n<string>:5: UserWarning: Input value is negative.\n```\n:::\n\n```{.python .cell-code}\ntry:\n    mysqrt('hat')\nexcept Exception as error:\n    print(error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nwhat is the square root of 'hat'?\n```\n:::\n:::\n\n\n### Catch run-time errors with  `try/except` statements\n\nAlso, sometimes a function you call will fail, but you want to continue execution. For example, consider the stratified analysis show previously in which you take subsets of your data based on some categorical variable and fit a statistical model for each value of the categorical variable. If some of the subsets have no or very few observations, the statistical model fitting might fail. To do this, you might be using a for loop or `apply`. You want your code to continue and fit the model for the rest of the cases even if one (or more) of the cases cannot be fit.  You can wrap the function call that may fail within the `try` statement and then your code won't stop, even when an error occurs. Here's a toy example.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport random\nimport statsmodels.api\n\nnp.random.seed(2)\nn_cats = 30\nn = 80\ny = np.random.normal(size=n)\nx = np.random.normal(size=n)\ncats = [np.random.randint(0, n_cats-1) for _ in range(n)]\ndata = pd.DataFrame({'y': y, 'x': x, 'cats': cats})\n\nparams = np.full((n_cats, 2), np.nan)\nfor i in range(n_cats):\n    sub = data[data['cats'] == i]\n    try:\n        model = statsmodels.api.OLS(sub['y'], statsmodels.api.add_constant(sub['x']))\n        fit = model.fit()\n        params[i, :] = fit.params.values\n    except Exception as error:\n        print(f\"Regression cannot be fit for stratum {i}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRegression cannot be fit for stratum 7.\nRegression cannot be fit for stratum 20.\nRegression cannot be fit for stratum 24.\nRegression cannot be fit for stratum 29.\n```\n:::\n\n```{.python .cell-code}\nprint(params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 5.52897442e-01  2.61511154e-01]\n [ 5.72564369e-01  4.37210543e-02]\n [-9.91086764e-01  2.84116572e-01]\n [-6.50606465e-01  4.26310060e-01]\n [-2.59058826e+00 -2.59058826e+00]\n [ 8.59455139e-01 -4.64514288e+00]\n [ 3.82737032e-06  3.82737032e-06]\n [            nan             nan]\n [-5.55478634e-01 -1.17864561e-01]\n [-9.11601460e-02 -5.91519525e-01]\n [-7.30270153e-01 -1.99976841e-01]\n [-1.14495705e-01 -3.06421213e-02]\n [ 4.01648095e-01  9.30890661e-01]\n [ 7.88388728e-01 -1.45835443e+00]\n [ 4.08462508e+01  6.89262864e+01]\n [ 2.95467536e-01  8.80528901e-01]\n [ 1.04592517e+00  4.55379445e+00]\n [ 6.99549010e-01 -5.17503241e-01]\n [-1.75642254e+00 -8.07798224e-01]\n [-4.49033150e-02  3.53455362e-01]\n [            nan             nan]\n [ 2.63097970e-01  2.63097970e-01]\n [ 1.13328314e+00 -1.39985074e-01]\n [ 1.17996663e+00  3.68770563e-01]\n [            nan             nan]\n [-3.85101497e-03 -3.85101497e-03]\n [-8.04536124e-01 -5.19470059e-01]\n [-5.19200779e-01 -1.39952387e-01]\n [-9.16593858e-01 -2.67613324e-01]\n [            nan             nan]]\n```\n:::\n:::\n\n\nThe stratum with id 7 had no observations, so that call to do the regression failed, but the loop continued because we 'caught' the error with `try`. In this example, we could have checked the sample size for the subset before doing the regression, but in other contexts, we may not have an easy way to check in advance whether the function call will fail.\n\n### Maintain dimensionality\n\nPython (usually helpfully) drops array dimensions that are extraneous. This can sometimes confuse later code that expects an object of a certain dimension. Here's a work-around:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nmat = np.array([[1, 2], [3, 4]])\nnp.sum(mat, axis=0)         # This sums columns, as desired\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([4, 6])\n```\n:::\n\n```{.python .cell-code}\nrow_subset = 1\nmat2 = mat[row_subset, :]\nnp.sum(mat2, axis=0)        # This sums the elements, not the columns.\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n7\n```\n:::\n\n```{.python .cell-code}\nif len(mat2.shape) != 2:    # Fix dimensionality.\n    mat2 = mat2.reshape(1, -1)\n\n\nnp.sum(mat2, axis=0)   \n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([3, 4])\n```\n:::\n:::\n\n\nIn this simple case it's obvious that a dimension will be dropped, but in more complicated settings, this can easily occur for some inputs without the coder realizing that it may happen. Not dropping dimensions is much easier than putting checks in to see if dimensions have been dropped and having the code behave differently depending on the dimensionality.\n\n### Find and avoid global variables\n\nIn general, using global variables (variables that are not created or passed into a function) results in code that is not robust. Results will change if you or a user modifies that global variable, usually without realizing/remembering that a function depends on it. \n\nOne ad hoc strategy is to remove objects you don't need from Python's global scope, to avoid accidentally using values from an old object via Python's scoping rules.\nYou can also run your function in a fresh session to see if it's unable to find variables.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndel x   # Mimic having a fresh sesson (knowing in this case `x` is global).\n\ndef f(z):\n    y = 3\n    print(x + y + z)\n\ntry:\n    f(2)\nexcept Exception as error:\n    print(error)\n    \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nname 'x' is not defined\n```\n:::\n:::\n\n\n### 5.5 Miscellaneous tips\n\n - Use core Python functionality and algorithms already coded. Figure out if a functionality already exists in (or can be adapted from) an Python package (or potentially in a C/Fortran library/package): code that is part of standard mathematical/numerical packages will probably be more efficient and bug-free than anything you would write.\n - Code in a modular fashion, making good use of functions, so that you don't need to debug the same code multiple times. Smaller functions are easier to debug, easier to understand, and can be combined in a modular fashion (like the UNIX utilities).\n - Write code for clarity and accuracy first; then worry about efficiency. Write an initial version of the code in the simplest way, without trying to be efficient (e.g., you might use for loops even if you're coding in Python); then make a second version that employs efficiency tricks and check that both produce the same output.\n - Plan out your code in advance, including all special cases/possibilities.\n - Write tests for your code early in the process. \n - Build up code in pieces, testing along the way. Make big changes in small steps, sequentially checking to see if the code has broken on test case(s).\n - Be careful that the conditions of `if` statements and the sequences of `for` loops are robust when they involve evaluating R code.\n - Don't hard code numbers - use variables (e.g., number of iterations, parameter values in simulations), even if you don't expect to change the value, as this makes the code more readable and reduces bugs when you use the same number multiple times; e.g. `speed_of_light = 3e8` or `n_its = 1000`.\n\n\nIn a future Lab, we'll go over debugging in detail.\n\n# 3. Tips for running analyses\n\nSave your output at intermediate steps (including the random seed state)\nso you can restart if an error occurs or a computer fails. Using\n`pickle.dump()` to write to pickle files works\nwell for this.\n\nRun your code on a small subset of the problem before setting off a job\nthat runs for hours or days. Make sure that the code works on the small\nsubset and saves what you need properly at the end.\n\n# 4. Reproducible research\n\nThe idea of \"reproducible research\" has gained a lot of attention in\nthe last decade because of the increasing complexity of research projects,\nlack of details in the published literature, failures in being able to\nreplicate or reproduce others' work, fraudulent research, and for other\nreasons.\n\nWe've seen a number of tools that can help with doing reproducible\nresearch, including version control systems such as git, the use of\nscripting such as bash and Python scripts, and literate programming tools\nsuch as Quarto and Jupyter notebooks.\n\n*Provenance* is becoming increasingly important in science. It basically\nmeans being able to trace the steps of an analysis back to its origins.\n*Reproducibility* and *replicability* are related concepts:\n\n*Reproducibility* - the idea is that a second person/group could get the\nexact same results as an existing analysis if they use the same input\ndata, methods, and code. This can be surprisingly hard as time passes\neven if you're the one attempting to reproduce things.\n\n*Replicability* - the idea is that a second/person could obtain results\nconsistent with an existing analysis when using new data to answer the\nsame scientific question.\n\nOpen question: What is required for something to be reproducible? What\nabout replicable? What are the challenges in doing so?\n\n## Some basic strategies\n\n- Have a directory for each project with subdirectories with\n    meaningful and standardized names: e.g., `code`, `data`, `paper`. The Journal of the American Statistical Association (JASA) has a [template GitHub repository](https://github.com/jasa-acs/repro-template) with some suggestions.\n- Have a file of code for pre-processing, one or more for analysis,\n    and one for figure/table preparation.\n    - The pre-processing may involve time-consuming steps. Save the\n        output of the pre-processing as a file that can be read in to\n        the analysis script.\n    - You may want to name your files something like this, so there is\n        an obvious ordering: \"1-prep.py\", \"2-analysis.py\", \"3-figs.py\".\n    - Have the code file for the figures produce the **exact** manuscript/report\n        figures, operating on a file (e.g., a pickle file) that contains all the\n        objects necessary to run the figure-producing code; the code\n        producing the pickle file should be in your analysis code file\n        (or somewhere else sensible).\n    - Alternatively, use Quarto or Jupyter notebooks\n        for your document preparation.\n- Keep a document describing your running analysis with dates in a\n    text file (i.e., a lab book).\n- Note where data were obtained (and when, which can be helpful when\n    publishing) and pre-processing steps in the lab book. Have data\n    version numbers with a file describing the changes and dates (or in\n    lab book). If possible, have all changes to data represented as code that processes the data relative to a fixed baseline dataset.\n- Note what code files do what in the lab book.\n- Keep track of the details of the system and software you are running\n    your code under, e.g., operating system version, software (e.g., Python,\n    R) versions, Python or R package versions, etc.\n    - `pip list` and `conda list` will show you version numbers for installed packages.\n\n## Formal tools\n\n1. In some cases you may be able to carry out your complete workflow in\n    a Quarto document or in a Jupyter notebook.\n2. You might consider workflow/pipeline management software such as Drake or other \n    tools discussed in the [CRAN Reproducible Research Task View](https://cran.r-project.org/web/views/ReproducibleResearch.html). Alternatively, one can use the *make* tool, which is generally\n    used for compiling code, as a tool for reproducible research: if\n    interested, see the tutorial on [Using make for workflows](http://github.com/berkeley-scf/tutorial-make-workflows) or this\n    [Journal of Statistical Software article](https://www.jstatsoft.org/article/view/v094c01)\n    for more details.\n3. You might organize your workflow as a Python or R package as described (for the R case) in\n    [this article](https://doi.org/10.1080/00031305.2017.1375986).\n4. Package management:\n    - Python: You can manage the versions of Python packages (and dependent packages) used in your project using Conda environments (or virtualenvs).\n    - R: You can manage the versions of R packages (and dependent packages)\n    used in your project using package management packages such as\n    `renv` and `packrat`. Unfortunately, the useful `checkpoint` package relies on snapshots of CRAN that are not available after January 2023.\n5. If your project uses multiple pieces of software (e.g., not just Python or R), you can set up a reproducible environment using *containers*, of which Docker containers are the best known. These provide something that is like a lightweight virtual machine in which you can install exactly the software (and versions) you want and then share with others. Docker container images are a key building block of various tools such as GitHub Actions and the [Binder project](https://mybinder.org). Alternatively Conda is a general package manager that can install lots of non-Python packages and can also be used in many circumstances.\n",
    "supporting": [
      "unit4-goodPractices_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}